{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "find-subnets-torch",
      "provenance": [],
      "collapsed_sections": [
        "O2PtbrFz01L5",
        "Y1R6bB1u1B-l",
        "_BLEWICr1H6K",
        "uIHGI0a71NVI",
        "dTVKe_Pozw0C",
        "wpSHf83VSgoJ",
        "MmX7Cyzes4Ct",
        "_WAEh60PtAFW"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arunraja-hub/Preference_Extraction/blob/code_de_dup/find_subnets_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2PtbrFz01L5",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVH7LTvX00Y5",
        "colab_type": "code",
        "outputId": "f2e52309-adc9-49bf-8fd5-aaa47703438d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "!git clone https://github.com/arunraja-hub/Preference_Extraction.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Preference_Extraction' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xmOhgVIHOwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms.functional as TF\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import torch.autograd as autograd\n",
        "from torchsummary import summary\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import tensorflow as tf\n",
        "import concurrent.futures\n",
        "import itertools\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "import time\n",
        "import re\n",
        "import io\n",
        "\n",
        "import sys\n",
        "\n",
        "sys.path.append('Preference_Extraction')\n",
        "from imports_data import all_load_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hU3eIxdF6IH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1R6bB1u1B-l",
        "colab_type": "text"
      },
      "source": [
        "## Subnets Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzdNqZBANfjh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "    Original code from What's hidden in a randomly weighted neural network? paper\n",
        "    Implemented at https://github.com/allenai/hidden-networks\n",
        "    Remove weigths-initialisation since it is not relevant for us\n",
        "\"\"\"\n",
        "\n",
        "class GetSubnet(autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, scores, k):\n",
        "        # Get the supermask by sorting the scores and using the top k%\n",
        "        out = scores.clone()\n",
        "        _, idx = scores.flatten().sort()\n",
        "        j = int((1 - k) * scores.numel())\n",
        "\n",
        "        # flat_out and out access the same memory.\n",
        "        flat_out = out.flatten()\n",
        "        flat_out[idx[:j]] = 0\n",
        "        flat_out[idx[j:]] = 1\n",
        "\n",
        "        return out\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, g):\n",
        "        # send the gradient g straight-through on the backward pass.\n",
        "        return g, None\n",
        "\n",
        "class SupermaskConv(nn.Conv2d):\n",
        "    def __init__(self, *args, k, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.k = k\n",
        "\n",
        "        # initialize the scores\n",
        "        self.scores = nn.Parameter(torch.Tensor(self.weight.size()))\n",
        "        nn.init.kaiming_uniform_(self.scores, a=math.sqrt(5))\n",
        "\n",
        "        # initialize the weights\n",
        "        nn.init.uniform_(self.weight)\n",
        "        \n",
        "        # NOTE: turn the gradient on the weights off\n",
        "        self.weight.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        subnet = GetSubnet.apply(self.scores.abs(), self.k)\n",
        "        w = self.weight * subnet\n",
        "        x = F.conv2d(\n",
        "            x, w, self.bias, self.stride, self.padding, self.dilation, self.groups\n",
        "        )\n",
        "        return x\n",
        "\n",
        "class SupermaskLinear(nn.Linear):\n",
        "    def __init__(self, *args, k, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.k = k\n",
        "\n",
        "        # initialize the scores\n",
        "        self.scores = nn.Parameter(torch.Tensor(self.weight.size()))\n",
        "        nn.init.kaiming_uniform_(self.scores, a=math.sqrt(5))\n",
        "\n",
        "        nn.init.uniform_(self.weight)\n",
        "\n",
        "        # NOTE: turn the gradient on the weights off\n",
        "        self.weight.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        subnet = GetSubnet.apply(self.scores.abs(), self.k)\n",
        "        w = self.weight * subnet\n",
        "        return F.linear(x, w, self.bias)\n",
        "        return x\n",
        "\n",
        "# NOTE: not used here but we use NON-AFFINE Normalization!\n",
        "# So there is no learned parameters for your nomralization layer.\n",
        "class NonAffineBatchNorm(nn.BatchNorm2d):\n",
        "    def __init__(self, dim):\n",
        "        super(NonAffineBatchNorm, self).__init__(dim, affine=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BLEWICr1H6K",
        "colab_type": "text"
      },
      "source": [
        "## Define Supermask Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKHxPPHXH-G-",
        "colab_type": "code",
        "outputId": "a888532f-e600-43f9-ad52-4598efbbcfee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "device"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIHGI0a71NVI",
        "colab_type": "text"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YikO82Jj1aWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_raw_data = all_load_data(\"Preference_Extraction/data/simple_env_1/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4htablfz1umt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activations = []\n",
        "observations = []\n",
        "preferences = []\n",
        "\n",
        "for data in all_raw_data:\n",
        "    for i in range(data.observation.shape[0]):\n",
        "        observations.append(np.copy(data.observation[i]))\n",
        "        activations.append(np.copy(data.policy_info[\"activations\"][i]))\n",
        "        preferences.append((data.policy_info['satisfaction'].as_list()[i] > -6).astype(int))\n",
        "\n",
        "activations = np.array(activations)\n",
        "observations = np.array(observations)\n",
        "preferences = np.array(preferences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTVKe_Pozw0C",
        "colab_type": "text"
      },
      "source": [
        "## Define architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLgKTR1sqhB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "    Class modified from above to become enseble of Qhead subnetwrosk\n",
        "\"\"\"\n",
        "\n",
        "class SuperMaskQNets(nn.Module):\n",
        "    def __init__(self, k, q_head_index, q_means_stds):\n",
        "        super(SuperMaskQNets, self).__init__()\n",
        "        self.conv1 = SupermaskConv(in_channels=5, out_channels=16, kernel_size=3, stride=1, bias=True, k=k)\n",
        "        self.conv2 = SupermaskConv(in_channels=16, out_channels=32, kernel_size=3, stride=2, bias=True, k=k)\n",
        "        self.fc1 = SupermaskLinear(in_features=960, out_features=64, bias=True, k=k)\n",
        "        self.fc2 = SupermaskLinear(in_features=64, out_features=3, bias=True, k=k)\n",
        "\n",
        "        assert q_head_index < 3, 'Model has only 3 qHeads'\n",
        "        self.qix = q_head_index\n",
        "        self.qu_mu_s = q_means_stds\n",
        "\n",
        "    def fwd_conv1(self, x):\n",
        "        x = self.conv1(x)\n",
        "        return F.relu(x)\n",
        "\n",
        "    def fwd_conv2(self, x):\n",
        "        x = self.fwd_conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        return F.relu(x)\n",
        "\n",
        "    def fwd_flat(self, x):\n",
        "        x = self.fwd_conv2(x)\n",
        "        return torch.flatten(torch.transpose(x, 1, 3), 1) # Pre-flattening transpose is necessary for TF-Torch conversion\n",
        "\n",
        "    def fwd_fc1(self, x):\n",
        "        x = self.fwd_flat(x)\n",
        "        x = self.fc1(x)\n",
        "        return F.relu(x)\n",
        "    \n",
        "    def fwd_fc2(self, x):\n",
        "        x = self.fwd_fc1(x)\n",
        "        return self.fc2(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fwd_fc2(x)[: ,self.qix]\n",
        "        x -= self.qu_mu_s[self.qix][0]\n",
        "        x /= self.qu_mu_s[self.qix][1]\n",
        "        return torch.sigmoid(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpSHf83VSgoJ",
        "colab_type": "text"
      },
      "source": [
        "## Loading Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD-16xFHSi5r",
        "colab_type": "code",
        "outputId": "b7920251-2ad5-405f-e43f-2eb6b9660741",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "new_save_path = \"Preference_Extraction/saved_model2\"\n",
        "restored_model = tf.keras.models.load_model(new_save_path)\n",
        "restored_model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "EncodingNetwork/conv2d (Conv (None, 12, 14, 16)        736       \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/conv2d_1 (Co (None, 5, 6, 32)          4640      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 960)               0         \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/dense (Dense (None, 64)                61504     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 67,075\n",
            "Trainable params: 67,075\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB2G-FiUTmr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_weights=restored_model.get_weights()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qg-CpUoIqlUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_weights(model):\n",
        "  model.conv1.weight.data = torch.from_numpy(np.transpose(original_weights[0]))\n",
        "  model.conv1.bias.data = torch.from_numpy(original_weights[1])\n",
        "  model.conv2.weight.data = torch.from_numpy(np.transpose(original_weights[2]))\n",
        "  model.conv2.bias.data = torch.from_numpy(original_weights[3])\n",
        "  model.fc1.weight.data = torch.from_numpy(np.transpose(original_weights[4]))\n",
        "  model.fc1.bias.data = torch.from_numpy(original_weights[5])\n",
        "  model.fc2.weight.data = torch.from_numpy(np.transpose(original_weights[6]))\n",
        "  model.fc2.bias.data = torch.from_numpy(original_weights[7])\n",
        "  model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwWx3ioNqhhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "supermask_test_model = SuperMaskQNets(k=1, q_head_index=0, q_means_stds=[0, 1]).to(device)\n",
        "load_weights(supermask_test_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmX7Cyzes4Ct",
        "colab_type": "text"
      },
      "source": [
        "## Test the weights loaded properly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXsgEQuAUwha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Comparing that the models have identical observations for identical images\n",
        "tf_conv1_fn = tf.keras.models.Model(inputs=restored_model.input, outputs=restored_model.layers[0].output)\n",
        "tf_conv2_fn = tf.keras.models.Model(inputs=restored_model.input, outputs=restored_model.layers[1].output)\n",
        "tf_flt_fn = tf.keras.models.Model(inputs=restored_model.input, outputs=restored_model.layers[2].output)\n",
        "tf_fc1_fn = tf.keras.models.Model(inputs=restored_model.input, outputs=restored_model.layers[3].output)\n",
        "\n",
        "for i in range(len(all_raw_data[0].observation)):\n",
        "\n",
        "    single_observation = np.array([all_raw_data[0].observation[i]])\n",
        "    single_observation_torch = torch.Tensor(np.array([np.transpose(all_raw_data[0].observation[i])]))\n",
        "    single_observation_torch = single_observation_torch.to(device)\n",
        "    \n",
        "    conv1_torch_out = np.transpose(supermask_test_model.fwd_conv1(single_observation_torch).detach().cpu().numpy())\n",
        "    conv1_torch_out = conv1_torch_out.reshape(conv1_torch_out.shape[:-1])\n",
        "    conv1_tf_out = tf_conv1_fn(single_observation)[0].numpy()\n",
        "    np.testing.assert_allclose(conv1_torch_out, conv1_tf_out, rtol=.1)\n",
        "\n",
        "    conv2_torch_out = np.transpose(supermask_test_model.fwd_conv2(single_observation_torch).detach().cpu().numpy())\n",
        "    conv2_torch_out = conv2_torch_out.reshape(conv2_torch_out.shape[:-1])\n",
        "    conv2_tf_out = tf_conv2_fn(single_observation)[0].numpy()\n",
        "    np.testing.assert_allclose(conv2_torch_out, conv2_tf_out, rtol=.1)\n",
        "\n",
        "    flt_torch_out = np.transpose(supermask_test_model.fwd_flat(single_observation_torch).detach().cpu().numpy())\n",
        "    flt_torch_out = flt_torch_out.reshape(flt_torch_out.shape[:-1])\n",
        "    tf_flt_out = tf_flt_fn(single_observation)[0].numpy()\n",
        "    np.testing.assert_allclose(flt_torch_out, tf_flt_out, rtol=.1)\n",
        "\n",
        "    fc1_torch_out = np.transpose(supermask_test_model.fwd_fc1(single_observation_torch).detach().cpu().numpy())\n",
        "    fc1_torch_out = fc1_torch_out.reshape(fc1_torch_out.shape[:-1])\n",
        "    fc1_tf_out = tf_fc1_fn(single_observation)[0].numpy()\n",
        "    \n",
        "    old_activations = all_raw_data[0].policy_info[\"activations\"][i]\n",
        "\n",
        "    np.testing.assert_allclose(fc1_torch_out, fc1_tf_out, rtol=.1)\n",
        "    np.testing.assert_allclose(fc1_torch_out, old_activations, rtol=.1)\n",
        "    np.testing.assert_allclose(old_activations, fc1_tf_out, rtol=.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WAEh60PtAFW",
        "colab_type": "text"
      },
      "source": [
        "## Create models for each q net head. And load weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66aDupQf2OAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create dataset iterators\n",
        "num_train = 50\n",
        "num_val = 400\n",
        "batch_size = 10\n",
        "val_batch_size = 10\n",
        "\n",
        "xs = np.rollaxis(observations, 3, 1) # Torch wants channel-first\n",
        "ys = preferences\n",
        "xs, ys = shuffle(xs, ys)\n",
        "\n",
        "xs_tr = xs[:num_train]\n",
        "ys_tr = ys[:num_train]\n",
        "xs_val = xs[num_train:num_train+num_val]\n",
        "ys_val = ys[num_train:num_train+num_val]\n",
        "\n",
        "tr_data_loader = torch.utils.data.DataLoader(\n",
        "    torch.utils.data.TensorDataset(torch.Tensor(xs_tr), torch.Tensor(ys_tr)),\n",
        "    batch_size=batch_size)\n",
        "\n",
        "val_data_loader = torch.utils.data.DataLoader(\n",
        "    torch.utils.data.TensorDataset(torch.Tensor(xs_val), torch.Tensor(ys_val)),\n",
        "    batch_size=val_batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbrjckDJn94C",
        "colab_type": "code",
        "outputId": "02a6cf6a-dc63-4995-858e-b772e4507579",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "def get_q_heads_mu_and_sigma(model, all_obs, num_obs):\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    all_obs = shuffle(all_obs)\n",
        "    obs_to_pass = all_obs[:num_obs]\n",
        "\n",
        "    obs_tensor = torch.Tensor(obs_to_pass)\n",
        "    obs_tensor = obs_tensor.to(device)\n",
        "    qheads_values = model.fwd_fc2(obs_tensor).detach().cpu().numpy()\n",
        "\n",
        "    mu = qheads_values.mean(axis=0)\n",
        "    s = qheads_values.std(axis=0)\n",
        "\n",
        "    qheads_mu_s = {}\n",
        "    for qix in range(len(mu)):\n",
        "        qheads_mu_s[qix] = (mu[qix], s[qix])\n",
        "    \n",
        "    return qheads_mu_s\n",
        "\n",
        "q_mu_s = get_q_heads_mu_and_sigma(supermask_test_model, xs, 10000)\n",
        "q_mu_s"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: (92.63736, 47.492996), 1: (68.10719, 50.8589), 2: (138.20757, 77.337135)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyUDDJgZrZN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K = 0.5\n",
        "\n",
        "spmsk_model_q0 = SuperMaskQNets(k=K, q_head_index=0, q_means_stds=q_mu_s).to(device)\n",
        "load_weights(spmsk_model_q0)\n",
        "\n",
        "spmsk_model_q1 = SuperMaskQNets(k=K, q_head_index=1, q_means_stds=q_mu_s).to(device)\n",
        "load_weights(spmsk_model_q1)\n",
        "\n",
        "spmsk_model_q2 = SuperMaskQNets(k=K, q_head_index=2, q_means_stds=q_mu_s).to(device)\n",
        "load_weights(spmsk_model_q1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmBC-kAotIBQ",
        "colab_type": "text"
      },
      "source": [
        "## Train models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEj7Qn1-H-Es",
        "colab_type": "code",
        "outputId": "f8208318-0f99-43ce-8507-dd8c617d594b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "\"\"\"\n",
        "    Train/Test function for Randomly Weighted Hidden Neural Networks Techniques\n",
        "    Adapted from https://github.com/NesterukSergey/hidden-networks/blob/master/demos/mnist.ipynb\n",
        "\"\"\"\n",
        "\n",
        "def train(model, device, train_loader, optimizer, criterion, verbose=False):\n",
        "    \n",
        "    train_loss = 0\n",
        "    true_labels = []\n",
        "    predictions = [] # labels\n",
        "    outputs = [] # probabilities\n",
        "\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss\n",
        "        output_value = output.detach().cpu().numpy()\n",
        "        outputs.append(output)\n",
        "        pred = (output_value > 0.5).astype(float)\n",
        "        predictions.extend(pred)\n",
        "        true_labels.extend(target.detach().cpu().numpy())\n",
        "\n",
        "    predictions = np.array(predictions)\n",
        "    true_labels = np.array(true_labels)\n",
        "    outputs = np.array(outputs)\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    accuracy = np.sum(np.equal(predictions, true_labels)) / len(true_labels)\n",
        "    auc = roc_auc_score(true_labels, predictions)\n",
        "\n",
        "    return train_loss.item(), accuracy, auc\n",
        "\n",
        "\n",
        "def test(model, device, criterion, test_loader):\n",
        "    true_labels = []\n",
        "    predictions = [] # labels\n",
        "    outputs = [] # probabilities\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target)\n",
        "\n",
        "            output_value = output.detach().cpu().numpy()\n",
        "            outputs.append(output)\n",
        "            pred = (output_value > 0.5).astype(float)\n",
        "            predictions.extend(pred)\n",
        "            true_labels.extend(target.detach().cpu().numpy())\n",
        "\n",
        "    predictions = np.array(predictions)\n",
        "    true_labels = np.array(true_labels)\n",
        "    outputs = np.array(outputs)\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = np.sum(np.equal(predictions, true_labels)) / len(true_labels)\n",
        "    auc = roc_auc_score(true_labels, predictions)\n",
        "\n",
        "    return test_loss.item(), accuracy, auc\n",
        "\n",
        "def run_model(model, num_epochs, verbose=False):\n",
        "  # NOTE: only pass the parameters where p.requires_grad == True to the optimizer! Important!\n",
        "  optimizer = optim.SGD(\n",
        "      [p for p in model.parameters() if p.requires_grad],\n",
        "      lr=0.1,\n",
        "      momentum=0.9,\n",
        "      weight_decay=0.0005,\n",
        "  )\n",
        "\n",
        "  criterion = nn.BCELoss().to(device)\n",
        "  scheduler = CosineAnnealingLR(optimizer, T_max=14)\n",
        "\n",
        "  train_accs = []\n",
        "  train_aucs = []\n",
        "  test_accs = []\n",
        "  test_aucs = []\n",
        "\n",
        "  for epoch in tqdm(range(num_epochs)):\n",
        "      train_loss, train_accuracy, train_auc = train(model, device, tr_data_loader, optimizer, criterion, verbose=False)\n",
        "      test_loss, test_accuracy, test_auc = test(model, device, criterion, val_data_loader)\n",
        "      if verbose:\n",
        "        print(f'Epoch {epoch}: train loss - {train_loss} / test loss {test_loss}')\n",
        "      scheduler.step()\n",
        "\n",
        "      train_accs.append(train_accuracy)\n",
        "      train_aucs.append(train_auc)\n",
        "      test_accs.append(test_accuracy)\n",
        "      test_aucs.append(test_auc)\n",
        "\n",
        "  print('Train accuracy: ', train_accs[-1])\n",
        "  print('Test accuracy: ', test_accs[-1])\n",
        "\n",
        "  print('Train AUC: ', train_aucs[-1])  \n",
        "  print('Test AUC: ', test_aucs[-1])\n",
        "\n",
        "num_epochs = 100\n",
        "print()\n",
        "run_model(spmsk_model_q0, num_epochs=num_epochs)\n",
        "print()\n",
        "run_model(spmsk_model_q1, num_epochs=num_epochs)\n",
        "print()\n",
        "run_model(spmsk_model_q2, num_epochs=num_epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.28it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train accuracy:  0.98\n",
            "Test accuracy:  0.6825\n",
            "Train AUC:  0.9821428571428572\n",
            "Test AUC:  0.68919779286927\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.30it/s]\n",
            "  1%|          | 1/100 [00:00<00:18,  5.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train accuracy:  1.0\n",
            "Test accuracy:  0.745\n",
            "Train AUC:  1.0\n",
            "Test AUC:  0.6975806451612904\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 25/100 [00:04<00:13,  5.36it/s]"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}