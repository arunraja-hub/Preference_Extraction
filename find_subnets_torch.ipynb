{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "find-subnets-torch",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arunraja-hub/Preference_Extraction/blob/fine_tune/find_subnets_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2PtbrFz01L5",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVH7LTvX00Y5",
        "colab_type": "code",
        "outputId": "c1896933-dc68-4f4b-b95f-c7fa7c7021ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "!git clone https://github.com/arunraja-hub/Preference_Extraction.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Preference_Extraction' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xmOhgVIHOwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms.functional as TF\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import torch.autograd as autograd\n",
        "from torchsummary import summary\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "import concurrent.futures\n",
        "import itertools\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import sys\n",
        "import time\n",
        "import re\n",
        "import io\n",
        "import collections"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hU3eIxdF6IH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1R6bB1u1B-l",
        "colab_type": "text"
      },
      "source": [
        "## Subnets Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzdNqZBANfjh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GetSubnet(autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, scores, k):\n",
        "        # Get the supermask by sorting the scores and using the top k%\n",
        "        out = scores.clone()\n",
        "        _, idx = scores.flatten().sort()\n",
        "        j = int((1 - k) * scores.numel())\n",
        "\n",
        "        # flat_out and out access the same memory.\n",
        "        flat_out = out.flatten()\n",
        "        flat_out[idx[:j]] = 0\n",
        "        flat_out[idx[j:]] = 1\n",
        "\n",
        "        return out\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, g):\n",
        "        # send the gradient g straight-through on the backward pass.\n",
        "        return g, None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBkV-s-bQPqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SupermaskConv(nn.Conv2d):\n",
        "    def __init__(self, *args, k, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.k = k\n",
        "\n",
        "        # initialize the scores\n",
        "        self.scores = nn.Parameter(torch.Tensor(self.weight.size()))\n",
        "        nn.init.kaiming_uniform_(self.scores, a=math.sqrt(5))\n",
        "\n",
        "        # initialize the weights\n",
        "        nn.init.uniform_(self.weight)\n",
        "        \n",
        "        # NOTE: turn the gradient on the weights off\n",
        "        self.weight.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        subnet = GetSubnet.apply(self.scores.abs(), self.k)\n",
        "        w = self.weight * subnet\n",
        "        x = F.conv2d(\n",
        "            x, w, self.bias, self.stride, self.padding, self.dilation, self.groups\n",
        "        )\n",
        "        return x\n",
        "\n",
        "class SupermaskLinear(nn.Linear):\n",
        "    def __init__(self, *args, k, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.k = k\n",
        "\n",
        "        # initialize the scores\n",
        "        self.scores = nn.Parameter(torch.Tensor(self.weight.size()))\n",
        "        nn.init.kaiming_uniform_(self.scores, a=math.sqrt(5))\n",
        "\n",
        "        nn.init.uniform_(self.weight)\n",
        "\n",
        "        # NOTE: turn the gradient on the weights off\n",
        "        self.weight.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        subnet = GetSubnet.apply(self.scores.abs(), self.k)\n",
        "        w = self.weight * subnet\n",
        "        return F.linear(x, w, self.bias)\n",
        "        return x\n",
        "\n",
        "# NOTE: not used here but we use NON-AFFINE Normalization!\n",
        "# So there is no learned parameters for your nomralization layer.\n",
        "class NonAffineBatchNorm(nn.BatchNorm2d):\n",
        "    def __init__(self, dim):\n",
        "        super(NonAffineBatchNorm, self).__init__(dim, affine=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BLEWICr1H6K",
        "colab_type": "text"
      },
      "source": [
        "## Define Supermask Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1Bbsd8pQPu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, k):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = SupermaskConv(in_channels=5, out_channels=16, kernel_size=3, stride=1, bias=True, k=k)\n",
        "        self.conv2 = SupermaskConv(in_channels=16, out_channels=32, kernel_size=3, stride=2, bias=True, k=k)\n",
        "        self.fc1 = SupermaskLinear(in_features=960, out_features=64, bias=True, k=k)\n",
        "        self.fc2 = SupermaskLinear(in_features=64, out_features=3, bias=True, k=k)\n",
        "\n",
        "    def fwd_conv1(self, x):\n",
        "        x = self.conv1(x)\n",
        "        return F.relu(x)\n",
        "\n",
        "    def fwd_conv2(self, x):\n",
        "        x = self.fwd_conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        return F.relu(x)\n",
        "\n",
        "    def fwd_flat(self, x):\n",
        "        x = self.fwd_conv2(x)\n",
        "        return torch.flatten(torch.transpose(x, 1, 3), 1)\n",
        "\n",
        "    def fwd_dense(self, x):\n",
        "        x = self.fwd_flat(x)\n",
        "        x = self.fc1(x)\n",
        "        return F.relu(x)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.fwd_dense(x)\n",
        "        x = self.fc2(x)\n",
        "        output = F.sigmoid(x)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKHxPPHXH-G-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7dd18319-f16e-4331-be0c-b34d7ed928f8"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "device"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYPowxHowZcH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "12c953e4-f667-4160-80cf-0ba51daa282a"
      },
      "source": [
        "# Using a mock supermask model with k=1 because we want to first test that the two models are equivalent \n",
        "supermask_test_model = Net(k=1).to(device)\n",
        "summary(supermask_test_model, (5, 14, 16))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "     SupermaskConv-1           [-1, 16, 12, 14]             736\n",
            "     SupermaskConv-2             [-1, 32, 5, 6]           4,640\n",
            "   SupermaskLinear-3                   [-1, 64]          61,504\n",
            "   SupermaskLinear-4                    [-1, 3]             195\n",
            "================================================================\n",
            "Total params: 67,075\n",
            "Trainable params: 0\n",
            "Non-trainable params: 67,075\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.03\n",
            "Params size (MB): 0.26\n",
            "Estimated Total Size (MB): 0.29\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIHGI0a71NVI",
        "colab_type": "text"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oQdQzNj1Ph2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Trajectory(\n",
        "    collections.namedtuple('Trajectory', [\n",
        "        'step_type',\n",
        "        'observation',\n",
        "        'action',\n",
        "        'policy_info',\n",
        "        'next_step_type',\n",
        "        'reward',\n",
        "        'discount',\n",
        "    ])):\n",
        "  \"\"\"Stores the observation the agent saw and the action it took.\n",
        "      The rest of the attributes aren't used in this code.\"\"\"\n",
        "  __slots__ = ()\n",
        "\n",
        "class ListWrapper(object):\n",
        "  def __init__(self, list_to_wrap):\n",
        "    self._list = list_to_wrap\n",
        "\n",
        "  def as_list(self):\n",
        "    return self._list\n",
        "\n",
        "class RenameUnpickler(pickle.Unpickler):\n",
        "    def find_class(self, module, name):\n",
        "      if name == \"Trajectory\":\n",
        "        return Trajectory\n",
        "      if name == \"ListWrapper\":\n",
        "        return ListWrapper\n",
        "\n",
        "      return super(RenameUnpickler, self).find_class(module, name)\n",
        "\n",
        "def rename_load(s):\n",
        "    \"\"\"Helper function analogous to pickle.loads().\"\"\"\n",
        "    return RenameUnpickler(s, encoding='latin1').load()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YikO82Jj1aWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Modified read trajectories functions to read files from local storage\n",
        "\n",
        "def load_file(full_path):\n",
        "    try:\n",
        "        with open(full_path, 'rb') as f:\n",
        "            data = rename_load(f)\n",
        "            return data\n",
        "    except:\n",
        "        return None\n",
        "    \n",
        "def all_load_data(base_path):\n",
        "    \n",
        "    executor = concurrent.futures.ThreadPoolExecutor(max_workers=100)\n",
        "    \n",
        "    futures = []\n",
        "    for i in range(5000):\n",
        "        full_path = os.path.join(base_path, \"ts\"+str(i)+\".pickle\")\n",
        "        future = executor.submit(load_file, full_path)\n",
        "        futures.append(future)\n",
        "    \n",
        "    raw_data = []\n",
        "    for future in concurrent.futures.as_completed(futures):\n",
        "        result = future.result()\n",
        "        if result:\n",
        "            raw_data.append(result)\n",
        "    \n",
        "    return raw_data\n",
        "\n",
        "\n",
        "all_raw_data = all_load_data(\"Preference_Extraction/data/simple_env_1/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4htablfz1umt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activations = []\n",
        "observations = []\n",
        "preferences = []\n",
        "\n",
        "for data in all_raw_data:\n",
        "    for i in range(data.observation.shape[0]):\n",
        "        observations.append(np.copy(data.observation[i]))\n",
        "        activations.append(np.copy(data.policy_info[\"activations\"][i]))\n",
        "        preferences.append((data.policy_info['satisfaction'].as_list()[i] > -6).astype(int))\n",
        "\n",
        "activations = np.array(activations)\n",
        "observations = np.array(observations)\n",
        "preferences = np.array(preferences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpSHf83VSgoJ",
        "colab_type": "text"
      },
      "source": [
        "## Loading Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD-16xFHSi5r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "e2939396-f3e4-4176-83b2-92c43e28247b"
      },
      "source": [
        "new_save_path = \"Preference_Extraction/saved_model2\"\n",
        "restored_model = tf.keras.models.load_model(new_save_path)\n",
        "restored_model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "EncodingNetwork/conv2d (Conv (None, 12, 14, 16)        736       \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/conv2d_1 (Co (None, 5, 6, 32)          4640      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 960)               0         \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/dense (Dense (None, 64)                61504     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 67,075\n",
            "Trainable params: 67,075\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB2G-FiUTmr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_weights=restored_model.get_weights()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL1eIitRUXYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check Shapes\n",
        "assert tuple(supermask_test_model.conv1.weight.data.shape) == np.transpose(original_weights[0]).shape\n",
        "assert tuple(supermask_test_model.conv1.bias.data.shape) == original_weights[1].shape\n",
        "assert tuple(supermask_test_model.conv2.weight.data.shape) == np.transpose(original_weights[2]).shape\n",
        "assert tuple(supermask_test_model.conv2.bias.data.shape) == original_weights[3].shape\n",
        "assert tuple(supermask_test_model.fc1.weight.data.shape) == np.transpose(original_weights[4]).shape\n",
        "assert tuple(supermask_test_model.fc1.bias.data.shape) == original_weights[5].shape\n",
        "assert tuple(supermask_test_model.fc2.weight.data.shape) == np.transpose(original_weights[6]).shape\n",
        "assert tuple(supermask_test_model.fc2.bias.data.shape) == original_weights[7].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oCGiuScTvXK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "59cbcf05-15d4-43a5-cea8-7631c6900fb9"
      },
      "source": [
        "# Load Weights\n",
        "supermask_test_model.conv1.weight.data = torch.from_numpy(np.transpose(original_weights[0]))\n",
        "supermask_test_model.conv1.bias.data = torch.from_numpy(original_weights[1])\n",
        "supermask_test_model.conv2.weight.data = torch.from_numpy(np.transpose(original_weights[2]))\n",
        "supermask_test_model.conv2.bias.data = torch.from_numpy(original_weights[3])\n",
        "\n",
        "supermask_test_model.fc1.weight.data = torch.from_numpy(np.transpose(original_weights[4]))\n",
        "supermask_test_model.fc1.bias.data = torch.from_numpy(original_weights[5])\n",
        "supermask_test_model.fc2.weight.data = torch.from_numpy(np.transpose(original_weights[6]))\n",
        "supermask_test_model.fc2.bias.data = torch.from_numpy(original_weights[7])\n",
        "\n",
        "supermask_test_model.to(device)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): SupermaskConv(5, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): SupermaskConv(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
              "  (fc1): SupermaskLinear(in_features=960, out_features=64, bias=True)\n",
              "  (fc2): SupermaskLinear(in_features=64, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXsgEQuAUwha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Comparing that the models have identical observations for identical images\n",
        "old_conv1 = tf.keras.models.Model(inputs=restored_model.input, outputs=restored_model.layers[0].output)\n",
        "old_conv2 = tf.keras.models.Model(inputs=restored_model.input, outputs=restored_model.layers[1].output)\n",
        "old_flt = tf.keras.models.Model(inputs=restored_model.input, outputs=restored_model.layers[2].output)\n",
        "old_fc1 = tf.keras.models.Model(inputs=restored_model.input, outputs=restored_model.layers[3].output)\n",
        "\n",
        "\n",
        "for i in range(len(all_raw_data[0].observation)):\n",
        "    single_observation = np.array([all_raw_data[0].observation[i]])\n",
        "\n",
        "    single_observation_torch = np.array([np.transpose(all_raw_data[0].observation[i])])\n",
        "\n",
        "    test_in = torch.Tensor(single_observation_torch)\n",
        "    test_in = test_in.to(memory_format=torch.channels_last)\n",
        "    test_in = test_in.to(device)\n",
        "    \n",
        "    test_conv1 = np.transpose(supermask_test_model.fwd_conv1(test_in).detach().cpu().numpy())\n",
        "    test_conv1 = test_conv1.reshape(test_conv1.shape[:-1])\n",
        "    restored_conv1 = old_conv1(single_observation)[0].numpy()\n",
        "    np.testing.assert_allclose(test_conv1, restored_conv1, rtol=.1)\n",
        "\n",
        "    test_conv2 = np.transpose(supermask_test_model.fwd_conv2(test_in).detach().cpu().numpy())\n",
        "    test_conv2 = test_conv2.reshape(test_conv2.shape[:-1])\n",
        "    restored_conv2 = old_conv2(single_observation)[0].numpy()\n",
        "    np.testing.assert_allclose(test_conv2, restored_conv2, rtol=.1)\n",
        "\n",
        "    test_flt = np.transpose(supermask_test_model.fwd_flat(test_in).detach().cpu().numpy())\n",
        "    test_flt = test_flt.reshape(test_flt.shape[:-1])\n",
        "    restored_flt = old_flt(single_observation)[0].numpy()\n",
        "    np.testing.assert_allclose(test_flt, restored_flt, rtol=.1)\n",
        "\n",
        "    test_fc1 = np.transpose(supermask_test_model.fwd_dense(test_in).detach().cpu().numpy())\n",
        "    test_fc1 = test_fc1.reshape(test_fc1.shape[:-1])\n",
        "    restored_fc1 = old_fc1(single_observation)[0].numpy()\n",
        "    old_activations = all_raw_data[0].policy_info[\"activations\"][i]\n",
        "\n",
        "    np.testing.assert_allclose(test_fc1, restored_fc1, rtol=.1)\n",
        "    np.testing.assert_allclose(test_fc1, old_activations, rtol=.1)\n",
        "    np.testing.assert_allclose(old_activations, restored_fc1, rtol=.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTVKe_Pozw0C",
        "colab_type": "text"
      },
      "source": [
        "## Training Supermask (incomplete)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJhAP7DAzy9Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "9b781586-2b80-4efa-8042-13e9fac98d6a"
      },
      "source": [
        "# Creating and loading weights\n",
        "spmsk_model = Net(k=1).to(device)\n",
        "\n",
        "spmsk_model.conv1.weight.data = torch.from_numpy(np.transpose(original_weights[0]))\n",
        "spmsk_model.conv1.bias.data = torch.from_numpy(original_weights[1])\n",
        "spmsk_model.conv2.weight.data = torch.from_numpy(np.transpose(original_weights[2]))\n",
        "spmsk_model.conv2.bias.data = torch.from_numpy(original_weights[3])\n",
        "spmsk_model.fc1.weight.data = torch.from_numpy(np.transpose(original_weights[4]))\n",
        "spmsk_model.fc1.bias.data = torch.from_numpy(original_weights[5])\n",
        "spmsk_model.fc2.weight.data = torch.from_numpy(np.transpose(original_weights[6]))\n",
        "spmsk_model.fc2.bias.data = torch.from_numpy(original_weights[7])\n",
        "\n",
        "spmsk_model.to(device)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): SupermaskConv(5, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): SupermaskConv(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
              "  (fc1): SupermaskLinear(in_features=960, out_features=64, bias=True)\n",
              "  (fc2): SupermaskLinear(in_features=64, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66aDupQf2OAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create dataset iterators\n",
        "num_train = 50\n",
        "num_val = 400\n",
        "batch_size = 50\n",
        "val_batch_size = 50\n",
        "\n",
        "xs = np.rollaxis(observations, 3, 1) # Torch wants channel-first\n",
        "ys = preferences\n",
        "xs, ys = shuffle(xs, ys)\n",
        "\n",
        "xs_tr = xs[:num_train]\n",
        "ys_tr = ys[:num_train]\n",
        "xs_val = xs[num_train:num_train+num_val]\n",
        "ys_val = ys[num_train:num_train+num_val]\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    torch.utils.data.TensorDataset(torch.Tensor(xs_tr), torch.Tensor(ys_tr)),\n",
        "    batch_size=batch_size)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    torch.utils.data.TensorDataset(torch.Tensor(xs_val), torch.Tensor(ys_val)),\n",
        "    batch_size=val_batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEj7Qn1-H-Es",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, device, train_loader, optimizer, criterion, epoch, verbose=False):\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss\n",
        "\n",
        "        if verbose:\n",
        "          if batch_idx % 5 == 0:\n",
        "              print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                  epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                  100. * batch_idx / len(train_loader), loss.item()))\n",
        "              \n",
        "    return train_loss / len(train_loader.dataset)\n",
        "\n",
        "\n",
        "def test(model, device, criterion, test_loader):\n",
        "    true_labels = []\n",
        "    predictions = [] # labels\n",
        "    outputs = [] # probabilities\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target)\n",
        "            outputs.append(output.detach().cpu().numpy())\n",
        "            pred = output > 0.5\n",
        "\n",
        "            predictions.extend(pred)\n",
        "            true_labels.extend(target.detach().cpu().numpy())\n",
        "\n",
        "    predictions = np.array(predictions)\n",
        "    true_labels = np.array(true_labels)\n",
        "    outputs = np.array(outputs)\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_accuracy = np.sum(np.equal(predictions, true_labels)) / len(true_labels)\n",
        "    \n",
        "    return test_loss.item(), test_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19SLowpjH-Lv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_model(k, model, num_epochs):\n",
        "  # NOTE: only pass the parameters where p.requires_grad == True to the optimizer! Important!\n",
        "  optimizer = optim.SGD(\n",
        "      [p for p in model.parameters() if p.requires_grad],\n",
        "      lr=0.1,\n",
        "      momentum=0.9,\n",
        "      weight_decay=0.0005,\n",
        "  )\n",
        "\n",
        "  criterion = nn.BCELoss().to(device)\n",
        "  scheduler = CosineAnnealingLR(optimizer, T_max=14)\n",
        "\n",
        "  train_losses = []\n",
        "  test_losses = []\n",
        "  test_acc = []\n",
        "\n",
        "  for epoch in tqdm(range(num_epochs)):\n",
        "      train_loss = train(model, device, train_loader, optimizer, criterion, epoch, verbose=False)\n",
        "      test_loss, test_accuracy = test(model, device, criterion, test_loader)\n",
        "      scheduler.step()\n",
        "\n",
        "      train_losses.append(train_loss)\n",
        "      test_losses.append(test_loss)\n",
        "      test_acc.append(test_accuracy)\n",
        "\n",
        "  print('k: ', k, '  init: ', init)\n",
        "  print('Test loss: ', test_losses[-1])\n",
        "  print('Test accuracy: ', test_acc[-1])\n",
        "\n",
        "# run_model(0.3, spmsk_model, num_epochs=400)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}