{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "find-subnets-torch-bugfix",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWwPhoB4VkHs",
        "colab_type": "text"
      },
      "source": [
        "# Everything"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2PtbrFz01L5",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVH7LTvX00Y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.isdir('Preference_Extraction'):\n",
        "    print(\"Setting up colab environment\")\n",
        "    !pip uninstall -y -q pyarrow\n",
        "    !pip install -q https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.8.0.dev5-cp36-cp36m-manylinux1_x86_64.whl\n",
        "    !pip install -q ray[debug]\n",
        "    !pip install 'ray[tune]' \n",
        "    !pip install bayesian-optimization\n",
        "\n",
        "    !git clone https://github.com/arunraja-hub/Preference_Extraction.git\n",
        "    # # A hack to force the runtime to restart, needed to include the above dependencies.\n",
        "    # # Only after first time\n",
        "    os._exit(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd-5ibD8Zsfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## If you are running on Google Colab, please install TensorFlow 2.0 by uncommenting below..\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xmOhgVIHOwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms.functional as TF\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torchvision import datasets, transforms\n",
        "import torch.autograd as autograd\n",
        "from torchsummary import summary\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import tensorflow as tf\n",
        "import concurrent.futures\n",
        "import itertools\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "import time\n",
        "import re\n",
        "import io\n",
        "import itertools\n",
        "import sys\n",
        "\n",
        "import ray\n",
        "from ray import tune\n",
        "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
        "from ray.tune.suggest.bayesopt import BayesOptSearch\n",
        "\n",
        "sys.path.append('Preference_Extraction')\n",
        "from imports_data import all_load_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hU3eIxdF6IH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKHxPPHXH-G-",
        "colab_type": "code",
        "outputId": "bec2c56b-0dd5-40ef-b39c-eb7f1a5f1712",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "device"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5pVqCzTrzc2",
        "colab_type": "text"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvjWhMZVr2el",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {\n",
        "    'num_train': 50,\n",
        "    'num_tune': 25,\n",
        "    'num_val': 400,\n",
        "    'batch_size': 10,\n",
        "    'val_batch_size': 10,\n",
        "    'num_epochs': 40,\n",
        "    'use_qnet_weights': True, # Flag for running models that use the weights of Qnet vs models that use random weights\n",
        "    'use_mnist': False,  # Flag for running models on MNIST. If False uses RL Preference Extraction data\n",
        "    'num_run': 5  # Number of runs (with different data sample) over which to average performance\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1R6bB1u1B-l",
        "colab_type": "text"
      },
      "source": [
        "## Subnets Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzdNqZBANfjh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "    Original code from What's hidden in a randomly weighted neural network? paper\n",
        "    Implemented at https://github.com/allenai/hidden-networks\n",
        "    Remove weigths-initialisation since it is not relevant for us\n",
        "\"\"\"\n",
        "\n",
        "class GetSubnet(autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, scores, k):\n",
        "        # Get the supermask by sorting the scores and using the top k%\n",
        "        out = scores.clone()\n",
        "        _, idx = scores.flatten().sort()\n",
        "        j = int((1 - k) * scores.numel())\n",
        "\n",
        "        # flat_out and out access the same memory.\n",
        "        flat_out = out.flatten()\n",
        "        flat_out[idx[:j]] = 0\n",
        "        flat_out[idx[j:]] = 1\n",
        "\n",
        "        return out\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, g):\n",
        "        # send the gradient g straight-through on the backward pass.\n",
        "        return g, None\n",
        "\n",
        "class SupermaskConv(nn.Conv2d):\n",
        "    def __init__(self, *args, k, scores_init='kaiming_uniform', **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.k = k\n",
        "        self.scores_init = scores_init\n",
        "\n",
        "        # initialize the scores\n",
        "        self.scores = nn.Parameter(torch.Tensor(self.weight.size()))\n",
        "        if self.scores_init == 'kaiming_normal':\n",
        "          nn.init.kaiming_normal_(self.weight)\n",
        "        elif self.scores_init == 'kaiming_uniform':\n",
        "          nn.init.kaiming_uniform_(self.scores, a=math.sqrt(5))\n",
        "        elif self.scores_init == 'xavier_normal':\n",
        "          nn.init.xavier_normal_(self.weight)\n",
        "        else:\n",
        "          nn.init.uniform_(self.weight)\n",
        "\n",
        "        # initialize the weights\n",
        "        nn.init.uniform_(self.weight)\n",
        "        \n",
        "        # NOTE: turn the gradient on the weights off\n",
        "        self.weight.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        subnet = GetSubnet.apply(self.scores.abs(), self.k)\n",
        "        w = self.weight * subnet\n",
        "        x = F.conv2d(\n",
        "            x, w, self.bias, self.stride, self.padding, self.dilation, self.groups\n",
        "        )\n",
        "        return x\n",
        "\n",
        "class SupermaskLinear(nn.Linear):\n",
        "    def __init__(self, *args, k, scores_init='xavier_normal', **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.k = k\n",
        "        self.scores_init = scores_init\n",
        "\n",
        "        # initialize the scores and weights\n",
        "        self.scores = nn.Parameter(torch.Tensor(self.weight.size()))\n",
        "        if self.scores_init == 'kaiming_normal':\n",
        "          nn.init.kaiming_normal_(self.weight)\n",
        "        elif self.scores_init == 'kaiming_uniform':\n",
        "          nn.init.kaiming_uniform_(self.scores, a=math.sqrt(5))\n",
        "        elif self.scores_init == 'xavier_normal':\n",
        "          nn.init.xavier_normal_(self.weight)\n",
        "        else:\n",
        "          nn.init.uniform_(self.weight)\n",
        "\n",
        "        nn.init.uniform_(self.weight)\n",
        "\n",
        "        # NOTE: turn the gradient on the weights off\n",
        "        self.weight.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        subnet = GetSubnet.apply(self.scores.abs(), self.k)\n",
        "        w = self.weight * subnet\n",
        "        return F.linear(x, w, self.bias)\n",
        "        return x\n",
        "\n",
        "# NOTE: not used here but we use NON-AFFINE Normalization!\n",
        "# So there is no learned parameters for your nomralization layer.\n",
        "class NonAffineBatchNorm(nn.BatchNorm2d):\n",
        "    def __init__(self, dim):\n",
        "        super(NonAffineBatchNorm, self).__init__(dim, affine=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTVKe_Pozw0C",
        "colab_type": "text"
      },
      "source": [
        "## Define architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLgKTR1sqhB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PrefQNet(nn.Module):\n",
        "    \"\"\"\n",
        "      If q_head_index is None, this uses a linear model on the normalized q outputs.\n",
        "      Otherwise, it gets the Q head with the specified index.\n",
        "    \"\"\" \n",
        "    def __init__(self, fine_tune, k, q_head_index, q_means_stds, use_last_linear):\n",
        "        super(PrefQNet, self).__init__()\n",
        "        \n",
        "        if not params['use_mnist']:\n",
        "            channels_in = 5\n",
        "            flattened_shape = 960\n",
        "        else:\n",
        "            channels_in = 1\n",
        "            flattened_shape = 4608\n",
        "\n",
        "        if fine_tune:\n",
        "            conv_layer = nn.Conv2d\n",
        "            dense_layer = nn.Linear\n",
        "            additional_args = {}\n",
        "        else:\n",
        "            conv_layer = SupermaskConv\n",
        "            dense_layer = SupermaskLinear\n",
        "            additional_args = {'k': k}\n",
        "\n",
        "        self.conv1 = conv_layer(in_channels=channels_in, out_channels=16, kernel_size=3, stride=1, bias=True, **additional_args)\n",
        "        self.conv2 = conv_layer(in_channels=16, out_channels=32, kernel_size=3, stride=2, bias=True, **additional_args)\n",
        "        self.fc1 = dense_layer(in_features=flattened_shape, out_features=64, bias=True, **additional_args)\n",
        "        self.fc2 = dense_layer(in_features=64, out_features=3, bias=True, **additional_args)\n",
        "        self.fc3 = dense_layer(in_features=3, out_features=1, bias=True, **additional_args)\n",
        "        self.linear = nn.Linear(1, 1, bias=True)\n",
        "\n",
        "        self.qix = q_head_index\n",
        "        self.qu_mu_s = q_means_stds\n",
        "        self.use_last_linear = use_last_linear\n",
        "\n",
        "    def fwd_conv1(self, x):\n",
        "        x = self.conv1(x)\n",
        "        return F.relu(x)\n",
        "\n",
        "    def fwd_conv2(self, x):\n",
        "        x = self.fwd_conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        return F.relu(x)\n",
        "\n",
        "    def fwd_flat(self, x):\n",
        "        x = self.fwd_conv2(x)\n",
        "        return torch.flatten(torch.transpose(x, 1, 3), 1) # Pre-flattening transpose is necessary for TF-Torch conversion\n",
        "\n",
        "    def fwd_fc1(self, x):\n",
        "        x = self.fwd_flat(x)\n",
        "        x = self.fc1(x)\n",
        "        return F.relu(x)\n",
        "    \n",
        "    def fwd_fc2(self, x):\n",
        "        x = self.fwd_fc1(x)\n",
        "        return self.fc2(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fwd_fc2(x)\n",
        "\n",
        "        x -= torch.tensor(self.qu_mu_s[0], device=device)\n",
        "        x /= torch.tensor(self.qu_mu_s[1], device=device)\n",
        "\n",
        "        if self.qix == None:\n",
        "          x = self.fc3(x)\n",
        "        else:\n",
        "          x = x[: ,self.qix:self.qix+1]\n",
        "\n",
        "        if self.use_last_linear:\n",
        "          x = self.linear(x)\n",
        "\n",
        "        x = torch.sigmoid(x)\n",
        "        return x.flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIHGI0a71NVI",
        "colab_type": "text"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4htablfz1umt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run this cell for training with original RL Preference Extraction data\n",
        "if not params['use_mnist']:\n",
        "    all_raw_data = all_load_data(\"Preference_Extraction/data/simple_env_1/\")\n",
        "\n",
        "    activations = []\n",
        "    observations = []\n",
        "    preferences = []\n",
        "\n",
        "    for data in all_raw_data:\n",
        "        for i in range(data.observation.shape[0]):\n",
        "            observations.append(np.copy(data.observation[i]))\n",
        "            activations.append(np.copy(data.policy_info[\"activations\"][i]))\n",
        "            preferences.append((data.policy_info['satisfaction'].as_list()[i] > -6).astype(int))\n",
        "\n",
        "    activations = np.array(activations)\n",
        "\n",
        "    xs = np.rollaxis(np.array(observations), 3, 1) # Torch wants channel-first\n",
        "    ys = np.array(preferences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tLaYKbpSct4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run this cell for training with MNIST\n",
        "if params['use_mnist']:\n",
        "    tr_data_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('mnist', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])), batch_size=params['batch_size'], shuffle=True)\n",
        "\n",
        "    val_data_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('mnist', train=False, download=True, \n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])), batch_size=params['val_batch_size'], shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpSHf83VSgoJ",
        "colab_type": "text"
      },
      "source": [
        "## Loading Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD-16xFHSi5r",
        "colab_type": "code",
        "outputId": "6c42aa8e-4f32-4a1c-9cc0-5f3371886682",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "new_save_path = \"Preference_Extraction/saved_model2\"\n",
        "restored_model = tf.keras.models.load_model(new_save_path)\n",
        "restored_model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "EncodingNetwork/conv2d (Conv (None, 12, 14, 16)        736       \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/conv2d_1 (Co (None, 5, 6, 32)          4640      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 960)               0         \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/dense (Dense (None, 64)                61504     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 67,075\n",
            "Trainable params: 67,075\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB2G-FiUTmr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_weights=restored_model.get_weights()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qg-CpUoIqlUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_weights(model):\n",
        "    if not params['use_mnist']:\n",
        "        model.conv1.weight.data = torch.from_numpy(np.transpose(original_weights[0]))\n",
        "        model.fc1.weight.data = torch.from_numpy(np.transpose(original_weights[4]))\n",
        "    else:\n",
        "        model.conv1.weight.data = torch.from_numpy(np.transpose(original_weights[0][:,:,:1,:]))\n",
        "        mnist_flt_weights = np.random.rand(64, 4608)\n",
        "        mnist_flt_weights[:, :original_weights[4].shape[0]] = np.transpose(original_weights[4])\n",
        "        mnist_flt_weights = mnist_flt_weights.astype(np.float32)\n",
        "        model.fc1.weight.data = torch.from_numpy(mnist_flt_weights)\n",
        "\n",
        "    model.conv1.bias.data = torch.from_numpy(original_weights[1])\n",
        "    model.conv2.weight.data = torch.from_numpy(np.transpose(original_weights[2]))\n",
        "    model.conv2.bias.data = torch.from_numpy(original_weights[3])\n",
        "    model.fc1.bias.data = torch.from_numpy(original_weights[5])\n",
        "    model.fc2.weight.data = torch.from_numpy(np.transpose(original_weights[6]))\n",
        "    model.fc2.bias.data = torch.from_numpy(original_weights[7])\n",
        "    model.fc3.weight.data = torch.from_numpy(np.ones(shape=[1,3], dtype=np.float32))\n",
        "    model.fc3.bias.data = torch.from_numpy(np.zeros(shape=[1], dtype=np.float32))\n",
        "    model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwWx3ioNqhhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_model = PrefQNet(k=1, fine_tune=False, q_head_index=None, q_means_stds=[[0, 0, 0], [1, 1, 1]], use_last_linear=True).to(device)\n",
        "\n",
        "if params['use_qnet_weights']:\n",
        "    load_weights(test_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmX7Cyzes4Ct",
        "colab_type": "text"
      },
      "source": [
        "## Test the weights loaded properly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXsgEQuAUwha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Comparing that the models have identical observations for identical images\n",
        "tf_conv1_fn = tf.keras.models.Model(inputs=restored_model.input, outputs=restored_model.layers[0].output)\n",
        "tf_conv2_fn = tf.keras.models.Model(inputs=restored_model.input, outputs=restored_model.layers[1].output)\n",
        "tf_flt_fn = tf.keras.models.Model(inputs=restored_model.input, outputs=restored_model.layers[2].output)\n",
        "tf_fc1_fn = tf.keras.models.Model(inputs=restored_model.input, outputs=restored_model.layers[3].output)\n",
        "\n",
        "def npsigmoid(x):\n",
        "  return 1/(1 + np.exp(-x)) \n",
        "\n",
        "def check_same(torch_layer, tf_layer):\n",
        "    torch_out = np.transpose(torch_layer(single_observation_torch).detach().cpu().numpy())\n",
        "    torch_out = torch_out.reshape(torch_out.shape[:-1])\n",
        "    tf_out = tf_layer(single_observation)[0].numpy()\n",
        "    np.testing.assert_allclose(torch_out, tf_out, rtol=.1, atol=5)  \n",
        "\n",
        "# due to shape of original TF model this test can be done only when use_mnist = False\n",
        "if not params['use_mnist'] and params['use_qnet_weights']:\n",
        "    for i in range(len(all_raw_data[0].observation)):\n",
        "\n",
        "        single_observation = np.array([all_raw_data[0].observation[i]])\n",
        "        single_observation_torch = torch.Tensor(np.array([np.transpose(all_raw_data[0].observation[i])]))\n",
        "\n",
        "        single_observation_torch = single_observation_torch.to(device)\n",
        "\n",
        "        check_same(test_model.fwd_conv1, tf_conv1_fn)\n",
        "        check_same(test_model.fwd_conv2, tf_conv2_fn)\n",
        "        check_same(test_model.fwd_flat, tf_flt_fn)\n",
        "        check_same(test_model.fwd_flat, tf_flt_fn)\n",
        "\n",
        "        fc1_torch_out = np.transpose(test_model.fwd_fc1(single_observation_torch).detach().cpu().numpy())\n",
        "        fc1_torch_out = fc1_torch_out.reshape(fc1_torch_out.shape[:-1])\n",
        "        fc1_tf_out = tf_fc1_fn(single_observation)[0].numpy()\n",
        "        \n",
        "        np.testing.assert_allclose(fc1_torch_out, fc1_tf_out, rtol=.1, atol=5)\n",
        "        old_activations = all_raw_data[0].policy_info[\"activations\"][i]\n",
        "        np.testing.assert_allclose(fc1_torch_out, old_activations, rtol=.1, atol=5)\n",
        "        np.testing.assert_allclose(old_activations, fc1_tf_out, rtol=.1, atol=5)\n",
        "\n",
        "        check_same(test_model.fwd_fc2, restored_model)\n",
        "\n",
        "        torch_out = np.transpose(test_model.forward(single_observation_torch).detach().cpu().numpy())\n",
        "        torch_out = torch_out.reshape(torch_out.shape[:-1])\n",
        "        tf_out = npsigmoid(np.sum(restored_model(single_observation)[0].numpy()))\n",
        "        np.testing.assert_allclose(torch_out, tf_out, rtol=.1, atol=5)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WAEh60PtAFW",
        "colab_type": "text"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4DfkOECSppn",
        "colab_type": "text"
      },
      "source": [
        "### Get data to normalize qHeads"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbrjckDJn94C",
        "colab_type": "code",
        "outputId": "f6734362-394c-4368-eda4-7cc251b5113e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def get_q_heads_mu_and_sigma(model, all_obs, num_obs):\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    all_obs = shuffle(all_obs)\n",
        "    obs_to_pass = all_obs[:num_obs]\n",
        "\n",
        "    obs_tensor = torch.Tensor(obs_to_pass)\n",
        "    obs_tensor = obs_tensor.to(device)\n",
        "    qheads_values = model.fwd_fc2(obs_tensor).detach().cpu().numpy()\n",
        "\n",
        "    mu = qheads_values.mean(axis=0)\n",
        "    s = qheads_values.std(axis=0)\n",
        "\n",
        "    print(\"mu\", mu, \"s\", s)\n",
        "    \n",
        "    return np.array([mu, s])\n",
        "\n",
        "if params['use_mnist']:\n",
        "    img_batch, label = iter(tr_data_loader).next()\n",
        "    xs = img_batch\n",
        "\n",
        "q_mu_s = get_q_heads_mu_and_sigma(test_model, xs, 10000)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mu [ 92.74277   68.562965 138.47565 ] s [47.730503 51.27868  77.85427 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnfF0HPKKxC3",
        "colab_type": "text"
      },
      "source": [
        "### Methods to inspect performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inXU2W5VKr2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_number_of_new_scores_in_top_k(new_scores, old_scores, k):\n",
        "    new_top_k_scores = set(new_scores[:int(len(new_scores) * k)])\n",
        "    old_top_k_scores = set(old_scores[:int(len(old_scores) * k)])\n",
        "\n",
        "    return len(old_top_k_scores) - len(new_top_k_scores.intersection(old_top_k_scores))\n",
        "\n",
        "def model_scores_to_dict(model):\n",
        "    return {\n",
        "        'conv1': model.conv1.scores.detach().cpu().numpy().flatten().argsort(),\n",
        "        'conv2': model.conv2.scores.detach().cpu().numpy().flatten().argsort(),\n",
        "        'fc1': model.fc1.scores.detach().cpu().numpy().flatten().argsort(),\n",
        "        'fc2': model.fc2.scores.detach().cpu().numpy().flatten().argsort(),\n",
        "        'fc3': model.fc3.scores.detach().cpu().numpy().flatten().argsort()\n",
        "    }\n",
        "\n",
        "def get_no_of_changed_scores(model, previous_scores, k):\n",
        "\n",
        "    new_scores_idxs = model_scores_to_dict(model)\n",
        "\n",
        "    score_changes = {}\n",
        "\n",
        "    for score in new_scores_idxs:\n",
        "        changed_scores_num = get_number_of_new_scores_in_top_k(new_scores_idxs[score], previous_scores[score], k)\n",
        "        score_changes[score] = changed_scores_num\n",
        "\n",
        "    return score_changes, new_scores_idxs\n",
        "\n",
        "def plot_metric(results_dict, metric):\n",
        "    plt.title(metric)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.plot(list(range(1, params['num_epochs'] + 1)), results_dict[f'train{metric}'], label=f'Train {metric}')\n",
        "    plt.plot(list(range(1, params['num_epochs'] + 1)), results_dict[f'test{metric}'], label=f'Test {metric}')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def plot_metric_multiple_runs(results_items, metric, train=True):\n",
        "    plt.title(metric)\n",
        "    plt.xlabel('Epochs')\n",
        "    for res_key, res_dict in results_items.items():\n",
        "        if train:\n",
        "            plt.plot(list(range(1, params['num_epochs'] + 1)), res_dict[f'train{metric}'], label=f'Train {metric} - {res_key}')\n",
        "        else:\n",
        "            plt.plot(list(range(1, params['num_epochs'] + 1)), res_dict[f'test{metric}'], label=f'Test {metric} - {res_key}')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def plot_score_changes(score_changes_dict):\n",
        "    plt.title('Layer-wise score changes')\n",
        "    plt.xlabel('Optimisation steps (num_train / batch_size * epochs)')\n",
        "    for layer in score_changes_dict:\n",
        "        plt.plot(list(range(1, len(score_changes_dict[layer]) + 1)), score_changes_dict[layer], label=f'{layer}')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjzhnnt9UqBB",
        "colab_type": "text"
      },
      "source": [
        "### Method to get data for one sample run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv8Z2oPJb270",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data_sample(xs=None, ys=None):\n",
        "\n",
        "    if not params['use_mnist']:\n",
        "        xs, ys = shuffle(xs, ys)\n",
        "        \n",
        "        train_split = params['num_train']\n",
        "        tune_split = params['num_train']+params['num_tune']\n",
        "        test_split = params['num_train']+params['num_tune']+params['num_val']\n",
        "\n",
        "        tr_data_loader = torch.utils.data.DataLoader(\n",
        "            torch.utils.data.TensorDataset(torch.Tensor(xs[:train_split]), torch.Tensor(ys[:train_split])),\n",
        "            batch_size=params['batch_size'])\n",
        "\n",
        "        tune_data_loader = torch.utils.data.DataLoader(\n",
        "            torch.utils.data.TensorDataset(torch.Tensor(xs[train_split:tune_split]), torch.Tensor(ys[train_split:tune_split])),\n",
        "            batch_size=params['batch_size'])\n",
        "\n",
        "        val_data_loader = torch.utils.data.DataLoader(\n",
        "            torch.utils.data.TensorDataset(torch.Tensor(xs[tune_split:test_split]), torch.Tensor(ys[tune_split:test_split])),\n",
        "            batch_size=params['val_batch_size'])\n",
        "    else:\n",
        "        tr_data_loader = torch.utils.data.DataLoader(\n",
        "            datasets.MNIST('mnist', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])), batch_size=params['batch_size'], shuffle=True)\n",
        "\n",
        "        tune_data_loader = torch.utils.data.DataLoader(\n",
        "            datasets.MNIST('mnist', train=False, download=True, \n",
        "                        transform=transforms.Compose([\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize((0.1307,), (0.3081,))\n",
        "                        ])), batch_size=params['batch_size'], shuffle=True)\n",
        "\n",
        "        val_data_loader = torch.utils.data.DataLoader(\n",
        "            datasets.MNIST('mnist', train=False, download=True, \n",
        "                        transform=transforms.Compose([\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize((0.1307,), (0.3081,))\n",
        "                        ])), batch_size=params['val_batch_size'], shuffle=True)\n",
        "        \n",
        "    return tr_data_loader, tune_data_loader, val_data_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Th-WxNDGTKth",
        "colab_type": "text"
      },
      "source": [
        "### Single run train/test methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEj7Qn1-H-Es",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "    Train/Test function for Randomly Weighted Hidden Neural Networks Techniques\n",
        "    Adapted from https://github.com/NesterukSergey/hidden-networks/blob/master/demos/mnist.ipynb\n",
        "\"\"\"\n",
        "\n",
        "def metrics(predictions, true_labels):\n",
        "    predictions = np.array(predictions)\n",
        "    true_labels = np.array(true_labels)\n",
        "    accuracy = np.sum(np.equal((predictions > 0.5).astype(int), true_labels)) / len(true_labels)\n",
        "    auc = roc_auc_score(true_labels, predictions)\n",
        "    return accuracy, auc\n",
        "\n",
        "def train(model, k, device, train_loader, optimizer, criterion):\n",
        "    \n",
        "    train_loss = 0\n",
        "    true_labels = []\n",
        "    predictions = [] # labels\n",
        "\n",
        "    model.train()\n",
        "    train_score_changes = {}\n",
        "    if k is not None:\n",
        "        scores = model_scores_to_dict(model)\n",
        "        train_score_changes = {k: [] for k in scores}\n",
        "\n",
        "    for data, target in itertools.islice(train_loader, params['num_train']):\n",
        "        \n",
        "        data, target = data.to(device), target.to(device)\n",
        "        if params['use_mnist']:\n",
        "            target = (target > 0).float()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if k is not None:\n",
        "            score_changes, scores = get_no_of_changed_scores(model, scores, k)\n",
        "            for layer_changes in score_changes:\n",
        "                train_score_changes[layer_changes].append(score_changes[layer_changes])\n",
        "\n",
        "        train_loss += loss\n",
        "        predictions.extend(output.detach().cpu().numpy())\n",
        "        true_labels.extend(target.detach().cpu().numpy())\n",
        "    \n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    accuracy, auc = metrics(predictions, true_labels)\n",
        "\n",
        "    return train_loss.item(), accuracy, auc, train_score_changes\n",
        "\n",
        "\n",
        "def test(model, device, criterion, test_loader, num_test):\n",
        "    true_labels = []\n",
        "    predictions = [] # labels\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in itertools.islice(test_loader, num_test):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            if params['use_mnist']:\n",
        "                target = (target > 0).float()\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target)\n",
        "\n",
        "            predictions.extend(output.detach().cpu().numpy())\n",
        "            true_labels.extend(target.detach().cpu().numpy())\n",
        "    \n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy, auc = metrics(predictions, true_labels)\n",
        "\n",
        "    return test_loss.item(), accuracy, auc\n",
        "\n",
        "def run_model(model, k, learning_rate, weight_decay, num_epochs):\n",
        "\n",
        "  tr_data_loader, tune_data_loader, val_data_loader = get_data_sample(xs, ys)\n",
        "\n",
        "  optimizer = optim.Adam(\n",
        "      [p for p in model.parameters() if p.requires_grad],\n",
        "      lr=learning_rate,\n",
        "      weight_decay=weight_decay\n",
        "      \n",
        "  )\n",
        "\n",
        "  criterion = nn.BCELoss().to(device)\n",
        "  scheduler = CosineAnnealingLR(optimizer, len(tr_data_loader), eta_min=learning_rate)\n",
        "\n",
        "  train_losses = []\n",
        "  test_losses = []\n",
        "  tune_losses = []\n",
        "  train_accs = []\n",
        "  train_aucs = []\n",
        "  test_accs = []\n",
        "  test_aucs = []\n",
        "  score_changes = []\n",
        "  \n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      train_loss, train_accuracy, train_auc, train_score_changes = train(model, k, device, tr_data_loader, optimizer, criterion)\n",
        "      tune_loss, _, _ = test(model, device, criterion, tune_data_loader, params['num_tune'])\n",
        "      test_loss, test_accuracy, test_auc = test(model, device, criterion, val_data_loader, params['num_val'])\n",
        "      scheduler.step()\n",
        "\n",
        "      score_changes.append(train_score_changes)\n",
        "      train_losses.append(train_loss)\n",
        "      tune_losses.append(tune_loss)\n",
        "      test_losses.append(test_loss)\n",
        "      train_accs.append(train_accuracy)\n",
        "      train_aucs.append(train_auc)\n",
        "      test_accs.append(test_accuracy)\n",
        "      test_aucs.append(test_auc)\n",
        "\n",
        "  merged_score_changes = {k: [] for k in score_changes[0].keys()}\n",
        "  for d in score_changes:\n",
        "    for k in d:\n",
        "        merged_score_changes[k].extend(d[k])\n",
        "\n",
        "  return {'trainLoss': train_losses, 'testLoss': test_losses, 'tuneLoss': tune_losses,\n",
        "          'trainAccuracy': train_accs, 'testAccuracy': test_accs,\n",
        "          'trainAUC': train_aucs, 'testAUC': test_aucs, 'scoreChanges': merged_score_changes}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnOmDXPEU5x7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multi_runs(config, reporter):\n",
        "\n",
        "    averaged_results = {}\n",
        "    tuning_losses = []\n",
        "    for run_ix in range(params['num_run']):\n",
        "        if params['fine_tune']:\n",
        "            K = None\n",
        "        else:\n",
        "            K = config['k']\n",
        "\n",
        "        model = PrefQNet(fine_tune=params['fine_tune'], k=K, \n",
        "                         q_head_index=None, q_means_stds=q_mu_s, use_last_linear=True).to(device)\n",
        "\n",
        "        if params['use_qnet_weights']:\n",
        "            load_weights(model)\n",
        "        \n",
        "        results = run_model(model, K, config['lr'], config['decay'], num_epochs=params['num_epochs'])\n",
        "\n",
        "        if reporter is not None:  # Hyperp-tuning pass\n",
        "            tuning_losses.append(results['tuneLoss'][-1])\n",
        "            reporter(timesteps_total=run_ix, mean_loss=sum(tuning_losses)/len(tuning_losses))\n",
        "\n",
        "        else:  # Normal scoring pass\n",
        "            print(f'Train pass no. {run_ix+1}')\n",
        "            if run_ix == 0:\n",
        "                print('Debug charts for first training run')\n",
        "                plot_metric(results, 'Loss')\n",
        "                plot_metric(results, 'Accuracy')\n",
        "                plot_metric(results, 'AUC')\n",
        "\n",
        "            for val in results:\n",
        "                if len(results[val]) > 0 and val != 'scoreChanges':\n",
        "                    if val not in averaged_results:\n",
        "                        averaged_results[val] = [results[val][-1]]\n",
        "                    else:\n",
        "                        averaged_results[val].append(results[val][-1])            \n",
        "    \n",
        "    return {x: sum(averaged_results[x]) / params['num_run'] for x in averaged_results}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzVb5sW-U6Gs",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameters Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj4MIa8iZEf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def launch_tune():\n",
        "\n",
        "    space = {\n",
        "        \"k\": (0.05, 0.95), \n",
        "        \"lr\": (0.001, 0.1), \n",
        "        'decay': (0.0001, 0.05)\n",
        "    }\n",
        "\n",
        "    if params['fine_tune']:\n",
        "        space['k'] = (1, 1)\n",
        "\n",
        "    config = {\"num_samples\": params['num_tune_iters'], \"stop\": {\"timesteps_total\": params['num_run']}}\n",
        "\n",
        "    algo = BayesOptSearch(space, metric=\"mean_loss\", mode=\"min\", utility_kwargs={\n",
        "        \"kind\": \"ucb\", \"kappa\": 2.5, \"xi\": 0.0})\n",
        "\n",
        "    scheduler = AsyncHyperBandScheduler(metric=\"mean_loss\", mode=\"min\")\n",
        "\n",
        "    return tune.run(multi_runs, resources_per_trial={'gpu': 1, 'cpu': 2}, verbose=1, \n",
        "                    name=\"tune_exp\", search_alg=algo, scheduler=scheduler, **config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pyl2-zVvc8m",
        "colab_type": "text"
      },
      "source": [
        "### Subnetwork tune and get scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVKIdYlOvZpm",
        "colab_type": "code",
        "outputId": "6f30ca2f-00a5-4e06-a88b-4824c6fe6062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "# Note, with 10 runs, 100 epochs and 20 tuning iterations this can take up to 2 hrs\n",
        "params['num_run'] = 8\n",
        "params['num_epochs'] = 80\n",
        "params['num_tune_iters'] = 20\n",
        "params['fine_tune'] = False  # Flag for launching fine tuning or subnetwork search\n",
        "\n",
        "best_config = launch_tune().get_best_config(metric='mean_loss', mode='min')\n",
        "print('Parameters and best hyperparameters')\n",
        "print(params, best_config)\n",
        "multi_runs(best_config, None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 5.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: -0.08051539864391088 | Iter 1.000: -0.08044457621872425<br>Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.08 GiB heap, 0.0/2.44 GiB objects<br>Number of trials: 11 ({'TERMINATED': 1, 'RUNNING': 1, 'PENDING': 9})<br>Result logdir: /root/ray_results/tune_exp<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name         </th><th>ID      </th><th>status    </th><th>loc    </th><th style=\"text-align: right;\">    decay</th><th style=\"text-align: right;\">        lr</th><th style=\"text-align: right;\">       k</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     loss</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>multi_runs_20373a68</td><td>20373a68</td><td>TERMINATED</td><td>pid=459</td><td style=\"text-align: right;\">0.0209094</td><td style=\"text-align: right;\">0.00101132</td><td style=\"text-align: right;\">0.698292</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        138.94  </td><td style=\"text-align: right;\">0.087938 </td></tr>\n",
              "<tr><td>multi_runs_20b614f0</td><td>20b614f0</td><td>RUNNING   </td><td>pid=460</td><td style=\"text-align: right;\">0.0151864</td><td style=\"text-align: right;\">0.0101415 </td><td style=\"text-align: right;\">0.18208 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         63.9477</td><td style=\"text-align: right;\">0.0787526</td></tr>\n",
              "<tr><td>multi_runs_211efcf4</td><td>211efcf4</td><td>PENDING   </td><td>       </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td></tr>\n",
              "<tr><td>multi_runs_217832ec</td><td>217832ec</td><td>PENDING   </td><td>       </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td></tr>\n",
              "<tr><td>multi_runs_21d51142</td><td>21d51142</td><td>PENDING   </td><td>       </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td></tr>\n",
              "<tr><td>multi_runs_222ea9e6</td><td>222ea9e6</td><td>PENDING   </td><td>       </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td></tr>\n",
              "<tr><td>multi_runs_228cf366</td><td>228cf366</td><td>PENDING   </td><td>       </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td></tr>\n",
              "<tr><td>multi_runs_22e7c57a</td><td>22e7c57a</td><td>PENDING   </td><td>       </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td></tr>\n",
              "<tr><td>multi_runs_23472524</td><td>23472524</td><td>PENDING   </td><td>       </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td></tr>\n",
              "<tr><td>multi_runs_239debc0</td><td>239debc0</td><td>PENDING   </td><td>       </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td></tr>\n",
              "<tr><td>multi_runs_23f3c5c2</td><td>23f3c5c2</td><td>PENDING   </td><td>       </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td></tr>\n",
              "</tbody>\n",
              "</table><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmVclC7Cvpr7",
        "colab_type": "text"
      },
      "source": [
        "### Fine tune QNet and get scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf4vsrLQqwHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note, with 10 runs, 100 epochs and 20 tuning iterations this can take up to 2 hrs\n",
        "params['fine_tune'] = True  # Flag for launching fine tuning or subnetwork search\n",
        "\n",
        "best_config = launch_tune().get_best_config(metric='mean_loss', mode='min')\n",
        "print('Parameters and best hyperparameters')\n",
        "print(params, best_config)\n",
        "multi_runs(best_config, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4UmxuaQMS4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}