{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PreferenceNN_compiled.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arunraja-hub/Preference_Extraction/blob/master/PreferenceNN_compiled.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5gsIW7RSOkB",
        "colab_type": "code",
        "outputId": "50b011b0-c4f3-45a4-c466-40989092ed45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "!git clone https://github.com/arunraja-hub/Preference_Extraction.git\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Preference_Extraction'...\n",
            "remote: Enumerating objects: 142, done.\u001b[K\n",
            "remote: Counting objects: 100% (142/142), done.\u001b[K\n",
            "remote: Compressing objects: 100% (109/109), done.\u001b[K\n",
            "remote: Total 733 (delta 82), reused 37 (delta 31), pack-reused 591\u001b[K\n",
            "Receiving objects: 100% (733/733), 23.59 MiB | 16.95 MiB/s, done.\n",
            "Resolving deltas: 100% (120/120), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pipIvyqRz-qa",
        "colab_type": "code",
        "outputId": "b9e39147-17f5-4457-8f16-5c2a10e08b95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from google.colab import files\n",
        "import sys\n",
        "sys.path.append('Preference_Extraction')\n",
        "from imports_data import all_load_data\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "\n",
        "\n",
        "sns.set(style=\"white\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCXuaUj0Dn6H",
        "colab_type": "text"
      },
      "source": [
        "### Exploring each datapoint\n",
        "Each of the 475 datapoints is made up of the following 7 components of which we are only interested in observation,policy_info[\"activations\",\"satisfaction\"]\n",
        "\n",
        "        'step_type',\n",
        "        'observation',\n",
        "        'action',\n",
        "        'policy_info',\n",
        "        'next_step_type',\n",
        "        'reward',\n",
        "        'discount'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbpXyVzSzu1v",
        "colab_type": "code",
        "outputId": "8f828ec2-2240-4224-ab2c-28590c9ca231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "all_raw_data = all_load_data(\"Preference_Extraction/data/simple_env_1/\")\n",
        "print(len(all_raw_data))\n",
        "print(len(all_raw_data[0]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "475\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Tn-NC380t35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activations = []\n",
        "observations = []\n",
        "preferences = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO_3coxl1dki",
        "colab_type": "code",
        "outputId": "3643b14d-25d7-445e-d37c-11e035d4a1d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(all_raw_data[0].observation.shape)\n",
        "print(all_raw_data[0].policy_info[\"activations\"].shape)\n",
        "print(len(all_raw_data[0].policy_info[\"satisfaction\"].as_list()))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 14, 16, 5)\n",
            "(50, 64)\n",
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfgZs2rV1mSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load up data into arrays\n",
        "import numpy as np \n",
        "for data in all_raw_data:\n",
        "    for i in range(data.observation.shape[0]):\n",
        "        #data.observation.shape[0]=50\n",
        "        observations.append(np.copy(data.observation[i]))\n",
        "        activations.append(np.copy(data.policy_info[\"activations\"][i]))\n",
        "        preferences.append(data.policy_info['satisfaction'].as_list()[i])\n",
        "\n",
        "observations = np.array(observations)\n",
        "activations = np.array(activations)\n",
        "preferences = np.array(preferences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4ne7Iwg8CQw",
        "colab_type": "text"
      },
      "source": [
        "deep_NN_without_regularization.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwTp98Uf12fT",
        "colab_type": "code",
        "outputId": "57f44594-c7b6-49e1-9376-3fe9c74f50a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        }
      },
      "source": [
        "from lucid.misc.channel_reducer import ChannelReducer\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "!pip install tf-agents==0.3.0\n",
        "!pip uninstall tensorflow-probability -y\n",
        "!pip install tensorflow-probability==0.7.0\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "from tf_agents.trajectories.time_step import TimeStep\n",
        "from tf_agents.specs.tensor_spec import TensorSpec\n",
        "from tf_agents.specs.tensor_spec import TensorSpec\n",
        "from tf_agents.specs.tensor_spec import BoundedTensorSpec\n",
        "from tf_agents.networks import q_network\n",
        "\n",
        "import lucid.modelzoo.vision_models as models\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Collecting tf-agents==0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/a5/07aa82a3cd586d193b2f086b50a2fd0f48bd888ae204389f666eb178cfb3/tf_agents-0.3.0-py2.py3-none-any.whl (839kB)\n",
            "\u001b[K     |████████████████████████████████| 839kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-agents==0.3.0) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tf-agents==0.3.0) (1.18.4)\n",
            "Requirement already satisfied: tensorflow-probability>=0.6.0 in /tensorflow-1.15.2/python3.6 (from tf-agents==0.3.0) (0.7.0)\n",
            "Collecting gin-config==0.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/be/c984b1c8a7ba1c385b32bf39c7a225cd9f713d49705898309d01b60fd0e7/gin_config-0.1.3-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-agents==0.3.0) (1.12.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.6.0->tf-agents==0.3.0) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.6.0->tf-agents==0.3.0) (1.3.0)\n",
            "Installing collected packages: gin-config, tf-agents\n",
            "  Found existing installation: gin-config 0.3.0\n",
            "    Uninstalling gin-config-0.3.0:\n",
            "      Successfully uninstalled gin-config-0.3.0\n",
            "Successfully installed gin-config-0.1.3 tf-agents-0.3.0\n",
            "Uninstalling tensorflow-probability-0.7.0:\n",
            "  Successfully uninstalled tensorflow-probability-0.7.0\n",
            "Collecting tensorflow-probability==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/3a/c10b6c22320531c774402ac7186d1b673374e2a9d12502cbc8d811e4601c/tensorflow_probability-0.7.0-py2.py3-none-any.whl (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability==0.7.0) (1.3.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability==0.7.0) (4.4.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability==0.7.0) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability==0.7.0) (1.18.4)\n",
            "Installing collected packages: tensorflow-probability\n",
            "  Found existing installation: tensorflow-probability 0.10.0rc0\n",
            "    Uninstalling tensorflow-probability-0.10.0rc0:\n",
            "      Successfully uninstalled tensorflow-probability-0.10.0rc0\n",
            "Successfully installed tensorflow-probability-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggHQnGeNG8xq",
        "colab_type": "text"
      },
      "source": [
        "What is this checkpoint for?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN9eQBDt8G_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "cpt_name = \"Preference_Extraction/model_ckpt\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjwzLbvAHQsT",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "1.   Why are we resetting the graph here?\n",
        "2.   Why are the allowed values for action 0 and 2?     action_spec=((), tf.int32, 0, 2)-->(shape, data types, and allowed values of valid actions)\n",
        "3.    Why is the input_shape = [14, 16, 5]?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO1oKS6s8K9Y",
        "colab_type": "code",
        "outputId": "999247c1-8504-481d-dbf6-238518ac3e18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "input_shape = [14, 16, 5]\n",
        "\n",
        "my_input = tf.placeholder(tf.float32, shape=[None] + input_shape, name=\"my_input\")\n",
        "q_vals = q_network.QNetwork(input_tensor_spec=TensorSpec(shape=(14, 16, 5)), action_spec=BoundedTensorSpec((), tf.int32, 0, 2), conv_layer_params = [[16, 3, 1], [32, 3, 2]], fc_layer_params = [64])(my_input)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method QNetwork.call of <tf_agents.networks.q_network.QNetwork object at 0x7efddb197940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method EncodingNetwork.call of <tf_agents.networks.encoding_network.EncodingNetwork object at 0x7efddb197ac8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <bound method QNetwork.call of <tf_agents.networks.q_network.QNetwork object at 0x7efddb197940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method EncodingNetwork.call of <tf_agents.networks.encoding_network.EncodingNetwork object at 0x7efddb197ac8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axkKA_vn8Mpt",
        "colab_type": "code",
        "outputId": "34cea264-2019-4afc-be77-be17f8575a92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "cpt_var_info = tf.compat.v1.train.list_variables(cpt_name)\n",
        "print('cpt',cpt_var_info)\n",
        "cpt_var_info = [var for var in cpt_var_info if ((\"bias\" in var[0]) or (\"kernel\" in var[0])) and not (\"OPTIMIZER\" in var[0]) and not (\"_target_q_network\" in var[0])]\n",
        "shape_to_cpt_var_name = {tuple(var[1]): var[0] for var in cpt_var_info}\n",
        "\n",
        "current_vars = tf.get_collection(tf.GraphKeys.VARIABLES)\n",
        "shape_to_current_var_name = {tuple(var.get_shape().as_list()): var.name[:-2] for var in current_vars}\n",
        "\n",
        "var_name_to_prev_var_name = {}\n",
        "for shape in shape_to_current_var_name:\n",
        "  var_name_to_prev_var_name[shape_to_current_var_name[shape]] = shape_to_cpt_var_name[shape]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/util/decorator_utils.py:145: GraphKeys.VARIABLES (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.GraphKeys.GLOBAL_VARIABLES` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cpt [('_CHECKPOINTABLE_OBJECT_GRAPH', []), ('agent/_optimizer/beta1_power/.ATTRIBUTES/VARIABLE_VALUE', []), ('agent/_optimizer/beta2_power/.ATTRIBUTES/VARIABLE_VALUE', []), ('agent/_q_network/_encoder/_postprocessing_layers/0/bias/.ATTRIBUTES/VARIABLE_VALUE', [16]), ('agent/_q_network/_encoder/_postprocessing_layers/0/bias/.OPTIMIZER_SLOT/agent/_optimizer/m/.ATTRIBUTES/VARIABLE_VALUE', [16]), ('agent/_q_network/_encoder/_postprocessing_layers/0/bias/.OPTIMIZER_SLOT/agent/_optimizer/v/.ATTRIBUTES/VARIABLE_VALUE', [16]), ('agent/_q_network/_encoder/_postprocessing_layers/0/kernel/.ATTRIBUTES/VARIABLE_VALUE', [3, 3, 5, 16]), ('agent/_q_network/_encoder/_postprocessing_layers/0/kernel/.OPTIMIZER_SLOT/agent/_optimizer/m/.ATTRIBUTES/VARIABLE_VALUE', [3, 3, 5, 16]), ('agent/_q_network/_encoder/_postprocessing_layers/0/kernel/.OPTIMIZER_SLOT/agent/_optimizer/v/.ATTRIBUTES/VARIABLE_VALUE', [3, 3, 5, 16]), ('agent/_q_network/_encoder/_postprocessing_layers/1/bias/.ATTRIBUTES/VARIABLE_VALUE', [32]), ('agent/_q_network/_encoder/_postprocessing_layers/1/bias/.OPTIMIZER_SLOT/agent/_optimizer/m/.ATTRIBUTES/VARIABLE_VALUE', [32]), ('agent/_q_network/_encoder/_postprocessing_layers/1/bias/.OPTIMIZER_SLOT/agent/_optimizer/v/.ATTRIBUTES/VARIABLE_VALUE', [32]), ('agent/_q_network/_encoder/_postprocessing_layers/1/kernel/.ATTRIBUTES/VARIABLE_VALUE', [3, 3, 16, 32]), ('agent/_q_network/_encoder/_postprocessing_layers/1/kernel/.OPTIMIZER_SLOT/agent/_optimizer/m/.ATTRIBUTES/VARIABLE_VALUE', [3, 3, 16, 32]), ('agent/_q_network/_encoder/_postprocessing_layers/1/kernel/.OPTIMIZER_SLOT/agent/_optimizer/v/.ATTRIBUTES/VARIABLE_VALUE', [3, 3, 16, 32]), ('agent/_q_network/_encoder/_postprocessing_layers/3/bias/.ATTRIBUTES/VARIABLE_VALUE', [64]), ('agent/_q_network/_encoder/_postprocessing_layers/3/bias/.OPTIMIZER_SLOT/agent/_optimizer/m/.ATTRIBUTES/VARIABLE_VALUE', [64]), ('agent/_q_network/_encoder/_postprocessing_layers/3/bias/.OPTIMIZER_SLOT/agent/_optimizer/v/.ATTRIBUTES/VARIABLE_VALUE', [64]), ('agent/_q_network/_encoder/_postprocessing_layers/3/kernel/.ATTRIBUTES/VARIABLE_VALUE', [960, 64]), ('agent/_q_network/_encoder/_postprocessing_layers/3/kernel/.OPTIMIZER_SLOT/agent/_optimizer/m/.ATTRIBUTES/VARIABLE_VALUE', [960, 64]), ('agent/_q_network/_encoder/_postprocessing_layers/3/kernel/.OPTIMIZER_SLOT/agent/_optimizer/v/.ATTRIBUTES/VARIABLE_VALUE', [960, 64]), ('agent/_q_network/_q_value_layer/bias/.ATTRIBUTES/VARIABLE_VALUE', [3]), ('agent/_q_network/_q_value_layer/bias/.OPTIMIZER_SLOT/agent/_optimizer/m/.ATTRIBUTES/VARIABLE_VALUE', [3]), ('agent/_q_network/_q_value_layer/bias/.OPTIMIZER_SLOT/agent/_optimizer/v/.ATTRIBUTES/VARIABLE_VALUE', [3]), ('agent/_q_network/_q_value_layer/kernel/.ATTRIBUTES/VARIABLE_VALUE', [64, 3]), ('agent/_q_network/_q_value_layer/kernel/.OPTIMIZER_SLOT/agent/_optimizer/m/.ATTRIBUTES/VARIABLE_VALUE', [64, 3]), ('agent/_q_network/_q_value_layer/kernel/.OPTIMIZER_SLOT/agent/_optimizer/v/.ATTRIBUTES/VARIABLE_VALUE', [64, 3]), ('agent/_target_q_network/_encoder/_postprocessing_layers/0/bias/.ATTRIBUTES/VARIABLE_VALUE', [16]), ('agent/_target_q_network/_encoder/_postprocessing_layers/0/kernel/.ATTRIBUTES/VARIABLE_VALUE', [3, 3, 5, 16]), ('agent/_target_q_network/_encoder/_postprocessing_layers/1/bias/.ATTRIBUTES/VARIABLE_VALUE', [32]), ('agent/_target_q_network/_encoder/_postprocessing_layers/1/kernel/.ATTRIBUTES/VARIABLE_VALUE', [3, 3, 16, 32]), ('agent/_target_q_network/_encoder/_postprocessing_layers/3/bias/.ATTRIBUTES/VARIABLE_VALUE', [64]), ('agent/_target_q_network/_encoder/_postprocessing_layers/3/kernel/.ATTRIBUTES/VARIABLE_VALUE', [960, 64]), ('agent/_target_q_network/_q_value_layer/bias/.ATTRIBUTES/VARIABLE_VALUE', [3]), ('agent/_target_q_network/_q_value_layer/kernel/.ATTRIBUTES/VARIABLE_VALUE', [64, 3]), ('agent/_update_target/_counter/.ATTRIBUTES/VARIABLE_VALUE', []), ('global_step/.ATTRIBUTES/VARIABLE_VALUE', []), ('metrics/metrics/0/number_episodes/.ATTRIBUTES/VARIABLE_VALUE', []), ('metrics/metrics/1/environment_steps/.ATTRIBUTES/VARIABLE_VALUE', []), ('metrics/metrics/2/_return_accumulator/.ATTRIBUTES/VARIABLE_VALUE', [1]), ('metrics/metrics/3/_length_accumulator/.ATTRIBUTES/VARIABLE_VALUE', [1]), ('save_counter/.ATTRIBUTES/VARIABLE_VALUE', [])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwaeNBHf8ysX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.train.warm_start(cpt_name, var_name_to_prev_var_name=var_name_to_prev_var_name)\n",
        "init_op = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b7epJLn82Yy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_activations = []\n",
        "conv_activation_tensor = tf.get_default_graph().get_tensor_by_name(\n",
        "    \"QNetwork/EncodingNetwork/EncodingNetwork/conv2d/Relu:0\")\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init_op)\n",
        "\n",
        "  for img in observations:\n",
        "    conv_act = sess.run(conv_activation_tensor, {my_input: np.array([img])})[0]\n",
        "    conv_activations.append(conv_act)\n",
        "\n",
        "conv_activations = np.array(conv_activations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bxv9eqja86eH",
        "colab_type": "code",
        "outputId": "f4cc529f-85ff-4221-e336-ea041105a80e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print('Obs.shape', observations.shape)\n",
        "print('ConvAct.shape', conv_activations.shape)\n",
        "print('DensAct.shape', activations.shape)\n",
        "print('Pref.shape', preferences.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obs.shape (23750, 14, 16, 5)\n",
            "ConvAct.shape (23750, 12, 14, 16)\n",
            "DensAct.shape (23750, 64)\n",
            "Pref.shape (23750,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_vMlrmO9E-m",
        "colab_type": "code",
        "outputId": "a64137b0-e81a-4278-87c4-d53a285f0c18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import joblib\n",
        "joblib.dump(observations, 'obs.pkl')\n",
        "joblib.dump(conv_activations, 'convAct.pkl')\n",
        "joblib.dump(activations, 'densAct.pkl')\n",
        "joblib.dump(preferences, 'pref.pkl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pref.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko7MgXam9Inf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "observations = joblib.load('obs.pkl')\n",
        "conv_activations = joblib.load('convAct.pkl')\n",
        "activations = joblib.load('densAct.pkl')\n",
        "preferences = joblib.load('pref.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8XTVgnL_M9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xs_raw = []\n",
        "xs = []\n",
        "\n",
        "for conv_activation, activation in zip(conv_activations, activations):\n",
        "  xs_raw.append([conv_activation, [[activation]]])\n",
        "\n",
        "for element in xs_raw:\n",
        "  temp = []\n",
        "  for subelement in element:\n",
        "    for subsubelement in subelement:\n",
        "      for subsubsubelement in subsubelement:\n",
        "        for subsubsubsubelement in subsubsubelement:\n",
        "          temp.append(subsubsubsubelement)\n",
        "  temp = np.array(temp)\n",
        "  xs.append(temp)\n",
        "xs = np.array(xs)\n",
        "ys = (preferences > -6).astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oC5T7pNH_ZBQ",
        "colab_type": "code",
        "outputId": "77f4ba5d-5491-4d4c-fff6-f370c34235d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "xs.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23750, 2752)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbzlnb7l_jp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_val_auc(logs):\n",
        "      for key in logs:\n",
        "        if key.startswith('val_auc'):\n",
        "          return logs[key]\n",
        "\n",
        "class BestStats(tf.keras.callbacks.Callback):\n",
        "  \"\"\"A callback to keep track of the best val accuracy and auc seen so far.\"\"\"\n",
        "  def on_train_begin(self, logs):\n",
        "      self.bestMetric = -float('inf')\n",
        "      self.bestLogs = None\n",
        "      self.bestTrain = -float('inf')\n",
        "      self.num_epochs = 0\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    self.num_epochs += 1\n",
        "    self.bestTrain = max(self.bestTrain, logs.get('accuracy'))\n",
        "\n",
        "    val_accuracy = logs.get('val_accuracy')\n",
        "    if val_accuracy == None:\n",
        "      return \n",
        "\n",
        "    val_auc = get_val_auc(logs)\n",
        "    \n",
        "    metric = (val_accuracy + val_auc) / 2.0\n",
        "\n",
        "    if metric > self.bestMetric:\n",
        "      self.bestMetric = metric\n",
        "      self.bestLogs = logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rr77TrM_mSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try a different model that doesn't use convolutions and Flattens() the input at first\n",
        "\n",
        "def get_model(reg_amount, drop_rate, reduction_alg, n_components, model_name):\n",
        "  del reduction_alg, n_components\n",
        "  if model_name=='deepNNwoReg':\n",
        "\n",
        "    model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(256, activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(512, activation=\"relu\"),\n",
        "      tf.keras.layers.Dropout(drop_rate),\n",
        "      tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "    ])\n",
        "  if model_name=='deepNNwithReg':\n",
        "\n",
        "\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(256, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(512, activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(drop_rate),\n",
        "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(reg_amount)),\n",
        "      ])\n",
        "  if model_name=='conv':\n",
        "    model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, 2, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(reg_amount), input_shape=xs.shape[1:]),\n",
        "    tf.keras.layers.Conv2D(16, 1, activation='relu', strides=1, kernel_regularizer=tf.keras.regularizers.l2(reg_amount)),\n",
        "    tf.keras.layers.AveragePooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(drop_rate),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(reg_amount)),\n",
        "  ])\n",
        "\n",
        "\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(.01),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy',\n",
        "                        tf.keras.metrics.AUC()\n",
        "                        ],\n",
        "                )\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph2W7LYd_tnJ",
        "colab_type": "code",
        "outputId": "0812c3c5-4eef-40f1-c28f-78369b06392b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "use_activations = False\n",
        "\n",
        "drop_rate=[[.0,],[.2,]]\n",
        "model_names=[['deepNNwoReg'],['deepNNwithReg'], ['conv']]\n",
        "all_hparam_possibilities=[]\n",
        "for d in drop_rate:\n",
        "  for m in model_names:\n",
        "    dict_entry={\"drop_rate\": d, \"reg_amount\": [.0], 'reduction_alg': [None], 'n_components': [None], 'model_name': m}\n",
        "    all_hparam_possibilities.append(dict_entry)\n",
        "\n",
        "\n",
        "print(all_hparam_possibilities)\n",
        "# all_hparam_possibilities = [\n",
        "#     {\"drop_rate\": [.0,], \"reg_amount\": [.0], 'reduction_alg': [None], 'n_components': [None], 'model_name': ['deepNNwoReg']},\n",
        "#     {\"drop_rate\": [.2,], \"reg_amount\": [.0], 'reduction_alg': [None], 'n_components': [None],'model_name': ['deepNNwoReg']},\n",
        "#     {\"drop_rate\": [.2,], \"reg_amount\": [.0], 'reduction_alg': [None], 'n_components': [None],'model_name': ['deepNNwithReg']},\n",
        "#     {\"drop_rate\": [.2,], \"reg_amount\": [.0], 'reduction_alg': [None], 'n_components': [None],'model_name': ['deepNNwithReg']}]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'drop_rate': [0.0], 'reg_amount': [0.0], 'reduction_alg': [None], 'n_components': [None], 'model_name': ['deepNNwoReg']}, {'drop_rate': [0.0], 'reg_amount': [0.0], 'reduction_alg': [None], 'n_components': [None], 'model_name': ['deepNNwithReg']}, {'drop_rate': [0.0], 'reg_amount': [0.0], 'reduction_alg': [None], 'n_components': [None], 'model_name': ['conv']}, {'drop_rate': [0.2], 'reg_amount': [0.0], 'reduction_alg': [None], 'n_components': [None], 'model_name': ['deepNNwoReg']}, {'drop_rate': [0.2], 'reg_amount': [0.0], 'reduction_alg': [None], 'n_components': [None], 'model_name': ['deepNNwithReg']}, {'drop_rate': [0.2], 'reg_amount': [0.0], 'reduction_alg': [None], 'n_components': [None], 'model_name': ['conv']}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl05CcO0ARFx",
        "colab_type": "code",
        "outputId": "ad71bd53-660b-4f08-f959-a340741b3ae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import joblib\n",
        "import concurrent.futures\n",
        "import itertools\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import scipy\n",
        "from scipy import ndimage\n",
        "from sklearn import metrics\n",
        "from sklearn.utils import shuffle\n",
        "import io\n",
        "import collections\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuXBny-5_6DJ",
        "colab_type": "code",
        "outputId": "ad6dd5ed-fc99-4c1d-cee3-be8fc6c73113",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        }
      },
      "source": [
        "\n",
        "num_train = 50\n",
        "num_val = 1000\n",
        "epochs = 400\n",
        "print(\"use_activations:\", use_activations, \"num_train:\", num_train, \"epochs\", epochs)\n",
        "if num_train > 50:\n",
        "  print(\"More than 50 train data!!!!!!!!\")\n",
        "\n",
        "# each item in all_hparam_possibilities specifies valid hyper params to try. Put parameters that don't make sense together in separate lists.\n",
        "\n",
        "hparam_combinations = []\n",
        "for hparam_possibilities in all_hparam_possibilities:\n",
        "  hparam_keys, hparam_values = zip(*hparam_possibilities.items())\n",
        "  hparam_combinations.extend([dict(zip(hparam_keys, v)) for v in itertools.product(*hparam_values)])\n",
        "random.shuffle(hparam_combinations)\n",
        "print(\"len(hparam_combinations)\", len(hparam_combinations), \"hparam_combinations\", hparam_combinations)\n",
        "\n",
        "def modify_x_for_reduce(xs):\n",
        "  reshaped_x = np.reshape(xs, [xs.shape[0], -1])\n",
        "  # Make everything positive because some reductions don't work with negatives.\n",
        "  reshaped_x -= np.min(reshaped_x)\n",
        "  return reshaped_x\n",
        "\n",
        "def unsup_exstract(xs, reg_amount, drop_rate, layer_sizes, reduction_alg, n_components):\n",
        "  del reg_amount, drop_rate, layer_sizes\n",
        "\n",
        "  print(\"Using unsupervised feature extraction.\")\n",
        "\n",
        "  dim_reduct_model = ChannelReducer(reduction_alg=reduction_alg, n_components=n_components)\n",
        "  xs = dim_reduct_model.fit_transform(modify_x_for_reduce(xs))\n",
        "  return xs\n",
        "\n",
        "def train_best_logs(xs, ys, num_val, do_summary, hparams, get_model):\n",
        "  \"\"\"Trains the model and retruns the logs of the best epoch. randomly splits the train and val data before training.\"\"\"\n",
        "  tf.keras.backend.clear_session()\n",
        "  model = get_model(**hparams)\n",
        "  xs, ys = shuffle(xs, ys)\n",
        "\n",
        "  xs_val = xs[num_train:num_train+num_val]\n",
        "  ys_val = ys[num_train:num_train+num_val]\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, verbose=0)\n",
        "  best_stats = BestStats()\n",
        "  model.fit(xs[:num_train], ys[:num_train], epochs=epochs, batch_size=256, validation_freq=1, callbacks=[best_stats, early_stopping], validation_data=(xs_val, ys_val), verbose=0)\n",
        "  if do_summary:\n",
        "    model.summary()\n",
        "    print(\"best train accuracy:\", best_stats.bestTrain)\n",
        "    print(\"Number of epochs:\", best_stats.num_epochs)\n",
        "  return best_stats.bestLogs\n",
        "\n",
        "def multiple_train_ave(hparams):\n",
        "  \"\"\"Trains the model multiple times with the same parameters and returns the average metrics\"\"\"\n",
        "  start = time.time()\n",
        "  all_val_auc = []\n",
        "  all_val_accuracy = []\n",
        "\n",
        "  if hparams['reduction_alg'] != None:\n",
        "    xs_for_train = unsup_exstract(xs, **hparams)\n",
        "  else:\n",
        "    xs_for_train = xs\n",
        "\n",
        "  do_summary = True\n",
        "  for i in range(5):\n",
        "    logs = train_best_logs(xs_for_train, ys, num_val, do_summary, hparams, get_model)\n",
        "    all_val_auc.append(get_val_auc(logs))\n",
        "    all_val_accuracy.append(logs.get('val_accuracy'))\n",
        "    do_summary = False \n",
        "\n",
        "  mean_val_auc = np.mean(all_val_auc)\n",
        "  mean_val_accuracy = np.mean(all_val_accuracy)\n",
        "  metric = (mean_val_auc + mean_val_accuracy) / 2.0\n",
        "  print_data = (\"mean_val_auc\", mean_val_auc, \"mean_val_accuracy\", mean_val_accuracy, \"metric\", metric, \"val_auc_std\", np.std(all_val_auc), \"val_accuracy_std\", np.std(all_val_accuracy))\n",
        "\n",
        "  end = time.time()\n",
        "  print(\"Seconds per hyperparam config\", end - start)\n",
        "  # GPU: ('Seconds per hyperparam config', 16.970870971679688)\n",
        "\n",
        "  return metric, print_data\n",
        "\n",
        "best_metric = -float('inf')\n",
        "\n",
        "run_num = 0\n",
        "for hparams in hparam_combinations:\n",
        "  print(\"hparams\", hparams)\n",
        "\n",
        "  metric, print_data = multiple_train_ave(hparams)\n",
        "\n",
        "  print(print_data)\n",
        "  if metric > best_metric:\n",
        "    best_metric = metric\n",
        "    best_print_data = print_data\n",
        "    best_hparams = hparams\n",
        "\n",
        "  run_num += 1\n",
        "  print(\"fract done\", run_num/float(len(hparam_combinations)))\n",
        "  print\n",
        "  print(\"==============================================================================================\")\n",
        "  print\n",
        "  sys.stdout.flush()\n",
        "\n",
        "  print(\"best_hparams\", best_hparams)\n",
        "  print(\"best results\", best_print_data)\n",
        "  print(\"Retraining on the best_hparams to make sure we didn't just get good results by random chance.\")\n",
        "\n",
        "  _, print_data = multiple_train_ave(best_hparams)\n",
        "  print(\"Result of retrain on the best hyperparameters\", print_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "use_activations: False num_train: 50 epochs 400\n",
            "len(hparam_combinations) 6 hparam_combinations [{'drop_rate': 0.0, 'reg_amount': 0.0, 'reduction_alg': None, 'n_components': None, 'model_name': 'deepNNwithReg'}, {'drop_rate': 0.2, 'reg_amount': 0.0, 'reduction_alg': None, 'n_components': None, 'model_name': 'conv'}, {'drop_rate': 0.0, 'reg_amount': 0.0, 'reduction_alg': None, 'n_components': None, 'model_name': 'conv'}, {'drop_rate': 0.0, 'reg_amount': 0.0, 'reduction_alg': None, 'n_components': None, 'model_name': 'deepNNwoReg'}, {'drop_rate': 0.2, 'reg_amount': 0.0, 'reduction_alg': None, 'n_components': None, 'model_name': 'deepNNwoReg'}, {'drop_rate': 0.2, 'reg_amount': 0.0, 'reduction_alg': None, 'n_components': None, 'model_name': 'deepNNwithReg'}]\n",
            "hparams {'drop_rate': 0.0, 'reg_amount': 0.0, 'reduction_alg': None, 'n_components': None, 'model_name': 'deepNNwithReg'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-07a8e0e96872>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hparams\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m   \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiple_train_ave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-07a8e0e96872>\u001b[0m in \u001b[0;36mmultiple_train_ave\u001b[0;34m(hparams)\u001b[0m\n\u001b[1;32m     61\u001b[0m   \u001b[0mdo_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_best_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs_for_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mall_val_auc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_val_auc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mall_val_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-07a8e0e96872>\u001b[0m in \u001b[0;36mtrain_best_logs\u001b[0;34m(xs, ys, num_val, do_summary, hparams, get_model)\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0mbest_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBestStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_stats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdo_summary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m       \u001b[0;31m# Epochs only apply to `fit`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m     \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-80d88059b1d6>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbestTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbestTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'NoneType' and 'float'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57zxxQWo_9kh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}