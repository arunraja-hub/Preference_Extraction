{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pref_extract_from_reduce.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOgnBUqfYq7hmbM6dJ491n9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arunraja-hub/Preference_Extraction/blob/master/pref_extract_from_reduce.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d30Y6Tjy9j89",
        "colab_type": "text"
      },
      "source": [
        "Uses the reduction from the rl util to infer human preferences. **Run the use_rl_util.ipynb notebook before this one** to get the reduction saved in your drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYEIvaw755Ou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import joblib\n",
        "import os\n",
        "import itertools\n",
        "import random\n",
        "import time\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9FqWdiv6drn",
        "colab_type": "code",
        "outputId": "ad42aae7-f94e-485a-c32c-2cad44485b19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8Xdv5Sv6rXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = '/content/drive/My Drive/pref_extract_files/'\n",
        "ys = joblib.load(os.path.join(file_path, 'ys.pkl'))\n",
        "observations = joblib.load(os.path.join(file_path, 'observations.pkl'))\n",
        "dense_activations = joblib.load(os.path.join(file_path, 'dense_activations.pkl'))\n",
        "conv_reduced = joblib.load(os.path.join(file_path, 'reduced_train_attri_opt_act.pkl'))\n",
        "# xs = joblib.load(os.path.join(file_path, 'reduced_train_act_opt_act.pkl'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geB-dPGnrW_A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bc778fc5-b701-4da7-dc3a-7356672a62a3"
      },
      "source": [
        "print(dense_activations.shape)\n",
        "print(conv_reduced.shape)\n",
        "\n",
        "xs = []\n",
        "for conv_reduce, dense_activation in zip(conv_reduced, dense_activations):\n",
        "  xs.append([conv_reduce, dense_activation])\n",
        "\n",
        "# xs = np.array(xs)\n",
        "\n",
        "# print(xs.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4000, 64)\n",
            "(4000, 12, 14, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUuEUk_G65pi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_val_auc(logs):\n",
        "      for key in logs:\n",
        "        if key.startswith('val_auc'):\n",
        "          return logs[key]\n",
        "\n",
        "class BestStats(tf.keras.callbacks.Callback):\n",
        "  \"\"\"A callback to keep track of the best val accuracy and auc seen so far.\"\"\"\n",
        "  def on_train_begin(self, logs):\n",
        "      self.bestMetric = -float('inf')\n",
        "      self.bestLogs = None\n",
        "      self.bestTrain = -float('inf')\n",
        "      self.num_epochs = 0\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    self.num_epochs += 1\n",
        "    self.bestTrain = max(self.bestTrain, logs.get('accuracy'))\n",
        "\n",
        "    val_accuracy = logs.get('val_accuracy')\n",
        "    if val_accuracy == None:\n",
        "      return \n",
        "\n",
        "    val_auc = get_val_auc(logs)\n",
        "    \n",
        "    metric = (val_accuracy + val_auc) / 2.0\n",
        "\n",
        "    if metric > self.bestMetric:\n",
        "      self.bestMetric = metric\n",
        "      self.bestLogs = logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2cuwyUg7Sss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(reg_amount, drop_rate, do_ave_pool, conv_layer_params, fc_layer_sizes, reduction_alg, n_components):\n",
        "  del reduction_alg, n_components\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    conv_layer_params: Optional list of convolution layers parameters, where\n",
        "      each item is either a length-three tuple indicating\n",
        "      `(filters, kernel_size, stride)`.\n",
        "      \"\"\"\n",
        "\n",
        "  conv_model = tf.keras.models.Sequential()\n",
        "\n",
        "  for config in conv_layer_params:\n",
        "    (filters, kernel_size, strides) = config\n",
        "    conv_model.add(\n",
        "        tf.keras.layers.Conv2D(\n",
        "            filters=filters,\n",
        "            kernel_size=kernel_size,\n",
        "            strides=strides,\n",
        "            activation='relu',\n",
        "            ))\n",
        "  if do_ave_pool:\n",
        "    conv_model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "  conv_model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "  dense_model = tf.keras.models.Sequential(name='output')\n",
        "  for layer_size in fc_layer_sizes:\n",
        "    dense_model.add(tf.keras.layers.Dense(layer_size, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(reg_amount)))\n",
        "    dense_model.add(tf.keras.layers.Dropout(drop_rate))\n",
        "  dense_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  img_input = tf.keras.layers.Input(shape=(12, 14, 6), name='img_input')\n",
        "  conv_output = conv_model(img_input)\n",
        "  \n",
        "  dense_input = tf.keras.layers.Input(shape=[64], name='dense_input')\n",
        "  combined_input = tf.keras.layers.concatenate([conv_output, dense_input])\n",
        "  output = dense_model(combined_input)\n",
        "\n",
        "  model = tf.keras.models.Model(inputs=[img_input, dense_input], outputs=[output])\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(.01),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy', tf.keras.metrics.AUC()],\n",
        "                )\n",
        "  return model\n",
        "\n",
        "all_hparam_possibilities = [\n",
        "    {\"do_ave_pool\": [0, 1], \"conv_layer_params\": [((16, 3, 1),),  ((32, 3, 1), (16, 3, 2))], \"reg_amount\": [.1, .5, 1], \"drop_rate\": [0.0, .2, .4], \"fc_layer_sizes\": [(16,), (32,16),], 'reduction_alg': [None], 'n_components': [None]},\n",
        "]\n",
        "\n",
        "use_activations = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpJ1xtu-7V9B",
        "colab_type": "code",
        "outputId": "9e1b3fad-81c0-4a8b-9857-b3dd17dd53e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_train = 50\n",
        "num_val = 1000\n",
        "epochs = 400\n",
        "print(\"use_activations:\", use_activations, \"num_train:\", num_train, \"epochs\", epochs)\n",
        "if num_train > 50:\n",
        "  print(\"More than 50 train data!!!!!!!!\")\n",
        "\n",
        "# each item in all_hparam_possibilities specifies valid hyper params to try. Put parameters that don't make sense together in separate lists.\n",
        "\n",
        "hparam_combinations = []\n",
        "for hparam_possibilities in all_hparam_possibilities:\n",
        "  hparam_keys, hparam_values = zip(*hparam_possibilities.items())\n",
        "  hparam_combinations.extend([dict(zip(hparam_keys, v)) for v in itertools.product(*hparam_values)])\n",
        "random.shuffle(hparam_combinations)\n",
        "print(\"len(hparam_combinations)\", len(hparam_combinations), \"hparam_combinations\", hparam_combinations)\n",
        "\n",
        "def modify_x_for_reduce(xs):\n",
        "  reshaped_x = np.reshape(xs, [xs.shape[0], -1])\n",
        "  # Make everything positive because some reductions don't work with negatives.\n",
        "  reshaped_x -= np.min(reshaped_x)\n",
        "  return reshaped_x\n",
        "\n",
        "def unsup_exstract(xs, reg_amount, drop_rate, layer_sizes, reduction_alg, n_components):\n",
        "  del reg_amount, drop_rate, layer_sizes\n",
        "\n",
        "  print(\"Using unsupervised feature extraction.\")\n",
        "\n",
        "  dim_reduct_model = ChannelReducer(reduction_alg=reduction_alg, n_components=n_components)\n",
        "  xs = dim_reduct_model.fit_transform(modify_x_for_reduce(xs))\n",
        "  return xs\n",
        "\n",
        "def convert_np(lst, i):\n",
        "  result = []\n",
        "  for x in lst:\n",
        "    result.append(x[i])\n",
        "  return np.asarray(result)\n",
        "\n",
        "def convert_xs(xs):\n",
        "  return {'img_input': convert_np(xs, 0), 'dense_input': convert_np(xs, 1)}\n",
        "\n",
        "def train_best_logs(xs, ys, num_val, do_summary, hparams, get_model):\n",
        "  \"\"\"Trains the model and retruns the logs of the best epoch. randomly splits the train and val data before training.\"\"\"\n",
        "  tf.keras.backend.clear_session()\n",
        "  model = get_model(**hparams)\n",
        "  xs, ys = shuffle(xs, ys)\n",
        "\n",
        "  xs_val = xs[num_train:num_train+num_val]\n",
        "  ys_val = ys[num_train:num_train+num_val]\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, verbose=0)\n",
        "  best_stats = BestStats()\n",
        "  model.fit(convert_xs(xs[:num_train]), ys[:num_train], epochs=epochs, batch_size=256, validation_freq=1, callbacks=[best_stats, early_stopping], validation_data=(convert_xs(xs_val), ys_val), verbose=0)\n",
        "  if do_summary:\n",
        "    model.summary()\n",
        "    print(\"best train accuracy:\", best_stats.bestTrain)\n",
        "    print(\"Number of epochs:\", best_stats.num_epochs)\n",
        "  return best_stats.bestLogs\n",
        "\n",
        "def multiple_train_ave(hparams):\n",
        "  \"\"\"Trains the model multiple times with the same parameters and returns the average metrics\"\"\"\n",
        "  start = time.time()\n",
        "  all_val_auc = []\n",
        "  all_val_accuracy = []\n",
        "\n",
        "  if hparams['reduction_alg'] != None:\n",
        "    xs_for_train = unsup_exstract(xs, **hparams)\n",
        "  else:\n",
        "    xs_for_train = xs\n",
        "\n",
        "  do_summary = True\n",
        "  for i in range(5):\n",
        "    logs = train_best_logs(xs_for_train, ys, num_val, do_summary, hparams, get_model)\n",
        "    all_val_auc.append(get_val_auc(logs))\n",
        "    all_val_accuracy.append(logs.get('val_accuracy'))\n",
        "    do_summary = False \n",
        "\n",
        "  mean_val_auc = np.mean(all_val_auc)\n",
        "  mean_val_accuracy = np.mean(all_val_accuracy)\n",
        "  metric = (mean_val_auc + mean_val_accuracy) / 2.0\n",
        "  print_data = (\"mean_val_auc\", mean_val_auc, \"mean_val_accuracy\", mean_val_accuracy, \"metric\", metric, \"val_auc_std\", np.std(all_val_auc), \"val_accuracy_std\", np.std(all_val_accuracy))\n",
        "\n",
        "  end = time.time()\n",
        "  print(\"Seconds per hyperparam config\", end - start)\n",
        "  # GPU: ('Seconds per hyperparam config', 16.970870971679688)\n",
        "\n",
        "  return metric, print_data\n",
        "\n",
        "best_metric = -float('inf')\n",
        "\n",
        "run_num = 0\n",
        "for hparams in hparam_combinations:\n",
        "  print(\"hparams\", hparams)\n",
        "\n",
        "  metric, print_data = multiple_train_ave(hparams)\n",
        "\n",
        "  print(print_data)\n",
        "  if metric > best_metric:\n",
        "    best_metric = metric\n",
        "    best_print_data = print_data\n",
        "    best_hparams = hparams\n",
        "\n",
        "  run_num += 1\n",
        "  print(\"fract done\", run_num/float(len(hparam_combinations)))\n",
        "  print\n",
        "  print(\"==============================================================================================\")\n",
        "  print\n",
        "  sys.stdout.flush()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "use_activations: False num_train: 50 epochs 400\n",
            "len(hparam_combinations) 72 hparam_combinations [{'do_ave_pool': 1, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 1, 'drop_rate': 0.4, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 0.5, 'drop_rate': 0.2, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 0.5, 'drop_rate': 0.0, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 1, 'drop_rate': 0.2, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 1, 'drop_rate': 0.4, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 0.5, 'drop_rate': 0.2, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 0.1, 'drop_rate': 0.4, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 1, 'drop_rate': 0.0, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 1, 'drop_rate': 0.4, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 0.1, 'drop_rate': 0.4, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 0.1, 'drop_rate': 0.2, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 1, 'drop_rate': 0.4, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 0.5, 'drop_rate': 0.2, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 1, 'drop_rate': 0.4, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 0.1, 'drop_rate': 0.4, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 0.5, 'drop_rate': 0.4, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 0.5, 'drop_rate': 0.4, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 0.5, 'drop_rate': 0.2, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 0.1, 'drop_rate': 0.0, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 0.5, 'drop_rate': 0.2, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 0.5, 'drop_rate': 0.4, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 0.1, 'drop_rate': 0.0, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 0.1, 'drop_rate': 0.2, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 1, 'drop_rate': 0.2, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 1, 'drop_rate': 0.0, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 0.5, 'drop_rate': 0.0, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 1, 'drop_rate': 0.0, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 1, 'drop_rate': 0.0, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 0.1, 'drop_rate': 0.4, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 0.1, 'drop_rate': 0.2, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 0.1, 'drop_rate': 0.2, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 0.5, 'drop_rate': 0.4, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 0.5, 'drop_rate': 0.0, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 0.5, 'drop_rate': 0.4, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 0.1, 'drop_rate': 0.0, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 1, 'drop_rate': 0.4, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 0.5, 'drop_rate': 0.0, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 0.1, 'drop_rate': 0.0, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 0.1, 'drop_rate': 0.0, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 0.5, 'drop_rate': 0.0, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 0.5, 'drop_rate': 0.0, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 1, 'drop_rate': 0.0, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 1, 'drop_rate': 0.2, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 0.5, 'drop_rate': 0.2, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 0.5, 'drop_rate': 0.4, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 1, 'drop_rate': 0.0, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 0.1, 'drop_rate': 0.4, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 0.5, 'drop_rate': 0.4, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 0.5, 'drop_rate': 0.2, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 0.1, 'drop_rate': 0.2, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 0.5, 'drop_rate': 0.2, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 1, 'drop_rate': 0.0, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 1, 'drop_rate': 0.2, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 0.1, 'drop_rate': 0.4, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 0.1, 'drop_rate': 0.0, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 0.5, 'drop_rate': 0.0, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 0.5, 'drop_rate': 0.0, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 0.1, 'drop_rate': 0.2, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 1, 'drop_rate': 0.2, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 0.1, 'drop_rate': 0.4, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 0.5, 'drop_rate': 0.4, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 0.1, 'drop_rate': 0.4, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 1, 'drop_rate': 0.2, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 1, 'drop_rate': 0.0, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 0.1, 'drop_rate': 0.0, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 1, 'drop_rate': 0.4, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 0.1, 'drop_rate': 0.0, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 1, 'drop_rate': 0.2, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 1, 'drop_rate': 0.2, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 1, 'drop_rate': 0.4, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 0, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 0.1, 'drop_rate': 0.2, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}, {'do_ave_pool': 1, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 0.1, 'drop_rate': 0.2, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}]\n",
            "hparams {'do_ave_pool': 1, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 1, 'drop_rate': 0.4, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "img_input (InputLayer)          [(None, 12, 14, 6)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, 16)           880         img_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_input (InputLayer)        [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 80)           0           sequential[0][0]                 \n",
            "                                                                 dense_input[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "output (Sequential)             (None, 1)            3137        concatenate[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 4,017\n",
            "Trainable params: 4,017\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "best train accuracy: 0.9800000190734863\n",
            "Number of epochs: 122\n",
            "Seconds per hyperparam config 60.439990520477295\n",
            "('mean_val_auc', 0.8880589485168457, 'mean_val_accuracy', 0.8343999981880188, 'metric', 0.8612294733524323, 'val_auc_std', 0.024399450718634984, 'val_accuracy_std', 0.02490461361361681)\n",
            "fract done 0.013888888888888888\n",
            "==============================================================================================\n",
            "hparams {'do_ave_pool': 1, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 0.5, 'drop_rate': 0.2, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "img_input (InputLayer)          [(None, 12, 14, 6)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, 16)           6384        img_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_input (InputLayer)        [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 80)           0           sequential[0][0]                 \n",
            "                                                                 dense_input[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "output (Sequential)             (None, 1)            3137        concatenate[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 9,521\n",
            "Trainable params: 9,521\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "best train accuracy: 1.0\n",
            "Number of epochs: 113\n",
            "Seconds per hyperparam config 43.81689977645874\n",
            "('mean_val_auc', 0.9023842453956604, 'mean_val_accuracy', 0.8473999857902527, 'metric', 0.8748921155929565, 'val_auc_std', 0.01727508658097858, 'val_accuracy_std', 0.019895720331269382)\n",
            "fract done 0.027777777777777776\n",
            "==============================================================================================\n",
            "hparams {'do_ave_pool': 0, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 0.5, 'drop_rate': 0.0, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "img_input (InputLayer)          [(None, 12, 14, 6)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, 1920)         880         img_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_input (InputLayer)        [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 1984)         0           sequential[0][0]                 \n",
            "                                                                 dense_input[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "output (Sequential)             (None, 1)            64065       concatenate[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 64,945\n",
            "Trainable params: 64,945\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "best train accuracy: 1.0\n",
            "Number of epochs: 132\n",
            "Seconds per hyperparam config 36.458844900131226\n",
            "('mean_val_auc', 0.8826945900917054, 'mean_val_accuracy', 0.8269999980926513, 'metric', 0.8548472940921783, 'val_auc_std', 0.028325863522283803, 'val_accuracy_std', 0.01887856753152961)\n",
            "fract done 0.041666666666666664\n",
            "==============================================================================================\n",
            "hparams {'do_ave_pool': 1, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 1, 'drop_rate': 0.2, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "img_input (InputLayer)          [(None, 12, 14, 6)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, 16)           880         img_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_input (InputLayer)        [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 80)           0           sequential[0][0]                 \n",
            "                                                                 dense_input[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "output (Sequential)             (None, 1)            3137        concatenate[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 4,017\n",
            "Trainable params: 4,017\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "best train accuracy: 0.9399999976158142\n",
            "Number of epochs: 223\n",
            "Seconds per hyperparam config 53.08570098876953\n",
            "('mean_val_auc', 0.9036925077438355, 'mean_val_accuracy', 0.8456000089645386, 'metric', 0.874646258354187, 'val_auc_std', 0.008886561522057253, 'val_accuracy_std', 0.01730432934696322)\n",
            "fract done 0.05555555555555555\n",
            "==============================================================================================\n",
            "hparams {'do_ave_pool': 0, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 1, 'drop_rate': 0.4, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "img_input (InputLayer)          [(None, 12, 14, 6)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, 320)          6384        img_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_input (InputLayer)        [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 384)          0           sequential[0][0]                 \n",
            "                                                                 dense_input[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "output (Sequential)             (None, 1)            12865       concatenate[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 19,249\n",
            "Trainable params: 19,249\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "best train accuracy: 0.9599999785423279\n",
            "Number of epochs: 99\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2327\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2328\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2329\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'range/start' has no attr named '_read_only_resource_inputs'.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-dc6f73a36e0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hparams\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m   \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiple_train_ave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-dc6f73a36e0a>\u001b[0m in \u001b[0;36mmultiple_train_ave\u001b[0;34m(hparams)\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0mdo_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_best_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs_for_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mall_val_auc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_val_auc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mall_val_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-dc6f73a36e0a>\u001b[0m in \u001b[0;36mtrain_best_logs\u001b[0;34m(xs, ys, num_val, do_summary, hparams, get_model)\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0mbest_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBestStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_stats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdo_summary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    873\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m    876\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1058\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m           model=self)\n\u001b[0m\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;31m# trigger the next permutation. On the other hand, too many simultaneous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;31m# shuffles can contend on a hardware level and degrade all performance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1619\u001b[0m     \"\"\"\n\u001b[1;32m   1620\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1622\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m       return ParallelMapDataset(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   3972\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3973\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3974\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   3975\u001b[0m     variant_tensor = gen_dataset_ops.map_dataset(\n\u001b[1;32m   3976\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3219\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3220\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2530\u001b[0m     \"\"\"\n\u001b[1;32m   2531\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 2532\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2533\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2534\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2494\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2495\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2496\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2497\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         if x is not None)\n\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m     \u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0madd_control_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, unused_type, unused_value, unused_traceback)\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0;31m# Check for any resource inputs. If we find any, we update control_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0;31m# and last_write_to_resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_get_resource_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mis_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresource_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mResourceType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_ONLY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0minput_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36m_get_resource_inputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_resource_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;34m\"\"\"Returns an iterable of resources touched by this `op`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   \u001b[0mreads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrites\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_read_write_resource_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m   \u001b[0msaturated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msaturated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/auto_control_deps_utils.py\u001b[0m in \u001b[0;36mget_read_write_resource_inputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mread_only_input_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREAD_ONLY_RESOURCE_INPUTS_ATTR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m# Attr was not set. Add all resource inputs to `writes` and return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2328\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2329\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2330\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHbqZtL4c_v9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "8eae0be3-4e5e-4bf3-bd36-d7292b026101"
      },
      "source": [
        "print(\"best_hparams\", best_hparams)\n",
        "print(\"best results\", best_print_data)\n",
        "print(\"Retraining on the best_hparams to make sure we didn't just get good results by random chance.\")\n",
        "\n",
        "_, print_data = multiple_train_ave(best_hparams)\n",
        "print(\"Result of retrain on the best hyperparameters\", print_data)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best_hparams {'do_ave_pool': 1, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 0.5, 'drop_rate': 0.2, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}\n",
            "best results ('mean_val_auc', 0.9023842453956604, 'mean_val_accuracy', 0.8473999857902527, 'metric', 0.8748921155929565, 'val_auc_std', 0.01727508658097858, 'val_accuracy_std', 0.019895720331269382)\n",
            "Retraining on the best_hparams to make sure we didn't just get good results by random chance.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "img_input (InputLayer)          [(None, 12, 14, 6)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, 16)           6384        img_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_input (InputLayer)        [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 80)           0           sequential[0][0]                 \n",
            "                                                                 dense_input[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "output (Sequential)             (None, 1)            3137        concatenate[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 9,521\n",
            "Trainable params: 9,521\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "best train accuracy: 0.9800000190734863\n",
            "Number of epochs: 153\n",
            "Seconds per hyperparam config 37.09010553359985\n",
            "Result of retrain on the best hyperparameters ('mean_val_auc', 0.8900781273841858, 'mean_val_accuracy', 0.8314000010490418, 'metric', 0.8607390642166137, 'val_auc_std', 0.011880057467416237, 'val_accuracy_std', 0.015160480881220188)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FNKIjaxhw_g",
        "colab_type": "text"
      },
      "source": [
        "Results:\n",
        "\n",
        "on reduced_train_attri_opt_act and dense:\n",
        "```\n",
        "best_hparams {'do_ave_pool': 0, 'conv_layer_params': ((32, 3, 1), (16, 3, 2)), 'reg_amount': 1, 'drop_rate': 0.0, 'fc_layer_sizes': (32, 16), 'reduction_alg': None, 'n_components': None}\n",
        "best results ('mean_val_auc', 0.9136462450027466, 'mean_val_accuracy', 0.8553999900817871, 'metric', 0.8845231175422669, 'val_auc_std', 0.013748590940144823, 'val_accuracy_std', 0.019064111324065082)\n",
        "Result of retrain on the best hyperparameters ('mean_val_auc', 0.8914617776870728, 'mean_val_accuracy', 0.8314000010490418, 'metric', 0.8614308893680573, 'val_auc_std', 0.03895053454345975, 'val_accuracy_std', 0.03907224140448684)\n",
        "```\n",
        "\n",
        "on reduced_train_act_opt_act:\n",
        "\n",
        "```\n",
        "best_hparams {'do_ave_pool': 1, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 0.0, 'drop_rate': 0.2, 'fc_layer_sizes': (), 'reduction_alg': None, 'n_components': None}\n",
        "best results ('mean_val_auc', 0.8338292956352233, 'mean_val_accuracy', 0.770799994468689, 'metric', 0.8023146450519562, 'val_auc_std', 0.020978952292563628, 'val_accuracy_std', 0.02503918087631713)\n",
        "Result of retrain on the best hyperparameters ('mean_val_auc', 0.8178006529808044, 'mean_val_accuracy', 0.7424000144004822, 'metric', 0.7801003336906434, 'val_auc_std', 0.04277533943436206, 'val_accuracy_std', 0.0313343298064392)\n",
        "```\n",
        "\n",
        "on reduced_train_attri_opt_act:\n",
        "\n",
        "```\n",
        "best_hparams {'do_ave_pool': 1, 'conv_layer_params': ((16, 3, 1),), 'reg_amount': 0.1, 'drop_rate': 0.2, 'fc_layer_sizes': (16,), 'reduction_alg': None, 'n_components': None}\n",
        "best results ('mean_val_auc', 0.8876911640167237, 'mean_val_accuracy', 0.8391999959945678, 'metric', 0.8634455800056458, 'val_auc_std', 0.01197209366602662, 'val_accuracy_std', 0.017151083603375163)\n",
        "Result of retrain on the best hyperparameters ('mean_val_auc', 0.8815893292427063, 'mean_val_accuracy', 0.8297999978065491, 'metric', 0.8556946635246276, 'val_auc_std', 0.017778033902734827, 'val_accuracy_std', 0.023429907808406807)\n",
        "```"
      ]
    }
  ]
}