{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_NN_with_regularization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arunraja-hub/Preference_Extraction/blob/master/deep_NN_with_regularization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gB2HqtrX9qjK",
        "colab_type": "text"
      },
      "source": [
        "# Explore conv layers and neuron groups\n",
        "\n",
        "What information we can find in convolutional layers and neuron groups about human preferences?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEKdD5IH-BHK",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxabKhjl94Nf",
        "colab_type": "code",
        "outputId": "51386c82-d7f5-4f3e-ce5e-8098dcb8df23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "!git clone https://github.com/arunraja-hub/Preference_Extraction.git\n",
        "\n",
        "!pip install tf-agents==0.3.0\n",
        "!pip uninstall tensorflow-probability -y\n",
        "!pip install tensorflow-probability==0.7.0\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Cloning into 'Preference_Extraction'...\n",
            "remote: Enumerating objects: 614, done.\u001b[K\n",
            "remote: Counting objects: 100% (614/614), done.\u001b[K\n",
            "remote: Compressing objects: 100% (603/603), done.\u001b[K\n",
            "remote: Total 614 (delta 65), reused 511 (delta 10), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (614/614), 21.24 MiB | 9.27 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n",
            "Collecting tf-agents==0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/a5/07aa82a3cd586d193b2f086b50a2fd0f48bd888ae204389f666eb178cfb3/tf_agents-0.3.0-py2.py3-none-any.whl (839kB)\n",
            "\u001b[K     |████████████████████████████████| 839kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-agents==0.3.0) (1.12.0)\n",
            "Requirement already satisfied: tensorflow-probability>=0.6.0 in /tensorflow-1.15.2/python3.6 (from tf-agents==0.3.0) (0.7.0)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-agents==0.3.0) (0.9.0)\n",
            "Collecting gin-config==0.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/be/c984b1c8a7ba1c385b32bf39c7a225cd9f713d49705898309d01b60fd0e7/gin_config-0.1.3-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tf-agents==0.3.0) (1.18.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.6.0->tf-agents==0.3.0) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.6.0->tf-agents==0.3.0) (1.3.0)\n",
            "Installing collected packages: gin-config, tf-agents\n",
            "  Found existing installation: gin-config 0.3.0\n",
            "    Uninstalling gin-config-0.3.0:\n",
            "      Successfully uninstalled gin-config-0.3.0\n",
            "Successfully installed gin-config-0.1.3 tf-agents-0.3.0\n",
            "Uninstalling tensorflow-probability-0.7.0:\n",
            "  Successfully uninstalled tensorflow-probability-0.7.0\n",
            "Collecting tensorflow-probability==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/3a/c10b6c22320531c774402ac7186d1b673374e2a9d12502cbc8d811e4601c/tensorflow_probability-0.7.0-py2.py3-none-any.whl (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability==0.7.0) (1.18.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability==0.7.0) (4.4.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability==0.7.0) (1.12.0)\n",
            "Requirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability==0.7.0) (1.3.0)\n",
            "Installing collected packages: tensorflow-probability\n",
            "  Found existing installation: tensorflow-probability 0.10.0rc0\n",
            "    Uninstalling tensorflow-probability-0.10.0rc0:\n",
            "      Successfully uninstalled tensorflow-probability-0.10.0rc0\n",
            "Successfully installed tensorflow-probability-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe_ZicNb990h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from tf_agents.trajectories.time_step import TimeStep\n",
        "from tf_agents.specs.tensor_spec import TensorSpec\n",
        "from tf_agents.specs.tensor_spec import TensorSpec\n",
        "from tf_agents.specs.tensor_spec import BoundedTensorSpec\n",
        "from tf_agents.networks import q_network\n",
        "\n",
        "import lucid.modelzoo.vision_models as models\n",
        "\n",
        "import concurrent.futures\n",
        "import itertools\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import io\n",
        "import collections\n",
        "\n",
        "import urllib.request\n",
        "from urllib.error import HTTPError"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcTigUPrCyJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lucid.misc.channel_reducer import ChannelReducer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it1q6njY-Vj1",
        "colab_type": "text"
      },
      "source": [
        "## Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw6T-Fg0-WWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Trajectory(\n",
        "    collections.namedtuple('Trajectory', [\n",
        "        'step_type',\n",
        "        'observation',\n",
        "        'action',\n",
        "        'policy_info',\n",
        "        'next_step_type',\n",
        "        'reward',\n",
        "        'discount',\n",
        "    ])):\n",
        "  \"\"\"Stores the observation the agent saw and the action it took.\n",
        "      The rest of the attributes aren't used in this code.\"\"\"\n",
        "  __slots__ = ()\n",
        "\n",
        "class ListWrapper(object):\n",
        "  def __init__(self, list_to_wrap):\n",
        "    self._list = list_to_wrap\n",
        "\n",
        "  def as_list(self):\n",
        "    return self._list\n",
        "\n",
        "class RenameUnpickler(pickle.Unpickler):\n",
        "    def find_class(self, module, name):\n",
        "      if name == \"Trajectory\":\n",
        "        return Trajectory\n",
        "      if name == \"ListWrapper\":\n",
        "        return ListWrapper\n",
        "\n",
        "      return super(RenameUnpickler, self).find_class(module, name)\n",
        "\n",
        "def rename_load(s):\n",
        "    \"\"\"Helper function analogous to pickle.loads().\"\"\"\n",
        "    return RenameUnpickler(s, encoding='latin1').load()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LedD3rNS-YGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Modified read trajectories functions to read files from local storage\n",
        "\n",
        "def load_file(full_path):\n",
        "    try:\n",
        "        with open(full_path, 'rb') as f:\n",
        "            data = rename_load(f)\n",
        "            return data\n",
        "    except:\n",
        "        return None\n",
        "    \n",
        "def all_load_data(base_path):\n",
        "    \n",
        "    executor = concurrent.futures.ThreadPoolExecutor(max_workers=100)\n",
        "    \n",
        "    futures = []\n",
        "    for i in range(5000):\n",
        "        full_path = os.path.join(base_path, \"ts\"+str(i)+\".pickle\")\n",
        "        future = executor.submit(load_file, full_path)\n",
        "        futures.append(future)\n",
        "    \n",
        "    raw_data = []\n",
        "    for future in concurrent.futures.as_completed(futures):\n",
        "        result = future.result()\n",
        "        if result:\n",
        "            raw_data.append(result)\n",
        "    \n",
        "    return raw_data\n",
        "\n",
        "\n",
        "all_raw_data = all_load_data(\"Preference_Extraction/data/simple_env_1/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJCk1TSR-bnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert len(all_raw_data) == 475"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXK0vR1k-7MI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activations = []\n",
        "observations = []\n",
        "preferences = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDGO8-9o-8Ja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load up data into arrays\n",
        "for data in all_raw_data:\n",
        "    for i in range(data.observation.shape[0]):\n",
        "        observations.append(np.copy(data.observation[i]))\n",
        "        activations.append(np.copy(data.policy_info[\"activations\"][i]))\n",
        "        preferences.append(data.policy_info['satisfaction'].as_list()[i])\n",
        "\n",
        "observations = np.array(observations)\n",
        "activations = np.array(activations)\n",
        "preferences = np.array(preferences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6JY9CEO-lfn",
        "colab_type": "text"
      },
      "source": [
        "## Load model get conv activations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k1_vvLSAmEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cpt_name = \"Preference_Extraction/model_ckpt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvFq3urvAsgb",
        "colab_type": "code",
        "outputId": "b2079cd0-3af9-4b66-be61-abcdf85af16c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "input_shape = [14, 16, 5]\n",
        "\n",
        "my_input = tf.placeholder(tf.float32, shape=[None] + input_shape, name=\"my_input\")\n",
        "q_vals = q_network.QNetwork(input_tensor_spec=TensorSpec(shape=(14, 16, 5)), action_spec=BoundedTensorSpec((), tf.int32, 0, 2), conv_layer_params = [[16, 3, 1], [32, 3, 2]], fc_layer_params = [64])(my_input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method QNetwork.call of <tf_agents.networks.q_network.QNetwork object at 0x7f28fdbcccf8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method QNetwork.call of <tf_agents.networks.q_network.QNetwork object at 0x7f28fdbcccf8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <bound method QNetwork.call of <tf_agents.networks.q_network.QNetwork object at 0x7f28fdbcccf8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method EncodingNetwork.call of <tf_agents.networks.encoding_network.EncodingNetwork object at 0x7f293019ef98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method EncodingNetwork.call of <tf_agents.networks.encoding_network.EncodingNetwork object at 0x7f293019ef98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <bound method EncodingNetwork.call of <tf_agents.networks.encoding_network.EncodingNetwork object at 0x7f293019ef98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-vmY9crAUrC",
        "colab_type": "code",
        "outputId": "d2ff9ee2-4cf8-446b-d3e6-31bdf28af191",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "cpt_var_info = tf.compat.v1.train.list_variables(cpt_name)\n",
        "cpt_var_info = [var for var in cpt_var_info if ((\"bias\" in var[0]) or (\"kernel\" in var[0])) and not (\"OPTIMIZER\" in var[0]) and not (\"_target_q_network\" in var[0])]\n",
        "shape_to_cpt_var_name = {tuple(var[1]): var[0] for var in cpt_var_info}\n",
        "\n",
        "current_vars = tf.get_collection(tf.GraphKeys.VARIABLES)\n",
        "shape_to_current_var_name = {tuple(var.get_shape().as_list()): var.name[:-2] for var in current_vars}\n",
        "\n",
        "var_name_to_prev_var_name = {}\n",
        "for shape in shape_to_current_var_name:\n",
        "  var_name_to_prev_var_name[shape_to_current_var_name[shape]] = shape_to_cpt_var_name[shape]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/util/decorator_utils.py:145: GraphKeys.VARIABLES (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.GraphKeys.GLOBAL_VARIABLES` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/util/decorator_utils.py:145: GraphKeys.VARIABLES (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.GraphKeys.GLOBAL_VARIABLES` instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCVO9mz1-oOJ",
        "colab_type": "code",
        "outputId": "f40e1685-64d8-45f0-d0a6-3078d79af2fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "tf.train.warm_start(cpt_name, var_name_to_prev_var_name=var_name_to_prev_var_name)\n",
        "init_op = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Warm-starting from: Preference_Extraction/model_ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Warm-starting from: Preference_Extraction/model_ckpt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Warm-started 8 variables.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Warm-started 8 variables.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyOb1kp2-pVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_activations = []\n",
        "conv_activation_tensor = tf.get_default_graph().get_tensor_by_name(\n",
        "    \"QNetwork/EncodingNetwork/EncodingNetwork/conv2d/Relu:0\")\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init_op)\n",
        "\n",
        "  for img in observations:\n",
        "    conv_act = sess.run(conv_activation_tensor, {my_input: np.array([img])})[0]\n",
        "    conv_activations.append(conv_act)\n",
        "\n",
        "conv_activations = np.array(conv_activations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIUpPDNhBwFI",
        "colab_type": "text"
      },
      "source": [
        "## Data Recap\n",
        "\n",
        "Now we should have\n",
        "* preferences\n",
        "* dense layer activations\n",
        "* conv layer activations\n",
        "* observations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpgDDpiaB3dU",
        "colab_type": "code",
        "outputId": "a20aad3c-2465-4549-ab5d-fac259aa42e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print('Obs.shape', observations.shape)\n",
        "print('ConvAct.shape', conv_activations.shape)\n",
        "print('DensAct.shape', activations.shape)\n",
        "print('Pref.shape', preferences.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obs.shape (23750, 14, 16, 5)\n",
            "ConvAct.shape (23750, 12, 14, 16)\n",
            "DensAct.shape (23750, 64)\n",
            "Pref.shape (23750,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjWA9FmIMV3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import joblib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJfZNjB-MVsx",
        "colab_type": "code",
        "outputId": "a9a84157-4b7d-4bb7-bf76-ad9cfd420160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "joblib.dump(observations, 'obs.pkl')\n",
        "joblib.dump(conv_activations, 'convAct.pkl')\n",
        "joblib.dump(activations, 'densAct.pkl')\n",
        "joblib.dump(preferences, 'pref.pkl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pref.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmRXcClZCfti",
        "colab_type": "text"
      },
      "source": [
        "## Dimensionality reduction (unused)\n",
        "\n",
        "Let us try to compress convolutional activations using the neuron groups techniques used. Perhaps this can be applied to observations too?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPWhKs5r_Bhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def neuron_groups(acts, n_groups = 4):\n",
        "    nmf = ChannelReducer(n_groups, \"NMF\")\n",
        "    spatial_factors = nmf.fit_transform(acts)[0].astype(\"float32\")\n",
        "    channel_factors = nmf._reducer.components_.astype(\"float32\")\n",
        "    return spatial_factors, channel_factors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xldnyMX3DZE6",
        "colab_type": "code",
        "outputId": "cde5010b-f9ee-440f-a43f-8c3ea7b02d04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "conv_activations_space = []\n",
        "conv_activations_chan = []\n",
        "\n",
        "for c_act in conv_activations:\n",
        "    c_act_s, c_act_ch = neuron_groups(c_act)\n",
        "    conv_activations_space.append(c_act_s)\n",
        "    conv_activations_chan.append(c_act_ch)\n",
        "\n",
        "conv_activations_space = np.array(conv_activations_space)\n",
        "conv_activations_chan = np.array(conv_activations_chan)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-4d8abb7c6fd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc_act\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconv_activations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mc_act_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_act_ch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneuron_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_act\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mconv_activations_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_act_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mconv_activations_chan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_act_ch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-7df0a8c1125b>\u001b[0m in \u001b[0;36mneuron_groups\u001b[0;34m(acts, n_groups)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mneuron_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnmf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChannelReducer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NMF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mspatial_factors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mchannel_factors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reducer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mspatial_factors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_factors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lucid/misc/channel_reducer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, acts)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mChannelReducer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reducer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lucid/misc/channel_reducer.py\u001b[0m in \u001b[0;36m_apply_flat\u001b[0;34m(cls, f, acts)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0morig_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0macts_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mnew_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macts_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnew_flat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_nmf.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, W, H)\u001b[0m\n\u001b[1;32m   1285\u001b[0m             \u001b[0ml1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'both'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m             \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1287\u001b[0;31m             shuffle=self.shuffle)\n\u001b[0m\u001b[1;32m   1288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m         self.reconstruction_err_ = _beta_divergence(X, W, H, self.beta_loss,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_nmf.py\u001b[0m in \u001b[0;36mnon_negative_factorization\u001b[0;34m(X, W, H, n_components, init, update_H, solver, beta_loss, tol, max_iter, alpha, l1_ratio, regularization, random_state, verbose, shuffle)\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m         W, H = _initialize_nmf(X, n_components, init=init,\n\u001b[0;32m-> 1052\u001b[0;31m                                random_state=random_state)\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m     l1_reg_W, l1_reg_H, l2_reg_W, l2_reg_H = _compute_regularization(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_nmf.py\u001b[0m in \u001b[0;36m_initialize_nmf\u001b[0;34m(X, n_components, init, eps, random_state)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;31m# NNDSVD initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m     \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomized_svd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m     \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36mrandomized_svd\u001b[0;34m(M, n_components, n_oversamples, n_iter, power_iteration_normalizer, transpose, flip_sign, random_state)\u001b[0m\n\u001b[1;32m    324\u001b[0m       \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mSzlam\u001b[0m \u001b[0met\u001b[0m \u001b[0mal\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;36m2014\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \"\"\"\n\u001b[0;32m--> 326\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlil_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdok_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m         warnings.warn(\"Calculating SVD of a {} is expensive. \"\n\u001b[1;32m    328\u001b[0m                       \"csr_matrix is more efficient.\".format(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioHYXgNTD6l-",
        "colab_type": "code",
        "outputId": "2fa18750-c485-4058-fd03-50c0d58c8452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print('ConvAct.shape', conv_activations.shape)\n",
        "print('ConvAct_spatial.shape', conv_activations_space.shape)\n",
        "print('ConvAct_channels.shape', conv_activations_chan.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ConvAct.shape (23750, 12, 14, 16)\n",
            "ConvAct_spatial.shape (23750, 14, 4)\n",
            "ConvAct_channels.shape (23750, 4, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pztlV-H_MngR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ys = preferences\n",
        "xs = np.concatenate((\n",
        "    conv_activations_space.reshape(conv_activations_space.shape[0], -1),\n",
        "    conv_activations_chan.reshape(conv_activations_chan.shape[0], -1)\n",
        "), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epxLXWkkHXm0",
        "colab_type": "text"
      },
      "source": [
        "## Modelling (restart kernel)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jneb9SnnGXE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import joblib\n",
        "import concurrent.futures\n",
        "import itertools\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import scipy\n",
        "from scipy import ndimage\n",
        "from sklearn import metrics\n",
        "from sklearn.utils import shuffle\n",
        "import io\n",
        "import collections"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NblMHGdKD7n0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "observations = joblib.load('obs.pkl')\n",
        "conv_activations = joblib.load('convAct.pkl')\n",
        "activations = joblib.load('densAct.pkl')\n",
        "preferences = joblib.load('pref.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d258qRMCM61m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_20EFLDQ44_z",
        "colab_type": "text"
      },
      "source": [
        "#Data structure analysis (can be skipped)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkA6-uq14-T6",
        "colab_type": "code",
        "outputId": "51d77335-48af-4698-d816-11277a29a65e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#print(\"Convolutional activations:\")\n",
        "#print(conv_activations)\n",
        "#print(\"Activations:\")\n",
        "#print(activations)\n",
        "\n",
        "test_xs = []\n",
        "\n",
        "#for conv_activation in conv_activations:\n",
        "  #print(conv_activation)\n",
        "\n",
        "#for activation in activations:\n",
        "  #print(activation)\n",
        "\n",
        "for conv_activation, activation in zip(conv_activations, activations):\n",
        "  test_xs.append([conv_activation, activation])\n",
        "\n",
        "test_xs = np.array(test_xs)\n",
        "print(\"conv_activations[0] = \")\n",
        "print(conv_activations[0])\n",
        "print(\"activations[0] = \")\n",
        "print(activations[0])\n",
        "print(\"test_xs[0] = \")\n",
        "print(test_xs[0])\n",
        "print(test_xs.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv_activations[0] = \n",
            "[[[0.         0.         0.66749555 ... 0.         0.         1.4185064 ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.93666255]\n",
            "  [0.         0.         0.         ... 0.         0.         0.8227383 ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         1.1279838 ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.9015943 ]\n",
            "  [0.         0.         0.         ... 0.         0.         1.1268153 ]]\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         1.120673  ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.89428335]\n",
            "  [0.         0.         0.         ... 0.         0.         1.0960746 ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         0.8928306 ]\n",
            "  [0.         0.         0.         ... 0.         0.         1.1180516 ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.8916621 ]]\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         0.8855195 ]\n",
            "  [0.         0.         0.         ... 0.         0.         1.1107407 ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.8689314 ]\n",
            "  ...\n",
            "  [0.         0.         0.         ... 0.         0.         1.1092879 ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.8828982 ]\n",
            "  [0.         0.         0.         ... 0.         0.         1.1081192 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.         0.         0.         ... 0.         0.         0.5315988 ]\n",
            "  [0.         0.         0.34554416 ... 0.         0.         1.0122745 ]\n",
            "  [0.         0.         0.         ... 0.         0.         1.0182025 ]\n",
            "  ...\n",
            "  [0.         0.         0.33604607 ... 0.         0.         1.0108213 ]\n",
            "  [0.         0.         0.         ... 0.         0.         1.043269  ]\n",
            "  [0.         0.         0.         ... 0.         0.         0.8168788 ]]\n",
            "\n",
            " [[0.14829585 1.8491058  0.02602103 ... 0.         3.492464   0.52950704]\n",
            "  [0.15402052 1.9226723  0.         ... 0.         3.608715   1.1917502 ]\n",
            "  [0.13758947 2.0421906  0.02991688 ... 0.         3.6552649  0.50182015]\n",
            "  ...\n",
            "  [0.         0.85131645 0.         ... 0.         2.918829   1.6078326 ]\n",
            "  [0.         2.692934   0.         ... 0.         3.0272446  0.477512  ]\n",
            "  [0.         3.851204   0.         ... 0.         3.995493   1.4736009 ]]\n",
            "\n",
            " [[0.02067984 3.3800545  0.3022085  ... 0.         4.8484135  1.6715882 ]\n",
            "  [0.0861048  3.5174656  0.         ... 0.         4.948448   1.1301907 ]\n",
            "  [0.         3.5704784  0.30326882 ... 0.         5.005617   1.6650524 ]\n",
            "  ...\n",
            "  [0.         2.430935   0.         ... 0.         4.177017   1.7913481 ]\n",
            "  [0.         4.24596    0.2600329  ... 0.         4.3810997  1.207893  ]\n",
            "  [0.         5.4183636  0.         ... 0.         5.335533   1.3296237 ]]]\n",
            "activations[0] = \n",
            "[  0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.        34.20645\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        27.12121    0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        55.895454   0.\n",
            "  51.251602   0.        90.79614    0.         0.         0.\n",
            "   0.         0.       230.84906    0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.        66.48631    0.         0.      ]\n",
            "test_xs[0] = \n",
            "[array([[[0.        , 0.        , 0.66749555, ..., 0.        ,\n",
            "         0.        , 1.4185064 ],\n",
            "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "         0.        , 0.93666255],\n",
            "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "         0.        , 0.8227383 ],\n",
            "        ...,\n",
            "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "         0.        , 1.1279838 ],\n",
            "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "         0.        , 0.9015943 ],\n",
            "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "         0.        , 1.1268153 ]],\n",
            "\n",
            "       [[0.        , 0.        , 0.        , ..., 0.        ,\n",
            "         0.        , 1.120673  ],\n",
            "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "         0.        , 0.89428335],\n",
            "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "         0.        , 1.0960746 ],\n",
            "        ...,\n",
            "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "         0.        , 0.8928306 ],\n",
            "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "         0.        , 1.1180516 ],\n",
            "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "         0.        , 0.8916621 ]],\n",
            "\n",
            "       [[0.        , 0.        , 0.        , ..., 0.        ,\n",
            "         0.        , 0.8855195 ],\n",
            "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "         0.        , 1.1107407 ],\n",
            "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "         0.        , 0.8689314 ],\n",
            "        ...,\n",
            "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "         0.        , 1.1092879 ],\n",
            "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "         0.        , 0.8828982 ],\n",
            "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "         0.        , 1.1081192 ]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[0.        , 0.        , 0.        , ..., 0.        ,\n",
            "         0.        , 0.5315988 ],\n",
            "        [0.        , 0.        , 0.34554416, ..., 0.        ,\n",
            "         0.        , 1.0122745 ],\n",
            "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "         0.        , 1.0182025 ],\n",
            "        ...,\n",
            "        [0.        , 0.        , 0.33604607, ..., 0.        ,\n",
            "         0.        , 1.0108213 ],\n",
            "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "         0.        , 1.043269  ],\n",
            "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "         0.        , 0.8168788 ]],\n",
            "\n",
            "       [[0.14829585, 1.8491058 , 0.02602103, ..., 0.        ,\n",
            "         3.492464  , 0.52950704],\n",
            "        [0.15402052, 1.9226723 , 0.        , ..., 0.        ,\n",
            "         3.608715  , 1.1917502 ],\n",
            "        [0.13758947, 2.0421906 , 0.02991688, ..., 0.        ,\n",
            "         3.6552649 , 0.50182015],\n",
            "        ...,\n",
            "        [0.        , 0.85131645, 0.        , ..., 0.        ,\n",
            "         2.918829  , 1.6078326 ],\n",
            "        [0.        , 2.692934  , 0.        , ..., 0.        ,\n",
            "         3.0272446 , 0.477512  ],\n",
            "        [0.        , 3.851204  , 0.        , ..., 0.        ,\n",
            "         3.995493  , 1.4736009 ]],\n",
            "\n",
            "       [[0.02067984, 3.3800545 , 0.3022085 , ..., 0.        ,\n",
            "         4.8484135 , 1.6715882 ],\n",
            "        [0.0861048 , 3.5174656 , 0.        , ..., 0.        ,\n",
            "         4.948448  , 1.1301907 ],\n",
            "        [0.        , 3.5704784 , 0.30326882, ..., 0.        ,\n",
            "         5.005617  , 1.6650524 ],\n",
            "        ...,\n",
            "        [0.        , 2.430935  , 0.        , ..., 0.        ,\n",
            "         4.177017  , 1.7913481 ],\n",
            "        [0.        , 4.24596   , 0.2600329 , ..., 0.        ,\n",
            "         4.3810997 , 1.207893  ],\n",
            "        [0.        , 5.4183636 , 0.        , ..., 0.        ,\n",
            "         5.335533  , 1.3296237 ]]], dtype=float32)\n",
            " array([  0.      ,   0.      ,   0.      ,   0.      ,   0.      ,\n",
            "         0.      ,   0.      ,   0.      ,   0.      ,   0.      ,\n",
            "         0.      ,  34.20645 ,   0.      ,   0.      ,   0.      ,\n",
            "         0.      ,   0.      ,   0.      ,   0.      ,   0.      ,\n",
            "         0.      ,   0.      ,  27.12121 ,   0.      ,   0.      ,\n",
            "         0.      ,   0.      ,   0.      ,   0.      ,   0.      ,\n",
            "         0.      ,   0.      ,   0.      ,   0.      ,  55.895454,\n",
            "         0.      ,  51.251602,   0.      ,  90.79614 ,   0.      ,\n",
            "         0.      ,   0.      ,   0.      ,   0.      , 230.84906 ,\n",
            "         0.      ,   0.      ,   0.      ,   0.      ,   0.      ,\n",
            "         0.      ,   0.      ,   0.      ,   0.      ,   0.      ,\n",
            "         0.      ,   0.      ,   0.      ,   0.      ,   0.      ,\n",
            "         0.      ,  66.48631 ,   0.      ,   0.      ], dtype=float32)]\n",
            "(23750, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-pONQA_HlNb",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiL291vIJ51V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xs_raw = []\n",
        "xs = []\n",
        "\n",
        "for conv_activation, activation in zip(conv_activations, activations):\n",
        "  xs_raw.append([conv_activation, [[activation]]])\n",
        "\n",
        "for element in xs_raw:\n",
        "  temp = []\n",
        "  for subelement in element:\n",
        "    for subsubelement in subelement:\n",
        "      for subsubsubelement in subsubelement:\n",
        "        for subsubsubsubelement in subsubsubelement:\n",
        "          temp.append(subsubsubsubelement)\n",
        "  temp = np.array(temp)\n",
        "  xs.append(temp)\n",
        "xs = np.array(xs)\n",
        "ys = (preferences > -6).astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rYDCr6kHwlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_val_auc(logs):\n",
        "      for key in logs:\n",
        "        if key.startswith('val_auc'):\n",
        "          return logs[key]\n",
        "\n",
        "class BestStats(tf.keras.callbacks.Callback):\n",
        "  \"\"\"A callback to keep track of the best val accuracy and auc seen so far.\"\"\"\n",
        "  def on_train_begin(self, logs):\n",
        "      self.bestMetric = -float('inf')\n",
        "      self.bestLogs = None\n",
        "      self.bestTrain = -float('inf')\n",
        "      self.num_epochs = 0\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    self.num_epochs += 1\n",
        "    self.bestTrain = max(self.bestTrain, logs.get('accuracy'))\n",
        "\n",
        "    val_accuracy = logs.get('val_accuracy')\n",
        "    if val_accuracy == None:\n",
        "      return \n",
        "\n",
        "    val_auc = get_val_auc(logs)\n",
        "    \n",
        "    metric = (val_accuracy + val_auc) / 2.0\n",
        "\n",
        "    if metric > self.bestMetric:\n",
        "      self.bestMetric = metric\n",
        "      self.bestLogs = logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eGAiwX8Nms-",
        "colab_type": "code",
        "outputId": "04448f4f-a385-41e1-8f1e-a45d41415d56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "xs.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23750, 2752)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PQd_KChHskj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try a different model that doesn't use convolutions and Flattens() the input at first\n",
        "\n",
        "def get_model(reg_amount, drop_rate, reduction_alg, n_components):\n",
        "  del reduction_alg, n_components\n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(512, activation=\"relu\"),\n",
        "    tf.keras.layers.Dropout(drop_rate),\n",
        "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(reg_amount)),\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(.01),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy',\n",
        "                        tf.keras.metrics.AUC()\n",
        "                        ],\n",
        "                )\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncJn-7_UH4ai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_activations = False\n",
        "\n",
        "all_hparam_possibilities = [\n",
        "    {\"drop_rate\": [.0,], \"reg_amount\": [.0], 'reduction_alg': [None], 'n_components': [None]},\n",
        "    {\"drop_rate\": [.2,], \"reg_amount\": [.0], 'reduction_alg': [None], 'n_components': [None]}]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQBhRFcFHl3w",
        "colab_type": "code",
        "outputId": "5176b8e9-6c26-4bf9-b547-f36013a19d42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_train = 50\n",
        "num_val = 1000\n",
        "epochs = 400\n",
        "print(\"use_activations:\", use_activations, \"num_train:\", num_train, \"epochs\", epochs)\n",
        "if num_train > 50:\n",
        "  print(\"More than 50 train data!!!!!!!!\")\n",
        "\n",
        "# each item in all_hparam_possibilities specifies valid hyper params to try. Put parameters that don't make sense together in separate lists.\n",
        "\n",
        "hparam_combinations = []\n",
        "for hparam_possibilities in all_hparam_possibilities:\n",
        "  hparam_keys, hparam_values = zip(*hparam_possibilities.items())\n",
        "  hparam_combinations.extend([dict(zip(hparam_keys, v)) for v in itertools.product(*hparam_values)])\n",
        "random.shuffle(hparam_combinations)\n",
        "print(\"len(hparam_combinations)\", len(hparam_combinations), \"hparam_combinations\", hparam_combinations)\n",
        "\n",
        "def modify_x_for_reduce(xs):\n",
        "  reshaped_x = np.reshape(xs, [xs.shape[0], -1])\n",
        "  # Make everything positive because some reductions don't work with negatives.\n",
        "  reshaped_x -= np.min(reshaped_x)\n",
        "  return reshaped_x\n",
        "\n",
        "def unsup_exstract(xs, reg_amount, drop_rate, layer_sizes, reduction_alg, n_components):\n",
        "  del reg_amount, drop_rate, layer_sizes\n",
        "\n",
        "  print(\"Using unsupervised feature extraction.\")\n",
        "\n",
        "  dim_reduct_model = ChannelReducer(reduction_alg=reduction_alg, n_components=n_components)\n",
        "  xs = dim_reduct_model.fit_transform(modify_x_for_reduce(xs))\n",
        "  return xs\n",
        "\n",
        "def train_best_logs(xs, ys, num_val, do_summary, hparams, get_model):\n",
        "  \"\"\"Trains the model and retruns the logs of the best epoch. randomly splits the train and val data before training.\"\"\"\n",
        "  tf.keras.backend.clear_session()\n",
        "  model = get_model(**hparams)\n",
        "  xs, ys = shuffle(xs, ys)\n",
        "\n",
        "  xs_val = xs[num_train:num_train+num_val]\n",
        "  ys_val = ys[num_train:num_train+num_val]\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, verbose=0)\n",
        "  best_stats = BestStats()\n",
        "  model.fit(xs[:num_train], ys[:num_train], epochs=epochs, batch_size=256, validation_freq=1, callbacks=[best_stats, early_stopping], validation_data=(xs_val, ys_val), verbose=0)\n",
        "  if do_summary:\n",
        "    model.summary()\n",
        "    print(\"best train accuracy:\", best_stats.bestTrain)\n",
        "    print(\"Number of epochs:\", best_stats.num_epochs)\n",
        "  return best_stats.bestLogs\n",
        "\n",
        "def multiple_train_ave(hparams):\n",
        "  \"\"\"Trains the model multiple times with the same parameters and returns the average metrics\"\"\"\n",
        "  start = time.time()\n",
        "  all_val_auc = []\n",
        "  all_val_accuracy = []\n",
        "\n",
        "  if hparams['reduction_alg'] != None:\n",
        "    xs_for_train = unsup_exstract(xs, **hparams)\n",
        "  else:\n",
        "    xs_for_train = xs\n",
        "\n",
        "  do_summary = True\n",
        "  for i in range(5):\n",
        "    logs = train_best_logs(xs_for_train, ys, num_val, do_summary, hparams, get_model)\n",
        "    all_val_auc.append(get_val_auc(logs))\n",
        "    all_val_accuracy.append(logs.get('val_accuracy'))\n",
        "    do_summary = False \n",
        "\n",
        "  mean_val_auc = np.mean(all_val_auc)\n",
        "  mean_val_accuracy = np.mean(all_val_accuracy)\n",
        "  metric = (mean_val_auc + mean_val_accuracy) / 2.0\n",
        "  print_data = (\"mean_val_auc\", mean_val_auc, \"mean_val_accuracy\", mean_val_accuracy, \"metric\", metric, \"val_auc_std\", np.std(all_val_auc), \"val_accuracy_std\", np.std(all_val_accuracy))\n",
        "\n",
        "  end = time.time()\n",
        "  print(\"Seconds per hyperparam config\", end - start)\n",
        "  # GPU: ('Seconds per hyperparam config', 16.970870971679688)\n",
        "\n",
        "  return metric, print_data\n",
        "\n",
        "best_metric = -float('inf')\n",
        "\n",
        "run_num = 0\n",
        "for hparams in hparam_combinations:\n",
        "  print(\"hparams\", hparams)\n",
        "\n",
        "  metric, print_data = multiple_train_ave(hparams)\n",
        "\n",
        "  print(print_data)\n",
        "  if metric > best_metric:\n",
        "    best_metric = metric\n",
        "    best_print_data = print_data\n",
        "    best_hparams = hparams\n",
        "\n",
        "  run_num += 1\n",
        "  print(\"fract done\", run_num/float(len(hparam_combinations)))\n",
        "  print\n",
        "  print(\"==============================================================================================\")\n",
        "  print\n",
        "  sys.stdout.flush()\n",
        "\n",
        "print(\"best_hparams\", best_hparams)\n",
        "print(\"best results\", best_print_data)\n",
        "print(\"Retraining on the best_hparams to make sure we didn't just get good results by random chance.\")\n",
        "\n",
        "_, print_data = multiple_train_ave(best_hparams)\n",
        "print(\"Result of retrain on the best hyperparameters\", print_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "use_activations: False num_train: 50 epochs 400\n",
            "len(hparam_combinations) 2 hparam_combinations [{'drop_rate': 0.0, 'reg_amount': 0.0, 'reduction_alg': None, 'n_components': None}, {'drop_rate': 0.2, 'reg_amount': 0.0, 'reduction_alg': None, 'n_components': None}]\n",
            "hparams {'drop_rate': 0.0, 'reg_amount': 0.0, 'reduction_alg': None, 'n_components': None}\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  704768    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  131584    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  65664     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              multiple                  8256      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              multiple                  65        \n",
            "=================================================================\n",
            "Total params: 910,337\n",
            "Trainable params: 910,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "best train accuracy: 1.0\n",
            "Number of epochs: 34\n",
            "Seconds per hyperparam config 18.118917226791382\n",
            "('mean_val_auc', 0.8673999428749084, 'mean_val_accuracy', 0.8117999911308289, 'metric', 0.8395999670028687, 'val_auc_std', 0.03557014848722692, 'val_accuracy_std', 0.03459132319455952)\n",
            "fract done 0.5\n",
            "==============================================================================================\n",
            "hparams {'drop_rate': 0.2, 'reg_amount': 0.0, 'reduction_alg': None, 'n_components': None}\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  704768    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  131584    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  65664     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              multiple                  8256      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              multiple                  65        \n",
            "=================================================================\n",
            "Total params: 910,337\n",
            "Trainable params: 910,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "best train accuracy: 1.0\n",
            "Number of epochs: 37\n",
            "Seconds per hyperparam config 18.620408535003662\n",
            "('mean_val_auc', 0.8747454166412354, 'mean_val_accuracy', 0.8052000045776367, 'metric', 0.8399727106094361, 'val_auc_std', 0.029254156543993853, 'val_accuracy_std', 0.03493652401675368)\n",
            "fract done 1.0\n",
            "==============================================================================================\n",
            "best_hparams {'drop_rate': 0.2, 'reg_amount': 0.0, 'reduction_alg': None, 'n_components': None}\n",
            "best results ('mean_val_auc', 0.8747454166412354, 'mean_val_accuracy', 0.8052000045776367, 'metric', 0.8399727106094361, 'val_auc_std', 0.029254156543993853, 'val_accuracy_std', 0.03493652401675368)\n",
            "Retraining on the best_hparams to make sure we didn't just get good results by random chance.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  704768    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  131584    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  65664     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              multiple                  8256      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              multiple                  65        \n",
            "=================================================================\n",
            "Total params: 910,337\n",
            "Trainable params: 910,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "best train accuracy: 1.0\n",
            "Number of epochs: 38\n",
            "Seconds per hyperparam config 18.034223318099976\n",
            "Result of retrain on the best hyperparameters ('mean_val_auc', 0.8610486865043641, 'mean_val_accuracy', 0.7961999893188476, 'metric', 0.8286243379116058, 'val_auc_std', 0.032136141411180104, 'val_accuracy_std', 0.03761596041399407)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR2yvJAKICeK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}