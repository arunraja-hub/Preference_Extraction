{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "extract_preferences.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arunraja-hub/Preference_Extraction/blob/fine_tune/extract_preferences.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_IZz0TlnzhQ",
        "colab_type": "text"
      },
      "source": [
        "Click \"open in colab\" above to run. No need to download.\n",
        "Change the runtime type to GPU or TPU to make it faster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKmidrQSH8bZ",
        "colab_type": "text"
      },
      "source": [
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9uu_Ht_oXGx",
        "colab_type": "text"
      },
      "source": [
        "# Data and import stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nC3ZAJFA6Jz",
        "colab_type": "code",
        "outputId": "cec39740-5209-4571-b19e-737408a4246b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "!git clone https://github.com/arunraja-hub/Preference_Extraction.git\n",
        "\n",
        "!pip install tf-agents==0.3.0\n",
        "\n",
        "!pip uninstall tensorflow-probability -y\n",
        "!pip install tensorflow-probability==0.7.0\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Preference_Extraction'...\n",
            "remote: Enumerating objects: 30, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 773 (delta 19), reused 6 (delta 6), pack-reused 743\u001b[K\n",
            "Receiving objects: 100% (773/773), 32.02 MiB | 19.03 MiB/s, done.\n",
            "Resolving deltas: 100% (148/148), done.\n",
            "Collecting tf-agents==0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/a5/07aa82a3cd586d193b2f086b50a2fd0f48bd888ae204389f666eb178cfb3/tf_agents-0.3.0-py2.py3-none-any.whl (839kB)\n",
            "\u001b[K     |████████████████████████████████| 839kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tf-agents==0.3.0) (1.18.4)\n",
            "Collecting gin-config==0.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/be/c984b1c8a7ba1c385b32bf39c7a225cd9f713d49705898309d01b60fd0e7/gin_config-0.1.3-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-probability>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-agents==0.3.0) (0.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-agents==0.3.0) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-agents==0.3.0) (0.9.0)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.6.0->tf-agents==0.3.0) (0.3.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.6.0->tf-agents==0.3.0) (1.3.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.6.0->tf-agents==0.3.0) (4.4.2)\n",
            "Installing collected packages: gin-config, tf-agents\n",
            "  Found existing installation: gin-config 0.3.0\n",
            "    Uninstalling gin-config-0.3.0:\n",
            "      Successfully uninstalled gin-config-0.3.0\n",
            "Successfully installed gin-config-0.1.3 tf-agents-0.3.0\n",
            "Uninstalling tensorflow-probability-0.10.0:\n",
            "  Successfully uninstalled tensorflow-probability-0.10.0\n",
            "Collecting tensorflow-probability==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/3a/c10b6c22320531c774402ac7186d1b673374e2a9d12502cbc8d811e4601c/tensorflow_probability-0.7.0-py2.py3-none-any.whl (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability==0.7.0) (1.18.4)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability==0.7.0) (4.4.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability==0.7.0) (1.12.0)\n",
            "Requirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability==0.7.0) (1.3.0)\n",
            "Installing collected packages: tensorflow-probability\n",
            "Successfully installed tensorflow-probability-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGhMeaXwica2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import concurrent.futures\n",
        "import itertools\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import scipy\n",
        "from scipy import ndimage\n",
        "from sklearn import metrics\n",
        "from sklearn.utils import shuffle\n",
        "import io\n",
        "import collections\n",
        "\n",
        "import urllib.request\n",
        "from urllib.error import HTTPError\n",
        "\n",
        "from tf_agents.trajectories.time_step import TimeStep\n",
        "from tf_agents.specs.tensor_spec import TensorSpec\n",
        "from tf_agents.specs.tensor_spec import TensorSpec\n",
        "from tf_agents.specs.tensor_spec import BoundedTensorSpec\n",
        "from tf_agents.networks import q_network\n",
        "\n",
        "sys.path.append('Preference_Extraction')\n",
        "from imports_data import all_load_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHm3f_W6BX0X",
        "colab_type": "text"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYbfWqE8BWyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_raw_data = all_load_data(\"Preference_Extraction/data/simple_env_1/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLw7aBy67gnH",
        "colab_type": "code",
        "cellView": "code",
        "outputId": "7b2c7565-c0ea-4db1-f95d-52983e99a945",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# @title Preprocess the data into x,y training pairs\n",
        "# @markdown The use_activations control which data is used.\n",
        "# @markdown All of the cells below use the data specified here.\n",
        "\n",
        "xs, ys = [], []\n",
        "\n",
        "# Rerun this cell after setting these to different values to train on a different dataset.\n",
        "use_activations = True # @param\n",
        "fine_tune = True # @param\n",
        "\n",
        "\n",
        "for data in all_raw_data:\n",
        "  for i in range(data.observation.shape[0]):\n",
        "    \n",
        "    if use_activations and not fine_tune:\n",
        "      x = np.copy(data.policy_info[\"activations\"][i])\n",
        "    else:\n",
        "      x = np.copy(data.observation[i])\n",
        "\n",
        "    y = data.policy_info['satisfaction'].as_list()[i] > -6\n",
        "\n",
        "    xs.append(x)\n",
        "    ys.append(y)\n",
        "\n",
        "xs = np.array(xs)\n",
        "ys = np.array(ys).astype(int)\n",
        "\n",
        "xs, ys = shuffle(xs, ys)\n",
        "\n",
        "print(\"xs\", xs.shape, \"ys\", ys.shape)\n",
        "print(\"ys 1\", np.sum(ys))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xs (23750, 14, 16, 5) ys (23750,)\n",
            "ys 1 9569\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpNLoX8t8vC7",
        "colab_type": "code",
        "outputId": "f1b79a8b-0fd2-4657-b3bd-3796786ea67e",
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        }
      },
      "source": [
        "# @title Visualize and example\n",
        "rand_index = random.randint(0,1000)\n",
        "\n",
        "if use_activations == False:\n",
        "  print(\"Color channels:\")\n",
        "  plt.imshow(xs[rand_index,:,:,:3], interpolation=\"none\")\n",
        "  plt.show()\n",
        "  print(\"Remaining time channel:\")\n",
        "  plt.imshow(xs[rand_index,:,:,3], interpolation=\"none\")\n",
        "  plt.show()\n",
        "  print(\"A different value for each coordinate to help with convolution:\")\n",
        "  plt.imshow(xs[rand_index,:,:,4], interpolation=\"none\")\n",
        "  plt.show()\n",
        "else:\n",
        "  print(\"x\", xs[rand_index])\n",
        "print(\"y\", ys[rand_index])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x [[[0.03978452 0.9516016  0.7883434  0.8767286  0.        ]\n",
            "  [0.15536374 0.5461407  0.40262002 0.8767286  0.00446429]\n",
            "  [0.03978452 0.9516016  0.7883434  0.8767286  0.00892857]\n",
            "  ...\n",
            "  [0.15536374 0.5461407  0.40262002 0.30075014 0.05803571]\n",
            "  [0.03978452 0.9516016  0.7883434  0.30075014 0.0625    ]\n",
            "  [0.15536374 0.5461407  0.40262002 0.30075014 0.06696428]]\n",
            "\n",
            " [[0.15536374 0.5461407  0.40262002 0.8767286  0.07142857]\n",
            "  [0.03978452 0.9516016  0.7883434  0.8767286  0.07589286]\n",
            "  [0.15536374 0.5461407  0.40262002 0.8767286  0.08035714]\n",
            "  ...\n",
            "  [0.03978452 0.9516016  0.7883434  0.30075014 0.12946428]\n",
            "  [0.15536374 0.5461407  0.40262002 0.30075014 0.13392857]\n",
            "  [0.03978452 0.9516016  0.7883434  0.30075014 0.13839285]]\n",
            "\n",
            " [[0.03978452 0.9516016  0.7883434  0.8767286  0.14285715]\n",
            "  [0.15536374 0.5461407  0.40262002 0.8767286  0.14732143]\n",
            "  [0.03978452 0.9516016  0.7883434  0.8767286  0.15178572]\n",
            "  ...\n",
            "  [0.15536374 0.5461407  0.40262002 0.30075014 0.20089285]\n",
            "  [0.03978452 0.9516016  0.7883434  0.30075014 0.20535715]\n",
            "  [0.15536374 0.5461407  0.40262002 0.30075014 0.20982143]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.15536374 0.5461407  0.40262002 0.8767286  0.78571427]\n",
            "  [0.03978452 0.9516016  0.7883434  0.8767286  0.7901786 ]\n",
            "  [0.15536374 0.5461407  0.40262002 0.8767286  0.79464287]\n",
            "  ...\n",
            "  [0.03978452 0.9516016  0.7883434  0.30075014 0.84375   ]\n",
            "  [0.15536374 0.5461407  0.40262002 0.30075014 0.84821427]\n",
            "  [0.03978452 0.9516016  0.7883434  0.30075014 0.8526786 ]]\n",
            "\n",
            " [[0.         0.         0.         0.8767286  0.85714287]\n",
            "  [0.         0.         0.         0.8767286  0.86160713]\n",
            "  [0.         0.         0.         0.8767286  0.8660714 ]\n",
            "  ...\n",
            "  [0.29803923 0.         0.         0.30075014 0.9151786 ]\n",
            "  [0.         0.         0.         0.30075014 0.91964287]\n",
            "  [0.         0.         0.         0.30075014 0.92410713]]\n",
            "\n",
            " [[0.         0.         0.         0.8767286  0.9285714 ]\n",
            "  [0.         0.         0.         0.8767286  0.93303573]\n",
            "  [0.         0.         0.         0.8767286  0.9375    ]\n",
            "  ...\n",
            "  [0.29803923 0.         0.         0.30075014 0.98660713]\n",
            "  [0.         0.         0.         0.30075014 0.9910714 ]\n",
            "  [0.         0.         0.         0.30075014 0.99553573]]]\n",
            "y 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPKA64IvojNR",
        "colab_type": "text"
      },
      "source": [
        "# ML models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSIP8sjjGdiC",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "d3996ea0-fc5a-497a-a6e3-989714614132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# @title ChannelReducer from lucid\n",
        "# Copied from https://github.com/tensorflow/lucid/blob/master/lucid/misc/channel_reducer.py\n",
        "\n",
        "# Copyright 2018 The Lucid Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\"\"\"Helper for using sklearn.decomposition on high-dimensional tensors.\n",
        "\n",
        "Provides ChannelReducer, a wrapper around sklearn.decomposition to help them\n",
        "apply to arbitrary rank tensors. It saves lots of annoying reshaping.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import sklearn.decomposition\n",
        "\n",
        "try:\n",
        "    from sklearn.decomposition.base import BaseEstimator\n",
        "except AttributeError:\n",
        "    from sklearn.base import BaseEstimator\n",
        "\n",
        "\n",
        "class ChannelReducer(object):\n",
        "  \"\"\"Helper for dimensionality reduction to the innermost dimension of a tensor.\n",
        "\n",
        "  This class wraps sklearn.decomposition classes to help them apply to arbitrary\n",
        "  rank tensors. It saves lots of annoying reshaping.\n",
        "\n",
        "  See the original sklearn.decomposition documentation:\n",
        "  http://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, n_components=3, reduction_alg=\"NMF\", **kwargs):\n",
        "    \"\"\"Constructor for ChannelReducer.\n",
        "\n",
        "    Inputs:\n",
        "      n_components: Numer of dimensions to reduce inner most dimension to.\n",
        "      reduction_alg: A string or sklearn.decomposition class. Defaults to\n",
        "        \"NMF\" (non-negative matrix facotrization). Other options include:\n",
        "        \"PCA\", \"FastICA\", and \"MiniBatchDictionaryLearning\". The name of any of\n",
        "        the sklearn.decomposition classes will work, though.\n",
        "      kwargs: Additional kwargs to be passed on to the reducer.\n",
        "    \"\"\"\n",
        "\n",
        "    if not isinstance(n_components, int):\n",
        "      raise ValueError(\"n_components must be an int, not '%s'.\" % n_components)\n",
        "\n",
        "    # Defensively look up reduction_alg if it is a string and give useful errors.\n",
        "    algorithm_map = {}\n",
        "    for name in dir(sklearn.decomposition):\n",
        "      obj = sklearn.decomposition.__getattribute__(name)\n",
        "      if isinstance(obj, type) and issubclass(obj, BaseEstimator):\n",
        "        algorithm_map[name] = obj\n",
        "    if isinstance(reduction_alg, str):\n",
        "      if reduction_alg in algorithm_map:\n",
        "        reduction_alg = algorithm_map[reduction_alg]\n",
        "      else:\n",
        "        raise ValueError(\"Unknown dimensionality reduction method '%s'.\" % reduction_alg)\n",
        "\n",
        "\n",
        "    self.n_components = n_components\n",
        "    self._reducer = reduction_alg(n_components=n_components, **kwargs)\n",
        "    self._is_fit = False\n",
        "\n",
        "  @classmethod\n",
        "  def _apply_flat(cls, f, acts):\n",
        "    \"\"\"Utility for applying f to inner dimension of acts.\n",
        "\n",
        "    Flattens acts into a 2D tensor, applies f, then unflattens so that all\n",
        "    dimesnions except innermost are unchanged.\n",
        "    \"\"\"\n",
        "    orig_shape = acts.shape\n",
        "    acts_flat = acts.reshape([-1, acts.shape[-1]])\n",
        "    new_flat = f(acts_flat)\n",
        "    if not isinstance(new_flat, np.ndarray):\n",
        "      return new_flat\n",
        "    shape = list(orig_shape[:-1]) + [-1]\n",
        "    return new_flat.reshape(shape)\n",
        "\n",
        "  def fit(self, acts):\n",
        "    self._is_fit = True\n",
        "    return ChannelReducer._apply_flat(self._reducer.fit, acts)\n",
        "\n",
        "  def fit_transform(self, acts):\n",
        "    self._is_fit = True\n",
        "    return ChannelReducer._apply_flat(self._reducer.fit_transform, acts)\n",
        "\n",
        "  def transform(self, acts):\n",
        "    return ChannelReducer._apply_flat(self._reducer.transform, acts)\n",
        "\n",
        "  def __call__(self, acts):\n",
        "    if self._is_fit:\n",
        "      return self.transform(acts)\n",
        "    else:\n",
        "      return self.fit_transform(acts)\n",
        "\n",
        "  def __getattr__(self, name):\n",
        "    if name in self.__dict__:\n",
        "      return self.__dict__[name]\n",
        "    elif name + \"_\" in self._reducer.__dict__:\n",
        "      return self._reducer.__dict__[name+\"_\"]\n",
        "\n",
        "  def __dir__(self):\n",
        "    dynamic_attrs = [name[:-1]\n",
        "                     for name in dir(self._reducer)\n",
        "                     if name[-1] == \"_\" and name[0] != \"_\"\n",
        "                    ]\n",
        "\n",
        "    return list(ChannelReducer.__dict__.keys()) + list(self.__dict__.keys()) + dynamic_attrs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.decomposition.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.decomposition. Anything that cannot be imported from sklearn.decomposition is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo_yWm1n9Fp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_val_auc(logs):\n",
        "      for key in logs:\n",
        "        if key.startswith('val_auc'):\n",
        "          return logs[key]\n",
        "\n",
        "class BestStats(tf.keras.callbacks.Callback):\n",
        "  \"\"\"A callback to keep track of the best val accuracy and auc seen so far.\"\"\"\n",
        "  def on_train_begin(self, logs):\n",
        "      self.bestMetric = -float('inf')\n",
        "      self.bestLogs = None\n",
        "      self.bestTrain = -float('inf')\n",
        "      self.num_epochs = 0\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    self.num_epochs += 1\n",
        "    self.bestTrain = max(self.bestTrain, logs.get('accuracy'))\n",
        "\n",
        "    val_accuracy = logs.get('val_accuracy')\n",
        "    if val_accuracy == None:\n",
        "      return \n",
        "\n",
        "    val_auc = get_val_auc(logs)\n",
        "    \n",
        "    metric = (val_accuracy + val_auc) / 2.0\n",
        "\n",
        "    if metric > self.bestMetric:\n",
        "      self.bestMetric = metric\n",
        "      self.bestLogs = logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOHNseSRi-0L",
        "colab_type": "text"
      },
      "source": [
        "The cells below set the model and hyperparameters to search through. Only run the ones that set the options you want.\n",
        "\n",
        "The all_hparam_possibilities in the code below are the best ones found so far."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfVZf7rX9MZe",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "# @title Image model.\n",
        "# @markdown Run this cell iff use_activations=False and fine_tune=False\n",
        "# @markdown If you're trying to improve the accuracy of the model trained on activations, you won't care about this cell.\n",
        "\n",
        "def get_model(reg_amount, drop_rate, reduction_alg, n_components):\n",
        "  del reduction_alg, n_components\n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "    # This layer gets one of the color channels. It works better than using all of them.\n",
        "    tf.keras.layers.Lambda(lambda x: tf.expand_dims(x[:,:,:,tf.random.uniform((), 0,4,tf.int32)], 3), input_shape=xs.shape[1:]),\n",
        "    tf.keras.layers.Conv2D(32, 2, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(reg_amount)),\n",
        "    tf.keras.layers.Conv2D(16, 1, activation='relu', strides=1, kernel_regularizer=tf.keras.regularizers.l2(reg_amount)),\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(drop_rate),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(reg_amount)),\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(.01),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy',\n",
        "                        tf.keras.metrics.AUC()\n",
        "                        ],\n",
        "                )\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_Xcc_Zx_Any",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "# @title Model for training on the network activations\n",
        "# @markdown Run this cell iff use_activations=True and fine_tune=False\n",
        "\n",
        "def get_model(reg_amount, drop_rate, layer_sizes, reduction_alg, n_components):\n",
        "  del reduction_alg, n_components\n",
        "\n",
        "  layers = []\n",
        "  for layer_size in layer_sizes:\n",
        "    layers.append(tf.keras.layers.Dense(layer_size, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(reg_amount)))\n",
        "    layers.append(tf.keras.layers.Dropout(drop_rate))\n",
        "\n",
        "  model = tf.keras.models.Sequential(layers + [\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(reg_amount))\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(.01),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy', tf.keras.metrics.AUC()],\n",
        "                )\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfLFJnpgDN7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @title Run this cell for hparams with unsupervised feature extraction.\n",
        "# @markdown Run this cell iff use_activations=True and you want unspervised feature exraction.\n",
        "all_hparam_possibilities = [\n",
        "  {'drop_rate': [0], 'reduction_alg': ['PCA'], 'layer_sizes': [()], 'reg_amount': [0.2], 'n_components': [2]},\n",
        "  {'drop_rate': [0], 'reduction_alg': ['FastICA'], 'layer_sizes': [(16, 16)], 'reg_amount': [0], 'n_components': [8]},\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFOfyPihDPIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @title Run this cell for hparams without unsupervised feature extraction.\n",
        "# @markdown Run this cell iff use_activations=True and you don't want unspervised feature exraction.\n",
        "all_hparam_possibilities = [\n",
        "  {\"drop_rate\": [0],  \"layer_sizes\": [(32,)], \"reg_amount\": [0],  'reduction_alg': [None], 'n_components': [None]},                          \n",
        "  {\"drop_rate\": [.2], \"layer_sizes\": [(32,)], \"reg_amount\": [.2], 'reduction_alg': [None], 'n_components': [None]},\n",
        "  {\"drop_rate\": [.5], \"layer_sizes\": [(32,)], \"reg_amount\": [.5], 'reduction_alg': [None], 'n_components': [None]},\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XDVJIy9B3hk",
        "colab_type": "text"
      },
      "source": [
        "# Fine-tune Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjrGt3aEB-BJ",
        "colab_type": "text"
      },
      "source": [
        "## Set up model and restore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqcO8ZrWB5_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cpt_name = \"Preference_Extraction/model_ckpt\"\n",
        "\n",
        "input_shape = [14, 16, 5]\n",
        "q_net = q_network.QNetwork(input_tensor_spec=TensorSpec(shape=input_shape), action_spec=BoundedTensorSpec((), tf.int32, 0, 2), conv_layer_params = [[16, 3, 1], [32, 3, 2]], fc_layer_params = [64])\n",
        "q_net.layers[0].layers[1]._name = \"EncodingNetwork/conv2d_1\"\n",
        "\n",
        "latest_cpt =  tf.train.latest_checkpoint(cpt_name)\n",
        "reader = tf.compat.v1.train.NewCheckpointReader(latest_cpt)\n",
        "model_input = tf.keras.Input(shape=input_shape)\n",
        "q_model_nested = tf.keras.models.Model(inputs=model_input, outputs=[q_net(model_input)])\n",
        "q_model_nested.build(input_shape=input_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfrEjW3LCCm6",
        "colab_type": "code",
        "outputId": "0c1751d6-b96a-4a8b-8ac9-75ccbff75035",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "def flatten_model(model_nested):\n",
        "    def get_layers(layers):\n",
        "        layers_flat = []\n",
        "        for layer in layers:\n",
        "            try:\n",
        "                layers_flat.extend(get_layers(layer.layers))\n",
        "            except AttributeError:\n",
        "                layers_flat.append(layer)\n",
        "        return layers_flat\n",
        "\n",
        "    model_flat = tf.keras.models.Sequential(\n",
        "        get_layers(model_nested.layers)\n",
        "    )\n",
        "    return model_flat\n",
        "\n",
        "def load_weigths(model, last_layer):\n",
        "\n",
        "    layer_map = {\n",
        "        model.layers[0]: \"agent/_q_network/_encoder/_postprocessing_layers/0\",\n",
        "        model.layers[1]: \"agent/_q_network/_encoder/_postprocessing_layers/1\",\n",
        "    }\n",
        "    if last_layer > 3:\n",
        "        layer_map[model.layers[3]] = \"agent/_q_network/_encoder/_postprocessing_layers/3\"\n",
        "    if last_layer > 4:\n",
        "        layer_map[model.layers[4]] = \"agent/_q_network/_q_value_layer\"\n",
        "\n",
        "    last_name_part = \"/.ATTRIBUTES/VARIABLE_VALUE\"\n",
        "    for keras_layer, weights_bias_name in layer_map.items():\n",
        "        weights = reader.get_tensor(weights_bias_name+\"/kernel\"+last_name_part)\n",
        "        biases = reader.get_tensor(weights_bias_name+\"/bias\"+last_name_part)\n",
        "        keras_layer.set_weights([weights, biases])\n",
        "\n",
        "    return model\n",
        "\n",
        "q_model = flatten_model(q_model_nested)\n",
        "q_model = load_weigths(q_model, last_layer=5)\n",
        "q_model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "EncodingNetwork/conv2d (Conv (None, 12, 14, 16)        736       \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/conv2d_1 (Co (None, 5, 6, 32)          4640      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 960)               0         \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/dense (Dense (None, 64)                61504     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 67,075\n",
            "Trainable params: 67,075\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByjD8mUoCHVu",
        "colab_type": "text"
      },
      "source": [
        "## Verify it performs inference correctly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjbFIA5KCKRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def verify_model(model, output_index):\n",
        "  activation_model = tf.keras.models.Model(inputs=model.input, outputs=model.layers[output_index].output)\n",
        "  for i in range(len(all_raw_data[0].observation)):\n",
        "    single_observation = np.array([all_raw_data[0].observation[i]])\n",
        "\n",
        "    restored_activations = activation_model(single_observation)[0]\n",
        "    old_activations = all_raw_data[0].policy_info[\"activations\"][i]\n",
        "    np.testing.assert_allclose(restored_activations, old_activations, rtol=.1)\n",
        "\n",
        "verify_model(q_model, output_index=-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP_kL8W3CcPK",
        "colab_type": "text"
      },
      "source": [
        "## Get model to fit with main pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v30FiGi2Cf94",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "# @title Model for fine tuning\n",
        "# @markdown Run this cell iff fine_tune=True\n",
        "def get_model(reg_amount, drop_rate, layer_sizes, q_net_last_cut, q_net_freeze, reduction_alg, n_components):\n",
        "  del reduction_alg, n_components\n",
        "\n",
        "  layers = []\n",
        "  for ix, layer_size in enumerate(layer_sizes):\n",
        "    layers.append(tf.keras.layers.Dense(layer_size, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(reg_amount), name='post_agent_{}'.format(ix)))\n",
        "    layers.append(tf.keras.layers.Dropout(drop_rate))\n",
        "\n",
        "  for qix, _ in enumerate(q_model.layers[:q_net_last_cut]):\n",
        "      if qix in q_net_freeze:\n",
        "          q_model.layers[qix].trainable = False\n",
        "      else:\n",
        "          q_model.layers[qix].trainable = True\n",
        "        \n",
        "\n",
        "  model = tf.keras.models.Sequential([q_model.input] + q_model.layers[:q_net_last_cut] + layers + [\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(reg_amount), name='output')\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(.01),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy',\n",
        "                        tf.keras.metrics.AUC()\n",
        "                        ],\n",
        "                )\n",
        "\n",
        "  return load_weigths(model, last_layer=q_net_last_cut)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgCRDam2DZWB",
        "colab_type": "code",
        "colab": {},
        "cellView": "code"
      },
      "source": [
        "# @title Run this cell for hparams without unsupervised feature extraction.\n",
        "# @markdown Run this cell iff use_activations=True and you don't want unspervised feature exraction.\n",
        "all_hparam_possibilities = [\n",
        "   {\n",
        "    \"drop_rate\": [.2],  \n",
        "    \"reg_amount\": [.2],  \n",
        "    \"layer_sizes\": [(32,)],\n",
        "    \"q_net_last_cut\": [4, 5],\n",
        "    \"q_net_freeze\": [(), (0,1,2), (0,1,2,3)],\n",
        "    \"reduction_alg\": [None], \n",
        "    \"n_components\": [None]\n",
        "   },\n",
        "    {\n",
        "    \"drop_rate\": [.5],  \n",
        "    \"reg_amount\": [.5],  \n",
        "    \"layer_sizes\": [(32,)],\n",
        "    \"q_net_last_cut\": [4, 5],\n",
        "    \"q_net_freeze\": [(), (0,1,2), (0,1,2,3)],\n",
        "    \"reduction_alg\": [None], \n",
        "    \"n_components\": [None]\n",
        "   }\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yJW0yanonbZ",
        "colab_type": "text"
      },
      "source": [
        "# Training code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XG8eFVRagQ_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run this to reproduce the original results.\n",
        "num_train = 50\n",
        "num_val = 400\n",
        "epochs = 400\n",
        "num_repeat = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7Rg76Q4ckGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run this to train on 10k data instead.\n",
        "num_train = 10000\n",
        "num_val = 2000\n",
        "epochs = 1000\n",
        "num_repeat = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-2EQMqS_ayd",
        "colab_type": "code",
        "cellView": "code",
        "outputId": "03ffe117-220c-4e5b-df19-f7d13d5548aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# @title Train the model\n",
        "# @markdown This tries all the combinations of hparams and picks the best one.\n",
        "# @markdown For each combination of hparams, it averages over num_repeat different train val splits.\n",
        "# @markdown It re runs the best hyperparameters at the end.\n",
        "\n",
        "print(\"use_activations:\", use_activations, \"num_train:\", num_train, \"epochs\", epochs)\n",
        "if num_train > 50:\n",
        "  print(\"More than 50 train data!!!!!!!!\")\n",
        "\n",
        "# each item in all_hparam_possibilities specifies valid hyper params to try. Put parameters that don't make sense together in separate lists.\n",
        "\n",
        "hparam_combinations = []\n",
        "for hparam_possibilities in all_hparam_possibilities:\n",
        "  hparam_keys, hparam_values = zip(*hparam_possibilities.items())\n",
        "  hparam_combinations.extend([dict(zip(hparam_keys, v)) for v in itertools.product(*hparam_values)])\n",
        "random.shuffle(hparam_combinations)\n",
        "print(\"len(hparam_combinations)\", len(hparam_combinations), \"hparam_combinations\", hparam_combinations)\n",
        "\n",
        "def modify_x_for_reduce(xs):\n",
        "  reshaped_x = np.reshape(xs, [xs.shape[0], -1])\n",
        "  # Make everything positive because some reductions don't work with negatives.\n",
        "  reshaped_x -= np.min(reshaped_x)\n",
        "  return reshaped_x\n",
        "\n",
        "def unsup_exstract(xs, reg_amount, drop_rate, layer_sizes, reduction_alg, n_components):\n",
        "  del reg_amount, drop_rate, layer_sizes\n",
        "\n",
        "  print(\"Using unsupervised feature extraction.\")\n",
        "\n",
        "  dim_reduct_model = ChannelReducer(reduction_alg=reduction_alg, n_components=n_components)\n",
        "  xs = dim_reduct_model.fit_transform(modify_x_for_reduce(xs))\n",
        "  return xs\n",
        "\n",
        "def train_best_logs(xs, ys, num_val, do_summary, hparams, get_model):\n",
        "  \"\"\"Trains the model and retruns the logs of the best epoch. randomly splits the train and val data before training.\"\"\"\n",
        "  tf.keras.backend.clear_session()\n",
        "  model = get_model(**hparams)\n",
        "  if fine_tune:\n",
        "      verify_model(model, output_index=3)\n",
        "  xs, ys = shuffle(xs, ys)\n",
        "\n",
        "  xs_val = xs[num_train:num_train+num_val]\n",
        "  ys_val = ys[num_train:num_train+num_val]\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, verbose=0)\n",
        "  best_stats = BestStats()\n",
        "  model.fit(xs[:num_train], ys[:num_train], epochs=epochs, batch_size=256, validation_freq=1, callbacks=[best_stats, early_stopping], validation_data=(xs_val, ys_val), verbose=0)\n",
        "  if do_summary:\n",
        "    model.summary()\n",
        "    print(\"best train accuracy:\", best_stats.bestTrain)\n",
        "    print(\"Number of epochs:\", best_stats.num_epochs)\n",
        "  return best_stats.bestLogs\n",
        "\n",
        "def multiple_train_ave(hparams):\n",
        "  \"\"\"Trains the model multiple times with the same parameters and returns the average metrics\"\"\"\n",
        "  start = time.time()\n",
        "  all_val_auc = []\n",
        "  all_val_accuracy = []\n",
        "\n",
        "  if hparams['reduction_alg'] != None:\n",
        "    xs_for_train = unsup_exstract(xs, **hparams)\n",
        "  else:\n",
        "    xs_for_train = xs\n",
        "\n",
        "  do_summary = True\n",
        "  for i in range(num_repeat):\n",
        "    logs = train_best_logs(xs_for_train, ys, num_val, do_summary, hparams, get_model)\n",
        "    all_val_auc.append(get_val_auc(logs))\n",
        "    all_val_accuracy.append(logs.get('val_accuracy'))\n",
        "    do_summary = False \n",
        "\n",
        "  mean_val_auc = np.mean(all_val_auc)\n",
        "  mean_val_accuracy = np.mean(all_val_accuracy)\n",
        "  metric = (mean_val_auc + mean_val_accuracy) / 2.0\n",
        "  print_data = (\"mean_val_auc\", mean_val_auc, \"mean_val_accuracy\", mean_val_accuracy, \"metric\", metric, \"val_auc_std\", np.std(all_val_auc), \"val_accuracy_std\", np.std(all_val_accuracy))\n",
        "\n",
        "  end = time.time()\n",
        "  print(\"Seconds per hyperparam config\", end - start)\n",
        "  # GPU: ('Seconds per hyperparam config', 16.970870971679688)\n",
        "\n",
        "  return metric, print_data\n",
        "\n",
        "best_metric = -float('inf')\n",
        "\n",
        "run_num = 0\n",
        "for hparams in hparam_combinations:\n",
        "  print(\"hparams\", hparams)\n",
        "\n",
        "  metric, print_data = multiple_train_ave(hparams)\n",
        "\n",
        "  print(print_data)\n",
        "  if metric > best_metric:\n",
        "    best_metric = metric\n",
        "    best_print_data = print_data\n",
        "    best_hparams = hparams\n",
        "\n",
        "  run_num += 1\n",
        "  print(\"fract done\", run_num/float(len(hparam_combinations)))\n",
        "  print\n",
        "  print(\"==============================================================================================\")\n",
        "  print\n",
        "  sys.stdout.flush()\n",
        "\n",
        "print(\"best_hparams\", best_hparams)\n",
        "print(\"best results\", best_print_data)\n",
        "print(\"Retraining on the best_hparams to make sure we didn't just get good results by random chance.\")\n",
        "\n",
        "_, print_data = multiple_train_ave(best_hparams)\n",
        "print(\"Result of retrain on the best hyperparameters\", print_data)\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "use_activations: True num_train: 50 epochs 400\n",
            "len(hparam_combinations) 12 hparam_combinations [{'drop_rate': 0.2, 'reg_amount': 0.2, 'layer_sizes': (32,), 'q_net_last_cut': 4, 'q_net_freeze': (), 'reduction_alg': None, 'n_components': None}, {'drop_rate': 0.5, 'reg_amount': 0.5, 'layer_sizes': (32,), 'q_net_last_cut': 4, 'q_net_freeze': (), 'reduction_alg': None, 'n_components': None}, {'drop_rate': 0.5, 'reg_amount': 0.5, 'layer_sizes': (32,), 'q_net_last_cut': 5, 'q_net_freeze': (), 'reduction_alg': None, 'n_components': None}, {'drop_rate': 0.2, 'reg_amount': 0.2, 'layer_sizes': (32,), 'q_net_last_cut': 5, 'q_net_freeze': (), 'reduction_alg': None, 'n_components': None}, {'drop_rate': 0.2, 'reg_amount': 0.2, 'layer_sizes': (32,), 'q_net_last_cut': 5, 'q_net_freeze': (0, 1, 2), 'reduction_alg': None, 'n_components': None}, {'drop_rate': 0.5, 'reg_amount': 0.5, 'layer_sizes': (32,), 'q_net_last_cut': 5, 'q_net_freeze': (0, 1, 2), 'reduction_alg': None, 'n_components': None}, {'drop_rate': 0.5, 'reg_amount': 0.5, 'layer_sizes': (32,), 'q_net_last_cut': 4, 'q_net_freeze': (0, 1, 2, 3), 'reduction_alg': None, 'n_components': None}, {'drop_rate': 0.2, 'reg_amount': 0.2, 'layer_sizes': (32,), 'q_net_last_cut': 4, 'q_net_freeze': (0, 1, 2), 'reduction_alg': None, 'n_components': None}, {'drop_rate': 0.2, 'reg_amount': 0.2, 'layer_sizes': (32,), 'q_net_last_cut': 5, 'q_net_freeze': (0, 1, 2, 3), 'reduction_alg': None, 'n_components': None}, {'drop_rate': 0.5, 'reg_amount': 0.5, 'layer_sizes': (32,), 'q_net_last_cut': 4, 'q_net_freeze': (0, 1, 2), 'reduction_alg': None, 'n_components': None}, {'drop_rate': 0.2, 'reg_amount': 0.2, 'layer_sizes': (32,), 'q_net_last_cut': 4, 'q_net_freeze': (0, 1, 2, 3), 'reduction_alg': None, 'n_components': None}, {'drop_rate': 0.5, 'reg_amount': 0.5, 'layer_sizes': (32,), 'q_net_last_cut': 5, 'q_net_freeze': (0, 1, 2, 3), 'reduction_alg': None, 'n_components': None}]\n",
            "hparams {'drop_rate': 0.2, 'reg_amount': 0.2, 'layer_sizes': (32,), 'q_net_last_cut': 4, 'q_net_freeze': (), 'reduction_alg': None, 'n_components': None}\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "EncodingNetwork/conv2d (Conv (None, 12, 14, 16)        736       \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/conv2d_1 (Co (None, 5, 6, 32)          4640      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 960)               0         \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/dense (Dense (None, 64)                61504     \n",
            "_________________________________________________________________\n",
            "post_agent_0 (Dense)         (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 68,993\n",
            "Trainable params: 68,993\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "best train accuracy: 1.0\n",
            "Number of epochs: 259\n",
            "Seconds per hyperparam config 66.2778251171112\n",
            "('mean_val_auc', 0.8135456562042236, 'mean_val_accuracy', 0.7680000066757202, 'metric', 0.7907728314399719, 'val_auc_std', 0.07239101695909787, 'val_accuracy_std', 0.047471045367638985)\n",
            "fract done 0.08333333333333333\n",
            "==============================================================================================\n",
            "hparams {'drop_rate': 0.5, 'reg_amount': 0.5, 'layer_sizes': (32,), 'q_net_last_cut': 4, 'q_net_freeze': (), 'reduction_alg': None, 'n_components': None}\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "EncodingNetwork/conv2d (Conv (None, 12, 14, 16)        736       \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/conv2d_1 (Co (None, 5, 6, 32)          4640      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 960)               0         \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/dense (Dense (None, 64)                61504     \n",
            "_________________________________________________________________\n",
            "post_agent_0 (Dense)         (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 68,993\n",
            "Trainable params: 68,993\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "best train accuracy: 1.0\n",
            "Number of epochs: 256\n",
            "Seconds per hyperparam config 62.90045881271362\n",
            "('mean_val_auc', 0.7927543640136718, 'mean_val_accuracy', 0.7465000033378602, 'metric', 0.769627183675766, 'val_auc_std', 0.09200568252021765, 'val_accuracy_std', 0.08971621741982572)\n",
            "fract done 0.16666666666666666\n",
            "==============================================================================================\n",
            "hparams {'drop_rate': 0.5, 'reg_amount': 0.5, 'layer_sizes': (32,), 'q_net_last_cut': 5, 'q_net_freeze': (), 'reduction_alg': None, 'n_components': None}\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "EncodingNetwork/conv2d (Conv (None, 12, 14, 16)        736       \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/conv2d_1 (Co (None, 5, 6, 32)          4640      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 960)               0         \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/dense (Dense (None, 64)                61504     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 195       \n",
            "_________________________________________________________________\n",
            "post_agent_0 (Dense)         (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 67,236\n",
            "Trainable params: 67,236\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "best train accuracy: 1.0\n",
            "Number of epochs: 128\n",
            "Seconds per hyperparam config 50.75582456588745\n",
            "('mean_val_auc', 0.8062063574790954, 'mean_val_accuracy', 0.7504999995231628, 'metric', 0.7783531785011291, 'val_auc_std', 0.08332090580659567, 'val_accuracy_std', 0.09234988143626312)\n",
            "fract done 0.25\n",
            "==============================================================================================\n",
            "hparams {'drop_rate': 0.2, 'reg_amount': 0.2, 'layer_sizes': (32,), 'q_net_last_cut': 5, 'q_net_freeze': (), 'reduction_alg': None, 'n_components': None}\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "EncodingNetwork/conv2d (Conv (None, 12, 14, 16)        736       \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/conv2d_1 (Co (None, 5, 6, 32)          4640      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 960)               0         \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/dense (Dense (None, 64)                61504     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 195       \n",
            "_________________________________________________________________\n",
            "post_agent_0 (Dense)         (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 67,236\n",
            "Trainable params: 67,236\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "best train accuracy: 1.0\n",
            "Number of epochs: 72\n",
            "Seconds per hyperparam config 31.78878355026245\n",
            "('mean_val_auc', 0.7650488376617431, 'mean_val_accuracy', 0.7125, 'metric', 0.7387744188308716, 'val_auc_std', 0.025627873284070797, 'val_accuracy_std', 0.02334524088111489)\n",
            "fract done 0.3333333333333333\n",
            "==============================================================================================\n",
            "hparams {'drop_rate': 0.2, 'reg_amount': 0.2, 'layer_sizes': (32,), 'q_net_last_cut': 5, 'q_net_freeze': (0, 1, 2), 'reduction_alg': None, 'n_components': None}\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "EncodingNetwork/conv2d (Conv (None, 12, 14, 16)        736       \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/conv2d_1 (Co (None, 5, 6, 32)          4640      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 960)               0         \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/dense (Dense (None, 64)                61504     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 195       \n",
            "_________________________________________________________________\n",
            "post_agent_0 (Dense)         (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 67,236\n",
            "Trainable params: 61,860\n",
            "Non-trainable params: 5,376\n",
            "_________________________________________________________________\n",
            "best train accuracy: 1.0\n",
            "Number of epochs: 288\n",
            "Seconds per hyperparam config 62.394030809402466\n",
            "('mean_val_auc', 0.9004547238349915, 'mean_val_accuracy', 0.8555000066757202, 'metric', 0.8779773652553559, 'val_auc_std', 0.016794487308899205, 'val_accuracy_std', 0.01111305873227447)\n",
            "fract done 0.4166666666666667\n",
            "==============================================================================================\n",
            "hparams {'drop_rate': 0.5, 'reg_amount': 0.5, 'layer_sizes': (32,), 'q_net_last_cut': 5, 'q_net_freeze': (0, 1, 2), 'reduction_alg': None, 'n_components': None}\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "EncodingNetwork/conv2d (Conv (None, 12, 14, 16)        736       \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/conv2d_1 (Co (None, 5, 6, 32)          4640      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 960)               0         \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/dense (Dense (None, 64)                61504     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 195       \n",
            "_________________________________________________________________\n",
            "post_agent_0 (Dense)         (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 67,236\n",
            "Trainable params: 61,860\n",
            "Non-trainable params: 5,376\n",
            "_________________________________________________________________\n",
            "best train accuracy: 1.0\n",
            "Number of epochs: 116\n",
            "Seconds per hyperparam config 45.93529152870178\n",
            "('mean_val_auc', 0.8928041577339172, 'mean_val_accuracy', 0.8385000109672547, 'metric', 0.8656520843505859, 'val_auc_std', 0.01328376452492568, 'val_accuracy_std', 0.028000000757832242)\n",
            "fract done 0.5\n",
            "==============================================================================================\n",
            "hparams {'drop_rate': 0.5, 'reg_amount': 0.5, 'layer_sizes': (32,), 'q_net_last_cut': 4, 'q_net_freeze': (0, 1, 2, 3), 'reduction_alg': None, 'n_components': None}\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "EncodingNetwork/conv2d (Conv (None, 12, 14, 16)        736       \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/conv2d_1 (Co (None, 5, 6, 32)          4640      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 960)               0         \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/dense (Dense (None, 64)                61504     \n",
            "_________________________________________________________________\n",
            "post_agent_0 (Dense)         (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 68,993\n",
            "Trainable params: 2,113\n",
            "Non-trainable params: 66,880\n",
            "_________________________________________________________________\n",
            "best train accuracy: 1.0\n",
            "Number of epochs: 327\n",
            "Seconds per hyperparam config 85.34214234352112\n",
            "('mean_val_auc', 0.8918830513954162, 'mean_val_accuracy', 0.8325000166893005, 'metric', 0.8621915340423584, 'val_auc_std', 0.01685615016320958, 'val_accuracy_std', 0.019874616451284605)\n",
            "fract done 0.5833333333333334\n",
            "==============================================================================================\n",
            "hparams {'drop_rate': 0.2, 'reg_amount': 0.2, 'layer_sizes': (32,), 'q_net_last_cut': 4, 'q_net_freeze': (0, 1, 2), 'reduction_alg': None, 'n_components': None}\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "EncodingNetwork/conv2d (Conv (None, 12, 14, 16)        736       \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/conv2d_1 (Co (None, 5, 6, 32)          4640      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 960)               0         \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/dense (Dense (None, 64)                61504     \n",
            "_________________________________________________________________\n",
            "post_agent_0 (Dense)         (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 68,993\n",
            "Trainable params: 63,617\n",
            "Non-trainable params: 5,376\n",
            "_________________________________________________________________\n",
            "best train accuracy: 1.0\n",
            "Number of epochs: 391\n",
            "Seconds per hyperparam config 82.76073837280273\n",
            "('mean_val_auc', 0.8757919192314148, 'mean_val_accuracy', 0.8039999961853027, 'metric', 0.8398959577083587, 'val_auc_std', 0.023813946139298957, 'val_accuracy_std', 0.02216979641678196)\n",
            "fract done 0.6666666666666666\n",
            "==============================================================================================\n",
            "hparams {'drop_rate': 0.2, 'reg_amount': 0.2, 'layer_sizes': (32,), 'q_net_last_cut': 5, 'q_net_freeze': (0, 1, 2, 3), 'reduction_alg': None, 'n_components': None}\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "EncodingNetwork/conv2d (Conv (None, 12, 14, 16)        736       \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/conv2d_1 (Co (None, 5, 6, 32)          4640      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 960)               0         \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/dense (Dense (None, 64)                61504     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 195       \n",
            "_________________________________________________________________\n",
            "post_agent_0 (Dense)         (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 67,236\n",
            "Trainable params: 356\n",
            "Non-trainable params: 66,880\n",
            "_________________________________________________________________\n",
            "best train accuracy: 0.9800000190734863\n",
            "Number of epochs: 318\n",
            "Seconds per hyperparam config 63.144373178482056\n",
            "('mean_val_auc', 0.8988391160964966, 'mean_val_accuracy', 0.8434999942779541, 'metric', 0.8711695551872254, 'val_auc_std', 0.02276422762537647, 'val_accuracy_std', 0.026248810804771924)\n",
            "fract done 0.75\n",
            "==============================================================================================\n",
            "hparams {'drop_rate': 0.5, 'reg_amount': 0.5, 'layer_sizes': (32,), 'q_net_last_cut': 4, 'q_net_freeze': (0, 1, 2), 'reduction_alg': None, 'n_components': None}\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "EncodingNetwork/conv2d (Conv (None, 12, 14, 16)        736       \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/conv2d_1 (Co (None, 5, 6, 32)          4640      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 960)               0         \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/dense (Dense (None, 64)                61504     \n",
            "_________________________________________________________________\n",
            "post_agent_0 (Dense)         (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 68,993\n",
            "Trainable params: 63,617\n",
            "Non-trainable params: 5,376\n",
            "_________________________________________________________________\n",
            "best train accuracy: 1.0\n",
            "Number of epochs: 254\n",
            "Seconds per hyperparam config 64.66368412971497\n",
            "('mean_val_auc', 0.8990165829658509, 'mean_val_accuracy', 0.840499997138977, 'metric', 0.8697582900524139, 'val_auc_std', 0.014276648234024313, 'val_accuracy_std', 0.02976574937689661)\n",
            "fract done 0.8333333333333334\n",
            "==============================================================================================\n",
            "hparams {'drop_rate': 0.2, 'reg_amount': 0.2, 'layer_sizes': (32,), 'q_net_last_cut': 4, 'q_net_freeze': (0, 1, 2, 3), 'reduction_alg': None, 'n_components': None}\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "EncodingNetwork/conv2d (Conv (None, 12, 14, 16)        736       \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/conv2d_1 (Co (None, 5, 6, 32)          4640      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 960)               0         \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/dense (Dense (None, 64)                61504     \n",
            "_________________________________________________________________\n",
            "post_agent_0 (Dense)         (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 68,993\n",
            "Trainable params: 2,113\n",
            "Non-trainable params: 66,880\n",
            "_________________________________________________________________\n",
            "best train accuracy: 1.0\n",
            "Number of epochs: 400\n",
            "Seconds per hyperparam config 92.45892429351807\n",
            "('mean_val_auc', 0.8874560475349427, 'mean_val_accuracy', 0.8369999885559082, 'metric', 0.8622280180454254, 'val_auc_std', 0.021817999296049825, 'val_accuracy_std', 0.020700243686773485)\n",
            "fract done 0.9166666666666666\n",
            "==============================================================================================\n",
            "hparams {'drop_rate': 0.5, 'reg_amount': 0.5, 'layer_sizes': (32,), 'q_net_last_cut': 5, 'q_net_freeze': (0, 1, 2, 3), 'reduction_alg': None, 'n_components': None}\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "EncodingNetwork/conv2d (Conv (None, 12, 14, 16)        736       \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/conv2d_1 (Co (None, 5, 6, 32)          4640      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 960)               0         \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/dense (Dense (None, 64)                61504     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 195       \n",
            "_________________________________________________________________\n",
            "post_agent_0 (Dense)         (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 67,236\n",
            "Trainable params: 356\n",
            "Non-trainable params: 66,880\n",
            "_________________________________________________________________\n",
            "best train accuracy: 0.8799999952316284\n",
            "Number of epochs: 205\n",
            "Seconds per hyperparam config 63.28559136390686\n",
            "('mean_val_auc', 0.8757757663726806, 'mean_val_accuracy', 0.8034999966621399, 'metric', 0.8396378815174103, 'val_auc_std', 0.02478858338209984, 'val_accuracy_std', 0.021365856144527302)\n",
            "fract done 1.0\n",
            "==============================================================================================\n",
            "best_hparams {'drop_rate': 0.2, 'reg_amount': 0.2, 'layer_sizes': (32,), 'q_net_last_cut': 5, 'q_net_freeze': (0, 1, 2), 'reduction_alg': None, 'n_components': None}\n",
            "best results ('mean_val_auc', 0.9004547238349915, 'mean_val_accuracy', 0.8555000066757202, 'metric', 0.8779773652553559, 'val_auc_std', 0.016794487308899205, 'val_accuracy_std', 0.01111305873227447)\n",
            "Retraining on the best_hparams to make sure we didn't just get good results by random chance.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "EncodingNetwork/conv2d (Conv (None, 12, 14, 16)        736       \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/conv2d_1 (Co (None, 5, 6, 32)          4640      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 960)               0         \n",
            "_________________________________________________________________\n",
            "EncodingNetwork/dense (Dense (None, 64)                61504     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 195       \n",
            "_________________________________________________________________\n",
            "post_agent_0 (Dense)         (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 67,236\n",
            "Trainable params: 61,860\n",
            "Non-trainable params: 5,376\n",
            "_________________________________________________________________\n",
            "best train accuracy: 1.0\n",
            "Number of epochs: 199\n",
            "Seconds per hyperparam config 52.12105059623718\n",
            "Result of retrain on the best hyperparameters ('mean_val_auc', 0.9026936769485474, 'mean_val_accuracy', 0.8379999995231628, 'metric', 0.8703468382358551, 'val_auc_std', 0.03507916407863068, 'val_accuracy_std', 0.033443976607509446)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}